{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d92101e",
   "metadata": {},
   "source": [
    "# GPT Model Development Notebook\n",
    "This notebook is organized into the following sections:\n",
    "1. **Imports & Setup**\n",
    "2. **Data Loading & Preprocessing**\n",
    "3. **Model Architecture**\n",
    "4. **Training**\n",
    "5. **Evaluation & Results**\n",
    "6. **Saving & Exporting Model**\n",
    "7. **Notes & Next Steps**\n",
    "---\n",
    "Please follow the section headers and keep code and explanations grouped for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fad05",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup\n",
    "Import all required libraries and set up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d2d7a",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing\n",
    "Load your dataset and perform any necessary preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03cf42",
   "metadata": {},
   "source": [
    "## 6. Saving & Exporting Model\n",
    "Save your trained model and export as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133d2a4",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Results\n",
    "Evaluate your model and display results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b3f63",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "Train your model and monitor metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43169b8",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "Define your GPT model architecture here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62adc19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26b8fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "007f70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from typing import List, Dict, Tuple\n",
    "\n",
    "# def tokenize_and_build_vocabulary_tf(\n",
    "#     file_path_list: List[str] = [r\"/home/akshat/GPT_from_scratch/text_data/pg76702.txt\"],\n",
    "#     existing_vocab: Dict[str, int] = None # type: ignore\n",
    "# ) -> Tuple[tf.lookup.StaticHashTable, tf.lookup.StaticHashTable]:\n",
    "#     \"\"\"\n",
    "#     Build a character-level vocabulary from text files and return TensorFlow lookup tables.\n",
    "    \n",
    "#     Returns:\n",
    "#         token_to_id_table: tf.lookup.StaticHashTable mapping char -> int\n",
    "#         id_to_token_table: tf.lookup.StaticHashTable mapping int -> char\n",
    "#     \"\"\"\n",
    "#     if existing_vocab is None:\n",
    "#         existing_vocab = {}\n",
    "\n",
    "#     vocab_set = set(existing_vocab.keys())\n",
    "\n",
    "#     # Collect characters from all files\n",
    "#     for file_name in file_path_list:\n",
    "#         with open(file_name, encoding=\"utf-8\") as f:\n",
    "#             text = f.read()\n",
    "#             vocab_set.update(text)\n",
    "\n",
    "#     # Sort for consistency\n",
    "#     sorted_tokens = sorted(vocab_set)\n",
    "\n",
    "#     # Assign IDs (keep existing IDs if possible)\n",
    "#     token_to_id = {token: i for i, token in enumerate(sorted_tokens)}\n",
    "#     id_to_token = {i: token for token, i in token_to_id.items()}\n",
    "\n",
    "#     # Convert dicts to tensors\n",
    "#     token_keys = tf.constant(list(token_to_id.keys()))\n",
    "#     token_values = tf.constant(list(token_to_id.values()), dtype=tf.int32)\n",
    "\n",
    "#     id_keys = tf.constant(list(id_to_token.keys()), dtype=tf.int32)\n",
    "#     id_values = tf.constant(list(id_to_token.values()))\n",
    "\n",
    "#     # Create TensorFlow lookup tables\n",
    "#     token_to_id_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(token_keys, token_values),\n",
    "#         default_value=-1  # unknown token\n",
    "#     )\n",
    "#     id_to_token_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(id_keys, id_values),\n",
    "#         default_value=\"\"  # unknown ID\n",
    "#     )\n",
    "\n",
    "#     return token_to_id_table, id_to_token_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9856e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from typing import List, Dict, Tuple\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def tokenize_and_build_vocabulary_tf(\n",
    "#     file_path_list: List[str],\n",
    "#     existing_vocab: Dict[str, int] | None = None\n",
    "# ) -> Tuple[tf.lookup.StaticHashTable, tf.lookup.StaticHashTable]:\n",
    "#     \"\"\"\n",
    "#     Build a character-level vocabulary from text files and return TF lookup tables:\n",
    "#       token_to_id: char -> int\n",
    "#       id_to_token: int -> char\n",
    "#     \"\"\"\n",
    "#     if isinstance(file_path_list, (str, bytes)):\n",
    "#         file_path_list = [file_path_list] # type: ignore\n",
    "#     if existing_vocab is None:\n",
    "#         existing_vocab = {}\n",
    "\n",
    "#     vocab_set = set(existing_vocab.keys())\n",
    "#     for file_name in file_path_list:\n",
    "#         if os.path.isdir(file_name):\n",
    "#             raise IsADirectoryError(f\"Expected file path, got directory: {file_name}\")\n",
    "#         if not os.path.isfile(file_name):\n",
    "#             raise FileNotFoundError(f\"File not found: {file_name}\")\n",
    "#         with open(file_name, encoding=\"utf-8\") as f:\n",
    "#             text = f.read()\n",
    "#             vocab_set.update(text)\n",
    "\n",
    "#     sorted_tokens = sorted(vocab_set)\n",
    "#     token_to_id = {tok: i for i, tok in enumerate(sorted_tokens)}\n",
    "#     id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
    "\n",
    "#     token_keys = tf.constant(list(token_to_id.keys()), dtype=tf.string)\n",
    "#     token_vals = tf.constant(list(token_to_id.values()), dtype=tf.int32)\n",
    "\n",
    "#     id_keys = tf.constant(list(id_to_token.keys()), dtype=tf.int32)\n",
    "#     id_vals = tf.constant(list(id_to_token.values()), dtype=tf.string)\n",
    "\n",
    "#     token_to_id_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(token_keys, token_vals),\n",
    "#         default_value=-1\n",
    "#     )\n",
    "#     id_to_token_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(id_keys, id_vals),\n",
    "#         default_value=tf.constant(\"\", dtype=tf.string)\n",
    "#     )\n",
    "#     return token_to_id_table, id_to_token_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b18d7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "@keras.saving.register_keras_serializable()\n",
    "def prepare_sinusoidal_lookup_table(EMBEDDING_SIZE: int = 128, max_seq_len: int = 512):\n",
    "    \"\"\"\n",
    "    Builds a sinusoidal positional encoding lookup table.\n",
    "    \n",
    "    Args:\n",
    "      EMBEDDING_SIZE: dimensionality of each position encoding vector (must be even).\n",
    "      max_seq_len: maximum sequence length (number of positions).\n",
    "    \n",
    "    Returns:\n",
    "      lookup_table: a tf array of shape (max_seq_len, EMBEDDING_SIZE)\n",
    "                    where row p gives the positional encoding for position p.\n",
    "    \"\"\"\n",
    "    # Initialize the table\n",
    "    lookup_table = np.zeros((max_seq_len, EMBEDDING_SIZE), dtype=np.float32)\n",
    "    \n",
    "    # Compute the angle rates for each dimension\n",
    "    # angle_rates[k] = 1 / (10000^(2*(k//2) / EMBEDDING_SIZE))\n",
    "    dims = np.arange(EMBEDDING_SIZE)[np.newaxis, :]   # shape (1, EMBEDDING_SIZE)\n",
    "    positions = np.arange(max_seq_len)[:, np.newaxis] # shape (max_seq_len, 1)\n",
    "    angle_rates = 1 / np.power(10000, (2 * (dims // 2)) / EMBEDDING_SIZE)\n",
    "    \n",
    "    # Compute the angle for each position and dimension: position * angle_rate\n",
    "    angle_rads = positions * angle_rates  # shape (max_seq_len, EMBEDDING_SIZE)\n",
    "    \n",
    "    # Apply sin to even indices (0,2,4,...) and cos to odd indices (1,3,5,...)\n",
    "    lookup_table[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    lookup_table[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    return tf.constant(lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "741514bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def tokenize_and_build_token_id(token_to_id_table: tf.lookup.StaticHashTable,\n",
    "#                                 text_batch: tf.Tensor,\n",
    "#                                 pad_value: int = 0):\n",
    "#     \"\"\"\n",
    "#     Tokenize a batch of strings character by character, pad sequences,\n",
    "#     and return attention masks.\n",
    "\n",
    "#     Args:\n",
    "#         token_to_id_table: TF lookup table mapping char -> int\n",
    "#         text_batch: tf.Tensor of shape [batch_size], dtype=tf.string\n",
    "#         pad_value: int, ID to use for padding\n",
    "\n",
    "#     Returns:\n",
    "#         token_ids: tf.Tensor [batch_size, max_seq_len]\n",
    "#         attention_mask: tf.Tensor [batch_size, max_seq_len]\n",
    "#     \"\"\"\n",
    "#     token_ids_list = []\n",
    "\n",
    "#     for text in text_batch.numpy():  # type: ignore\n",
    "#         # Convert bytes to TF string\n",
    "\n",
    "#         # Split into characters\n",
    "#         char_tensor = tf.strings.bytes_split(text)\n",
    "\n",
    "#         # Lookup token IDs\n",
    "#         token_ids = token_to_id_table.lookup(char_tensor)\n",
    "\n",
    "#         token_ids_list.append(token_ids)\n",
    "\n",
    "#     # Pad all sequences to the same length\n",
    "#     token_ids_padded = tf.ragged.stack(token_ids_list).to_tensor(default_value=pad_value) # type: ignore\n",
    "#     # Create attention mask: 1 for real tokens, 0 for padding\n",
    "#     attention_mask = tf.cast(token_ids_padded != pad_value, tf.int32)\n",
    "\n",
    "#     return token_ids_padded, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c66c28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from typing import Tuple\n",
    "\n",
    "\n",
    "# def tokenize_and_build_token_id(\n",
    "#     token_to_id_dict: dict,\n",
    "#     text_batch: list[str],\n",
    "#     max_seq_len: int,\n",
    "#     pad_value: int = 0,\n",
    "#     unk_value: int = None\n",
    "# ) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "#     \"\"\"\n",
    "#     TensorFlow-compatible tokenization converting batch of strings to char token IDs,\n",
    "#     padded/truncated to max_seq_len, along with attention mask.\n",
    "\n",
    "#     Args:\n",
    "#         token_to_id_dict: dict mapping character str -> int ID\n",
    "#         text_batch: list of strings to tokenize\n",
    "#         max_seq_len: max length to pad/truncate sequences\n",
    "#         pad_value: int ID for padding tokens\n",
    "#         unk_value: int ID for unknown tokens; if None, uses pad_value\n",
    "\n",
    "#     Returns:\n",
    "#         token_ids: (batch_size, max_seq_len) tf.int32 tensor of token IDs\n",
    "#         attention_mask: (batch_size, max_seq_len) tf.int32 tensor (1 for tokens, 0 for padding)\n",
    "#     \"\"\"\n",
    "\n",
    "#     if unk_value is None:\n",
    "#         unk_value = pad_value\n",
    "\n",
    "#     # Create lookup table from token_to_id_dict\n",
    "#     keys = tf.constant(list(token_to_id_dict.keys()))\n",
    "#     values = tf.constant(list(token_to_id_dict.values()), dtype=tf.int32)\n",
    "#     table = tf.lookup.StaticHashTable(\n",
    "#         tf.lookup.KeyValueTensorInitializer(keys, values),\n",
    "#         default_value=unk_value\n",
    "#     )\n",
    "\n",
    "#     # Convert text batch to a RaggedTensor of chars\n",
    "#     rt_chars = tf.strings.unicode_split(text_batch, 'UTF-8')  # shape: [batch_size, (seq_len)]\n",
    "\n",
    "#     # Lookup token IDs for each char\n",
    "#     token_ids = table.lookup(rt_chars)\n",
    "\n",
    "#     # Pad or truncate sequences to max_seq_len\n",
    "#     token_ids = token_ids.to_tensor(default_value=pad_value, shape=[None, max_seq_len])\n",
    "#     token_ids = token_ids[:, :max_seq_len]  # truncate if longer\n",
    "\n",
    "#     # Construct attention mask: 1 where not pad_value, else 0\n",
    "#     attention_mask = tf.cast(token_ids != pad_value, tf.int32)\n",
    "\n",
    "#     return token_ids, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21e3a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def tokenize_and_build_vocabulary_tf(file_path_list: List[str], existing_vocab: Dict[str, int] | None = None) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a character-level vocabulary dictionary from text files.\n",
    "    \n",
    "    Args:\n",
    "        file_path_list: List of file paths containing the text corpus.\n",
    "        existing_vocab: Optional existing vocabulary to extend.\n",
    "\n",
    "    Returns:\n",
    "        token_to_id: dict mapping character to unique integer token ID.\n",
    "    \"\"\"\n",
    "    if isinstance(file_path_list, (str, bytes)):\n",
    "        file_path_list = [file_path_list] # type: ignore\n",
    "    if existing_vocab is None:\n",
    "        existing_vocab = {}\n",
    "    vocab_set = set(existing_vocab.keys())\n",
    "    \n",
    "    for file_name in file_path_list:\n",
    "        if os.path.isdir(file_name):\n",
    "            raise IsADirectoryError(f\"Expected file path, got directory: {file_name}\")\n",
    "        if not os.path.isfile(file_name):\n",
    "            raise FileNotFoundError(f\"File not found: {file_name}\")\n",
    "        with open(file_name, encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            vocab_set.update(text)\n",
    "    \n",
    "    sorted_tokens = sorted(vocab_set)\n",
    "    token_to_id = {char: idx for idx, char in enumerate(sorted_tokens)}\n",
    "    return token_to_id\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def tokenize_and_build_token_id(token_to_id_dict: Dict[str, int], text_batch: List[str], max_seq_len: int, pad_value: int = 0) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Tokenize a batch of text strings into character token IDs using a token dictionary,\n",
    "    then pad/truncate to max_seq_len and create attention masks.\n",
    "\n",
    "    Args:\n",
    "        token_to_id_dict: dict mapping character to integer token ID.\n",
    "        text_batch: list of text strings to tokenize.\n",
    "        max_seq_len: maximum sequence length after padding/truncation.\n",
    "        pad_value: integer ID used for padding tokens.\n",
    "\n",
    "    Returns:\n",
    "        token_ids: tf.Tensor of shape (batch_size, max_seq_len), dtype tf.int32.\n",
    "        attention_mask: tf.Tensor of shape (batch_size, max_seq_len), dtype tf.int32 (1 for real tokens, 0 for padding).\n",
    "    \"\"\"\n",
    "    batch_token_ids = []\n",
    "    for text in text_batch:\n",
    "        ids = [token_to_id_dict.get(c, pad_value) for c in text]\n",
    "        if len(ids) > max_seq_len:\n",
    "            ids = ids[:max_seq_len]\n",
    "        else:\n",
    "            ids += [pad_value] * (max_seq_len - len(ids))\n",
    "        batch_token_ids.append(ids)\n",
    "    \n",
    "    token_ids = np.array(batch_token_ids, dtype=np.int32)\n",
    "    attention_mask = (token_ids != pad_value).astype(np.int32)\n",
    "    \n",
    "    return tf.constant(token_ids), tf.constant(attention_mask) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4965754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Letters, digits, punctuation, space, newline\n",
    "ALLOWED = set(\n",
    "    list(string.ascii_lowercase) +\n",
    "    list(\" .,!?;\\\"\\n\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5158d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt') as f:\n",
    "    text = f.read()\n",
    "    text = \"\".join(ch if ch in ALLOWED else \" \" for ch in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "153f850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "token_to_id_dict = tokenize_and_build_vocabulary_tf([r'/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt'])\n",
    "# Lookup with plain Python dict\n",
    "token_id_for_a = token_to_id_dict.get('a', None)\n",
    "print(token_id_for_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca4c6824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " \"'\": 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " ':': 9,\n",
       " ';': 10,\n",
       " '?': 11,\n",
       " 'a': 12,\n",
       " 'b': 13,\n",
       " 'c': 14,\n",
       " 'd': 15,\n",
       " 'e': 16,\n",
       " 'f': 17,\n",
       " 'g': 18,\n",
       " 'h': 19,\n",
       " 'i': 20,\n",
       " 'j': 21,\n",
       " 'k': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'q': 28,\n",
       " 'r': 29,\n",
       " 's': 30,\n",
       " 't': 31,\n",
       " 'u': 32,\n",
       " 'v': 33,\n",
       " 'w': 34,\n",
       " 'x': 35,\n",
       " 'y': 36,\n",
       " 'z': 37}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec9075b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(13,), dtype=string, numpy=\n",
       "array([b'A', b'k', b's', b'h', b'a', b't', b' ', b'K', b'h', b'a', b't',\n",
       "       b'r', b'i'], dtype=object)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = tf.constant('Akshat Khatri')\n",
    "tf.strings.bytes_split(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45984209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello'\n",
      "b'Worlds '\n"
     ]
    }
   ],
   "source": [
    "name = tf.constant(['Hello','Worlds '])\n",
    "for name in name.numpy():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33ba567a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1.,2.,3.])\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "046629d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
       " array([[ 0, 22, 30, ...,  0,  0,  0],\n",
       "        [19, 16, 23, ...,  0,  0,  0],\n",
       "        [24, 16,  0, ...,  0,  0,  0]], shape=(3, 512), dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
       " array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0]], shape=(3, 512), dtype=int32)>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['Akshat Khatri','hello ','me']\n",
    "tokenize_and_build_token_id(token_to_id_dict,name,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74d1a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "caa293c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Callable\n",
    "\n",
    "# class InitializePositionalEmbeddings(keras.layers.Layer): # Receives input of sequence of text\n",
    "#     def __init__(self,d_model: int = 128,sinusoidal_lookup_table = [],token_to_id_dict : tf.lookup.StaticHashTable = {} ,max_seq_len : int = 512,**kwargs): # type: ignore\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.d_model = d_model # d_model\n",
    "#         self.max_seq_len = max_seq_len\n",
    "        \n",
    "#         assert len(sinusoidal_lookup_table) > 0\n",
    "#         assert token_to_id_dict.size().numpy() > 0\n",
    "#         self.VOCAB_SIZE = token_to_id_dict.size().numpy()\n",
    "\n",
    "#         self.pos_table = sinusoidal_lookup_table\n",
    "#         self._embedding_dim = [self.VOCAB_SIZE,d_model]\n",
    "#         self.token_to_id_dict = token_to_id_dict\n",
    "    \n",
    "#     def build(self, input_shape): # this is batch input shape\n",
    "#         print(input_shape)\n",
    "#         self.embedding_matrix = self.add_weight(\n",
    "#             name=\"embedding_matrix\",\n",
    "#             shape=(self.VOCAB_SIZE, self.d_model),\n",
    "#             initializer=\"random_normal\",\n",
    "#             trainable=True   # important\n",
    "#         )\n",
    "#         self.input_seq_list = input_shape[-1]\n",
    "\n",
    "#     def call(self,inputs):\n",
    "#         # print(inputs)\n",
    "#         tokens_in_id,non_padded_tokens_mask = tokenize_and_build_token_id(self.token_to_id_dict,inputs)\n",
    "#         # print(tokens_in_id,non_padded_tokens_mask,sep = '\\n')\n",
    "#         token_embeddings = tf.nn.embedding_lookup(self.embedding_matrix, tokens_in_id)\n",
    "#         # Positional embeddings\n",
    "#         seq_len = tf.shape(tokens_in_id)[1] # type: ignore\n",
    "#         pos_embeddings = self.pos_table[:seq_len, :]\n",
    "#         pos_embeddings = tf.expand_dims(pos_embeddings, 0)  # broadcast along batch\n",
    "#         # Add token + position embeddings\n",
    "#         embeddings = token_embeddings + pos_embeddings\n",
    "#         return embeddings,non_padded_tokens_mask\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         base_config = super().get_config()\n",
    "#         return {**base_config,'EMBEDDING_SIZE' : self.EMBEDDING_SIZE,'VOCAB_SIZE' : self.VOCAB_SIZE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d037241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class InitializePositionalEmbeddings(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        vocab_size : int,\n",
    "        CONTEXT_LEN: int = 128,\n",
    "        pad_value: int = 0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_model = int(d_model)\n",
    "        self.pad_value = int(pad_value)\n",
    "        self.vocab_size = vocab_size\n",
    "        self._pos_table = prepare_sinusoidal_lookup_table(d_model, CONTEXT_LEN)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding_matrix = self.add_weight(\n",
    "            name=\"embedding_matrix\",\n",
    "            shape=(self.vocab_size, self.d_model),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, text_batch):\n",
    "\n",
    "        token_ids= text_batch # Unpacking Data Pre-processing inputs Embeddings\n",
    "        \n",
    "        # Embeddings lookup: (B, T, D)\n",
    "        token_emb = tf.nn.embedding_lookup(self.embedding_matrix, token_ids)\n",
    "        # Positional embeddings: slice and broadcast\n",
    "        seq_len = tf.shape(token_ids)[1] # type: ignore\n",
    "        pos_emb = self._pos_table[:seq_len, :]    # type: ignore # (T, D)\n",
    "        pos_emb = tf.expand_dims(pos_emb, 0)     # (1, T, D)\n",
    "        embeddings = token_emb + pos_emb         # (B, T, D)\n",
    "        return embeddings\n",
    "\n",
    "    # def compute_output_shape(self, input_shape):\n",
    "    #     # input_shape: (batch_size,)\n",
    "    #     batch = input_shape\n",
    "    #     # Sequence length is dynamic: None\n",
    "    #     return (batch, None, self.d_model), (batch, None)\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\n",
    "            \"d_model\": self.d_model,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'max_seq_len': self.max_seq_len,\n",
    "            \"pad_value\": self.pad_value,\n",
    "        })\n",
    "        return cfg\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape: (batch_size, seq_len)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        return (batch_size, seq_len, self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64c431a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(token_to_id_dict)\n",
    "D_MODEL = 64\n",
    "MAX_SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd66a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL)\n",
    "batch_text = ['yo','Akshat Khatri', 'Hello World','Me']\n",
    "batch_text = tokenize_and_build_token_id(token_to_id_dict,batch_text,MAX_SEQ_LEN) # type: ignore\n",
    "token_ids,attention_mask = batch_text\n",
    "\n",
    "layer = InitializePositionalEmbeddings(D_MODEL,VOCAB_SIZE)\n",
    "\n",
    "# @tf.function\n",
    "# def call_some(batch_text):\n",
    "#     embeddings = layer(batch_text)\n",
    "#     return embeddings\n",
    "\n",
    "# call_some(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bb6e1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class SelfAttentionLayer(keras.layers.Layer):\n",
    "    def __init__(self, attention_heads=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention_heads = attention_heads\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[0][-1]\n",
    "        \n",
    "        self.Query_projection = self.add_weight(\n",
    "            name='Query_Vector_for_projection',\n",
    "            initializer='random_normal',\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True \n",
    "        )\n",
    "        self.Key_projection = self.add_weight(\n",
    "            name='Key_Vector_for_projection',\n",
    "            initializer='random_normal',\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True \n",
    "        )\n",
    "        self.Value_projection = self.add_weight(\n",
    "            name='Value_Vector_for_projection',\n",
    "            initializer='random_normal',\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True \n",
    "        )\n",
    "        self.output_projection = self.add_weight(\n",
    "            name=\"Output_projection\",\n",
    "            initializer=\"random_normal\",\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.d_head = self.d_model // self.attention_heads\n",
    "        assert self.d_model % self.attention_heads == 0, \"d_model must be divisible by attention_heads\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embeddings = inputs[0]\n",
    "        token_masks = inputs[1]\n",
    "\n",
    "        batch_size = tf.shape(embeddings)[0]\n",
    "        seq_len = tf.shape(embeddings)[1]\n",
    "\n",
    "        # 1. Project to Q, K, V\n",
    "        Q = embeddings @ self.Query_projection\n",
    "        K = embeddings @ self.Key_projection\n",
    "        V = embeddings @ self.Value_projection\n",
    "\n",
    "        # 2. Reshape for multi-head attention\n",
    "        Q = tf.reshape(Q, (batch_size, seq_len, self.attention_heads, self.d_head))\n",
    "        K = tf.reshape(K, (batch_size, seq_len, self.attention_heads, self.d_head))\n",
    "        V = tf.reshape(V, (batch_size, seq_len, self.attention_heads, self.d_head))\n",
    "\n",
    "        Q = tf.transpose(Q, (0, 2, 1, 3))  # (batch, heads, seq_len, d_head)\n",
    "        K = tf.transpose(K, (0, 2, 1, 3))\n",
    "        V = tf.transpose(V, (0, 2, 1, 3))\n",
    "\n",
    "        # 3. Compute attention scores\n",
    "        scores = tf.matmul(Q, K, transpose_b=True)  # (batch, heads, seq_len, seq_len)\n",
    "        scores = scores / tf.sqrt(tf.cast(self.d_head, tf.float32))\n",
    "        \n",
    "        # 4. FIXED MASKING - This was your main bug\n",
    "        # 4a. Causal mask (L,L) lower triangular\n",
    "        causal_mask = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        \n",
    "        # 4b. Token mask - FIXED: proper broadcasting to all heads\n",
    "        token_mask = tf.cast(token_masks, tf.float32)  # (B, L)\n",
    "        \n",
    "        # Create proper attention mask shape (B, H, L, L)\n",
    "        # Each head gets the same mask pattern\n",
    "        attention_mask = causal_mask[tf.newaxis, tf.newaxis, :, :]  # (1, 1, L, L)\n",
    "        attention_mask = attention_mask * token_mask[:, tf.newaxis, tf.newaxis, :]  # (B, 1, 1, L)\n",
    "        attention_mask = attention_mask * token_mask[:, tf.newaxis, :, tf.newaxis]  # (B, 1, L, 1)\n",
    "        \n",
    "        # Broadcast to all heads\n",
    "        attention_mask = tf.broadcast_to(attention_mask, (batch_size, self.attention_heads, seq_len, seq_len))\n",
    "        \n",
    "        # 5. Apply mask with stronger negative value\n",
    "        scores = tf.where(\n",
    "            attention_mask > 0, \n",
    "            scores, \n",
    "            tf.constant(-1e30, dtype=scores.dtype)  # FIXED: Much more negative\n",
    "        )\n",
    "\n",
    "        # 6. Softmax and apply to values\n",
    "        attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "        \n",
    "        # Add attention dropout (missing in your original)\n",
    "        attention_weights = tf.nn.dropout(attention_weights, rate=0.1)\n",
    "        \n",
    "        context = attention_weights @ V   # (batch, heads, seq_len, d_head)\n",
    "        \n",
    "        # 7. Concatenate heads\n",
    "        concat_context = tf.transpose(context, (0, 2, 1, 3))  # (batch, seq_len, heads, d_head)\n",
    "        concat_context = tf.reshape(concat_context, (batch_size, seq_len, self.d_model))\n",
    "        \n",
    "        # 8. Final projection\n",
    "        final_context = concat_context @ self.output_projection \n",
    "        return final_context\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"attention_heads\": self.attention_heads})\n",
    "        return config\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40a50e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 13, 4, 3), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]]], shape=(16, 13, 4, 3), dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "a = np.random.rand(3, 13, 64)  # batch, seq_len, d_model\n",
    "q = np.ones((64, 64))          # d_model × d_model\n",
    "\n",
    "a = tf.constant(a, dtype=tf.float32)\n",
    "q = tf.constant(q, dtype=tf.float32)\n",
    "\n",
    "s = a @ q   # type: ignore # [3, 13, 64]\n",
    "d_head = 16\n",
    "num_heads = 64 // d_head # 4\n",
    "\n",
    "# split into heads\n",
    "s = tf.reshape(s, (3, num_heads, 13, d_head))  # [3, 4, 13, 16]\n",
    "f = tf.constant(np.ones_like(s))\n",
    "\n",
    "tf.transpose(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "873ee087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0.04742587, 0.04742587, 0.95257413, 0.04742587, 0.04742587],\n",
       "       [0.95257413, 0.95257413, 0.04742587, 0.95257413, 0.95257413]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = tf.constant([[1,2,9,4,5],[4,5,6,7,8]])\n",
    "keras.activations.softmax(tf.cast(arr,dtype = tf.float32),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb91875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0.04742587, 0.04742587, 0.04742587, 0.04742587, 0.04742587],\n",
       "       [0.95257413, 0.95257413, 0.95257413, 0.95257413, 0.95257413]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = tf.constant([[1,2,3,4,5],[4,5,6,7,8]])\n",
    "arr = tf.cast(arr,dtype = tf.float32)\n",
    "\n",
    "tf.nn.softmax(arr,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac7cc3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000000000.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0da4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self,eps=1e-5,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def build(self,input_shape): # Near Attention (batch, seq_len, d_model)\n",
    "        self.alpha = self.add_weight(\n",
    "            name = 'alpha',\n",
    "            shape = input_shape[-1:],\n",
    "            initializer = 'ones',\n",
    "            dtype = tf.float32,\n",
    "            trainable = True\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            name = 'beta',\n",
    "            shape = input_shape[-1:],\n",
    "            initializer = 'zeros',\n",
    "            dtype = tf.float32,\n",
    "            trainable = True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mean, var = tf.nn.moments(inputs, axes=[-1], keepdims=True)\n",
    "        normed = (inputs - mean) / tf.sqrt(var + self.eps) # type: ignore\n",
    "        return self.alpha * normed + self.beta\n",
    "\n",
    "    def get_config(self):\n",
    "        base = super().get_config()\n",
    "        return {**base, \"eps\": self.eps}\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7a994b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense(keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"he_normal\",\n",
    "            trainable=True,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=\"bias\",\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs shape: (batch, seq_len, input_dim)\n",
    "        output = tf.matmul(inputs, self.kernel) + self.bias  # shape: (batch, seq_len, units))  # shape: (batch, seq_len, units)\n",
    "        return output + self.bias\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape: (batch, seq_len, input_dim)\n",
    "        return (input_shape, input_shape[1], self.units)\n",
    "\n",
    "    def get_config(self):\n",
    "        base = super().get_config()\n",
    "        return {**base, \"units\": self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cb7c629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (2,3,4,5,6)\n",
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea053e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class DecoderBlock(keras.Model):\n",
    "    '''A single Decoder Block'''\n",
    "    def __init__(self, d_model, n_heads, dropout_rate=0.1, epsilon=1e-5, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.epsilon = epsilon\n",
    "        # norms\n",
    "        self.ln1 = LayerNormalization(epsilon)   # pre-attn\n",
    "        self.ln2 = LayerNormalization(epsilon)   # pre-ffn\n",
    "        # attention (assumes your SelfAttentionLayer accepts (x, attention_mask))\n",
    "        self.attn = SelfAttentionLayer(n_heads)\n",
    "        self.dropout1 = keras.layers.Dropout(dropout_rate)\n",
    "        # FFN\n",
    "        self.ffn1 = keras.layers.Dense(4 * d_model, activation=\"gelu\")\n",
    "        self.ffn2 = keras.layers.Dense(d_model)\n",
    "        self.dropout2 = keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, attention_mask, training=False):\n",
    "        # Self-attention sublayer\n",
    "        y = self.ln1(x)\n",
    "        y = self.attn((y, attention_mask))          # shape: (B, T, d_model)\n",
    "        y = self.dropout1(y, training=training)\n",
    "        x = x + y                                    # residual\n",
    "\n",
    "        # FFN sublayer\n",
    "        y = self.ln2(x)\n",
    "        y = self.ffn1(y)\n",
    "        y = self.ffn2(y)\n",
    "        y = self.dropout2(y, training=training)\n",
    "        x = x + y                                    # residual\n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape is typically (batch_size, seq_len, d_model)\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"d_model\": self.d_model,\n",
    "            \"n_heads\": self.n_heads,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "            \"epsilon\": self.epsilon,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class GPT(keras.Model):\n",
    "    '''\n",
    "    GPT model with N distinct blocks\n",
    "      -----------------------------------'''\n",
    "    def __init__(self,\n",
    "                 d_model: int = 128,\n",
    "                 vocab_size: int = 94,\n",
    "                 context_length: int = 512,\n",
    "                 attention_heads: int = 8,\n",
    "                 epsilon: float = 1e-5,\n",
    "                 decoder_blocks: int = 3,\n",
    "                 dropout_rate: float = 0.1,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._d_model = d_model\n",
    "        self._vocab_size = vocab_size\n",
    "        self._context_length = context_length\n",
    "        self._attention_heads = attention_heads\n",
    "        self._epsilon = epsilon\n",
    "        self._decoder_blocks = decoder_blocks\n",
    "        self._dropout_rate = dropout_rate\n",
    "\n",
    "        # embeddings (yours)\n",
    "        self.emb = InitializePositionalEmbeddings(\n",
    "            d_model, vocab_size,context_length,name=\"init_embeddings\"\n",
    "        )\n",
    "\n",
    "        # stack of distinct decoder blocks\n",
    "        self.blocks = [\n",
    "            DecoderBlock(d_model, attention_heads, dropout_rate, epsilon, name=f\"decoder_block_{i}\")\n",
    "            for i in range(decoder_blocks)\n",
    "        ]\n",
    "\n",
    "        # final norm (GPT-2 style) and LM head\n",
    "        self.final_ln = LayerNormalization(epsilon)\n",
    "        self.lm_head = keras.layers.Dense(vocab_size, name=\"Model_head\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        inputs: (token_ids, attention_mask)\n",
    "          - token_ids: int32 (B, T)\n",
    "          - attention_mask: int32/float32 mask broadcasting to attention logits.\n",
    "            Common shapes: (B, 1, 1, T) or (B, T) if your SelfAttentionLayer handles expansion.\n",
    "        \"\"\"\n",
    "        token_ids, attention_mask = inputs\n",
    "        x = self.emb(token_ids)                         # (B, T, d_model)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attention_mask, training=training)\n",
    "\n",
    "        x = self.final_ln(x)\n",
    "        logits = self.lm_head(x)                        # (B, T, vocab_size)\n",
    "        return logits                                   # keep softmax outside\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\n",
    "            \"d_model\": self._d_model,\n",
    "            \"vocab_size\": self._vocab_size,\n",
    "            \"context_length\": self._context_length,\n",
    "            \"attention_heads\": self._attention_heads,\n",
    "            \"epsilon\": self._epsilon,\n",
    "            \"decoder_blocks\": self._decoder_blocks,\n",
    "            \"dropout_rate\": self._dropout_rate,\n",
    "        })\n",
    "        return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd143548",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LEN = 128\n",
    "VOCAB_SIZE = len(token_to_id_dict) # 94 currently char level\n",
    "\n",
    "batch_text = ['yo','Akshat Khatri', 'Hello World','Me']\n",
    "token_ids,attention_mask = tokenize_and_build_token_id(token_to_id_dict,batch_text,CONTEXT_LEN) # type: ignore # Unpacking Values\n",
    "sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL,CONTEXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3d639c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(4, 128), dtype=int32, numpy=\n",
       " array([[36, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 22, 30, 19, 12, 31,  1,  0, 19, 12, 31, 29, 20,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 16, 23, 23, 26,  1,  0, 26, 29, 23, 15,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "       dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=int32)>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token_ids,attention_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f0db5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class CosineDecayWithWarmup(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, \n",
    "                 warmup_steps: int,\n",
    "                 total_steps: int,\n",
    "                 peak_learning_rate: float = 1e-4,\n",
    "                 min_learning_rate: float = 1e-6,\n",
    "                 name: str = \"cosine_decay_with_warmup\"):\n",
    "        super().__init__()\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.peak_learning_rate = peak_learning_rate\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.name = name\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        total_steps = tf.cast(self.total_steps, tf.float32)\n",
    "        \n",
    "        # Warmup phase: linear increase from 0 to peak_learning_rate\n",
    "        warmup_lr = self.peak_learning_rate * step / warmup_steps\n",
    "        \n",
    "        # Cosine decay phase\n",
    "        decay_steps = total_steps - warmup_steps\n",
    "        cosine_decay_lr = self.min_learning_rate + 0.5 * (\n",
    "            self.peak_learning_rate - self.min_learning_rate\n",
    "        ) * (1 + tf.cos(np.pi * (step - warmup_steps) / decay_steps))\n",
    "        \n",
    "        return tf.where(step < warmup_steps, warmup_lr, cosine_decay_lr)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"peak_learning_rate\": self.peak_learning_rate,\n",
    "            \"min_learning_rate\": self.min_learning_rate,\n",
    "            \"name\": self.name,\n",
    "        }\n",
    "\n",
    "# Example usage for your model\n",
    "# Estimate your training parameters\n",
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCH = 1000  # Adjust based on your dataset size and batch size\n",
    "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "WARMUP_STEPS = int(0.1 * TOTAL_STEPS)  # 10% warmup\n",
    "\n",
    "# Create the learning rate schedule\n",
    "lr_schedule = CosineDecayWithWarmup(\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    total_steps=TOTAL_STEPS,\n",
    "    peak_learning_rate=1e-4,  # Your desired peak learning rate\n",
    "    min_learning_rate=1e-6    # Minimum learning rate at the end\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d45b6a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ init_embeddings                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InitializePositionalEmbedding…</span> │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ layer_normalization_9      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ layer_normalization_10     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ self_attention_layer_3     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionLayer</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_11          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Model_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,470</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ init_embeddings                 │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "│ (\u001b[38;5;33mInitializePositionalEmbedding…\u001b[0m │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │        \u001b[38;5;34m49,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ layer_normalization_9      │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ layer_normalization_10     │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ self_attention_layer_3     │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │        \u001b[38;5;34m16,384\u001b[0m │\n",
       "│ (\u001b[38;5;33mSelfAttentionLayer\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_11          │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Model_head (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m38\u001b[0m)           │         \u001b[38;5;34m2,470\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build once to get .summary()\n",
    "DECODER_BLOCKS = 1\n",
    "ATTENTION_HEADS = 2\n",
    "\n",
    "GPT_model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,ATTENTION_HEADS,0.00001,DECODER_BLOCKS,0.3)\n",
    "_ = GPT_model((token_ids, attention_mask))\n",
    "GPT_model.summary(expand_nested=True)\n",
    "\n",
    "# training (stable): use logits\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-4, clipnorm=1.0)\n",
    "GPT_model.compile(optimizer=opt, loss=loss) # type: ignore\n",
    "\n",
    "# inference probs (when you actually need them)\n",
    "logits = GPT_model((token_ids, attention_mask), training=False)\n",
    "probs = keras.ops.softmax(logits, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc4eb0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 128, 38), dtype=float32, numpy=\n",
       "array([[[0.02427419, 0.00844106, 0.00674337, ..., 0.00477125,\n",
       "         0.02076543, 0.00828871],\n",
       "        [0.01316042, 0.0116842 , 0.00589607, ..., 0.00569568,\n",
       "         0.04424641, 0.01368236],\n",
       "        [0.01662502, 0.01813557, 0.00597432, ..., 0.01042927,\n",
       "         0.053636  , 0.01544004],\n",
       "        ...,\n",
       "        [0.01592959, 0.00297815, 0.00141975, ..., 0.00922529,\n",
       "         0.01749071, 0.00075334],\n",
       "        [0.00800081, 0.00451244, 0.00180551, ..., 0.01019324,\n",
       "         0.03020593, 0.00132201],\n",
       "        [0.00445642, 0.00955095, 0.00237412, ..., 0.00923473,\n",
       "         0.02976992, 0.00165074]],\n",
       "\n",
       "       [[0.02280555, 0.00861939, 0.00657079, ..., 0.00410576,\n",
       "         0.0271038 , 0.00749166],\n",
       "        [0.02359629, 0.01746042, 0.00732253, ..., 0.00576877,\n",
       "         0.03419791, 0.01191207],\n",
       "        [0.0168638 , 0.01274324, 0.00576653, ..., 0.00823772,\n",
       "         0.03976739, 0.01743495],\n",
       "        ...,\n",
       "        [0.01608564, 0.00302242, 0.00141322, ..., 0.00919705,\n",
       "         0.01782246, 0.00076548],\n",
       "        [0.00800666, 0.00457291, 0.00182889, ..., 0.01020666,\n",
       "         0.03018394, 0.00133081],\n",
       "        [0.00441568, 0.00954782, 0.00238026, ..., 0.00927593,\n",
       "         0.02962051, 0.00164141]],\n",
       "\n",
       "       [[0.02244888, 0.00876269, 0.0064248 , ..., 0.00408475,\n",
       "         0.02727075, 0.00747057],\n",
       "        [0.01679682, 0.01457764, 0.00592453, ..., 0.00658551,\n",
       "         0.03336759, 0.01314574],\n",
       "        [0.02148086, 0.01747933, 0.00662308, ..., 0.01212373,\n",
       "         0.02792542, 0.0178262 ],\n",
       "        ...,\n",
       "        [0.01599921, 0.0030007 , 0.0014198 , ..., 0.00928531,\n",
       "         0.01760137, 0.00076697],\n",
       "        [0.00811842, 0.00446541, 0.00184778, ..., 0.01016731,\n",
       "         0.02988618, 0.0013086 ],\n",
       "        [0.00440186, 0.00954029, 0.00236804, ..., 0.00920528,\n",
       "         0.03001476, 0.00167873]],\n",
       "\n",
       "       [[0.02265203, 0.00860163, 0.00646129, ..., 0.0040876 ,\n",
       "         0.02726906, 0.00754818],\n",
       "        [0.01679682, 0.01457764, 0.00592453, ..., 0.00658551,\n",
       "         0.03336759, 0.01314574],\n",
       "        [0.01671545, 0.01821531, 0.0059901 , ..., 0.01025133,\n",
       "         0.05400727, 0.0154018 ],\n",
       "        ...,\n",
       "        [0.01602126, 0.00302611, 0.00142294, ..., 0.00929061,\n",
       "         0.01758417, 0.00076612],\n",
       "        [0.00802423, 0.00452438, 0.00182878, ..., 0.01009993,\n",
       "         0.03004754, 0.00133522],\n",
       "        [0.00449873, 0.00954755, 0.00242224, ..., 0.00919302,\n",
       "         0.03017655, 0.00166743]]], shape=(4, 128, 38), dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81260874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 128, 38), dtype=float32, numpy=\n",
       "array([[[0.02427419, 0.00844106, 0.00674337, ..., 0.00477125,\n",
       "         0.02076543, 0.00828871],\n",
       "        [0.01441236, 0.01237122, 0.00629917, ..., 0.00738545,\n",
       "         0.03824622, 0.01349361],\n",
       "        [0.01685621, 0.01774202, 0.00600358, ..., 0.01018341,\n",
       "         0.05421719, 0.01545428],\n",
       "        ...,\n",
       "        [0.01615363, 0.00298077, 0.00143518, ..., 0.00926499,\n",
       "         0.01752654, 0.00076801],\n",
       "        [0.00801641, 0.00454536, 0.0018517 , ..., 0.01021357,\n",
       "         0.03007269, 0.00131147],\n",
       "        [0.00438085, 0.00967935, 0.00237462, ..., 0.0092137 ,\n",
       "         0.02995286, 0.00165967]],\n",
       "\n",
       "       [[0.02249563, 0.00874352, 0.00658948, ..., 0.00411398,\n",
       "         0.02734506, 0.00754081],\n",
       "        [0.01726262, 0.01583331, 0.00718337, ..., 0.00666552,\n",
       "         0.03666238, 0.01243987],\n",
       "        [0.01815676, 0.01363678, 0.00625158, ..., 0.01019126,\n",
       "         0.03491739, 0.01655457],\n",
       "        ...,\n",
       "        [0.01618759, 0.0029579 , 0.00143069, ..., 0.00914862,\n",
       "         0.01738329, 0.00076457],\n",
       "        [0.00802889, 0.00449368, 0.00183823, ..., 0.01016657,\n",
       "         0.02956688, 0.00129277],\n",
       "        [0.00436429, 0.00966537, 0.00236888, ..., 0.00926637,\n",
       "         0.02995704, 0.00165211]],\n",
       "\n",
       "       [[0.02248992, 0.00874272, 0.00649097, ..., 0.00407364,\n",
       "         0.02750942, 0.00746216],\n",
       "        [0.01449085, 0.01297158, 0.00482352, ..., 0.00382547,\n",
       "         0.04856883, 0.01308829],\n",
       "        [0.02148086, 0.01747933, 0.00662308, ..., 0.01212373,\n",
       "         0.02792542, 0.0178262 ],\n",
       "        ...,\n",
       "        [0.01618705, 0.00294865, 0.00140628, ..., 0.0091581 ,\n",
       "         0.01751784, 0.00076448],\n",
       "        [0.00804455, 0.00453536, 0.00184362, ..., 0.01015037,\n",
       "         0.03003075, 0.00131762],\n",
       "        [0.00439142, 0.00969619, 0.00235233, ..., 0.00928757,\n",
       "         0.02999088, 0.00165266]],\n",
       "\n",
       "       [[0.02244378, 0.00881029, 0.00636801, ..., 0.00403745,\n",
       "         0.02753555, 0.00751321],\n",
       "        [0.02114603, 0.01512023, 0.00596836, ..., 0.00572949,\n",
       "         0.03189167, 0.01263926],\n",
       "        [0.01672052, 0.01809613, 0.00595886, ..., 0.01037397,\n",
       "         0.0548842 , 0.01535218],\n",
       "        ...,\n",
       "        [0.01618698, 0.00301383, 0.00140994, ..., 0.00920277,\n",
       "         0.01754086, 0.00076201],\n",
       "        [0.00790861, 0.00458742, 0.00182   , ..., 0.01020947,\n",
       "         0.03027489, 0.00132108],\n",
       "        [0.00439696, 0.00955593, 0.0023744 , ..., 0.00929537,\n",
       "         0.03006582, 0.00166343]]], shape=(4, 128, 38), dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = GPT_model((token_ids, attention_mask))\n",
    "probs = tf.nn.softmax(outputs, axis=-1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72ebf9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ init_embeddings                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InitializePositionalEmbedding…</span> │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_11          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Model_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,470</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ init_embeddings                 │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "│ (\u001b[38;5;33mInitializePositionalEmbedding…\u001b[0m │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │        \u001b[38;5;34m49,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_11          │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Model_head (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m38\u001b[0m)           │         \u001b[38;5;34m2,470\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80e575a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved diagram to gpt_model.png\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "try:\n",
    "    plot_model(\n",
    "        GPT_model,\n",
    "        to_file=\"gpt_model.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        expand_nested=True,\n",
    "        dpi=160\n",
    "    )\n",
    "    print(\"Saved diagram to gpt_model.png\")\n",
    "except Exception as e:\n",
    "    print(\"plot_model failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fdd9c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InitializePositionalEmbeddings name=init_embeddings, built=True>,\n",
       " <DecoderBlock name=decoder_block_0, built=True>,\n",
       " <LayerNormalization name=layer_normalization_11, built=True>,\n",
       " <Dense name=Model_head, built=True>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe5fecf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54758"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7809a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                               GPT MODEL SUMMARY                                \n",
      "================================================================================\n",
      "Total parameters:      54,758\n",
      "Total layers:          4\n",
      "Trainable weights:     17\n",
      "Final output shape(s): ['(unavailable)']\n",
      "--------------------------------------------------------------------------------\n",
      "Idx | Layer Type               | Layer Name              | Weight Name                  | Shape           |   Params\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "000 | InitializePositionalEmbeddings | init_embeddings         | embedding_matrix             | (38, 64)        |    2,432\n",
      "001 | DecoderBlock             | decoder_block_0         | alpha                        | (64,)           |       64\n",
      "    |                          |                         | beta                         | (64,)           |       64\n",
      "    |                          |                         | alpha                        | (64,)           |       64\n",
      "    |                          |                         | beta                         | (64,)           |       64\n",
      "    |                          |                         | Query_Vector_for_projection  | (64, 64)        |    4,096\n",
      "    |                          |                         | Key_Vector_for_projection    | (64, 64)        |    4,096\n",
      "    |                          |                         | Value_Vector_for_projection  | (64, 64)        |    4,096\n",
      "    |                          |                         | Output_projection            | (64, 64)        |    4,096\n",
      "    |                          |                         | kernel                       | (64, 256)       |   16,384\n",
      "    |                          |                         | bias                         | (256,)          |      256\n",
      "    |                          |                         | kernel                       | (256, 64)       |   16,384\n",
      "    |                          |                         | bias                         | (64,)           |       64\n",
      "    |                          |                         |                              |                 |         \n",
      "002 | LayerNormalization       | layer_normalization_11  | alpha                        | (64,)           |       64\n",
      "    |                          |                         | beta                         | (64,)           |       64\n",
      "    |                          |                         |                              |                 |         \n",
      "003 | Dense                    | Model_head              | kernel                       | (64, 38)        |    2,432\n",
      "    |                          |                         | bias                         | (38,)           |       38\n",
      "    |                          |                         |                              |                 |         \n",
      "================================================================================\n",
      "Note: Only trainable weights are listed above. Output shapes may be unavailable\n",
      "for subclassed models or models not built symbolically.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def format_model_summary(model):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'GPT MODEL SUMMARY':^80}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_params = model.count_params()\n",
    "    total_layers = len(model.layers)\n",
    "    total_weights = sum(len(layer.trainable_weights) for layer in model.layers)\n",
    "    try:\n",
    "        output_shapes = [tuple(out.shape) for out in model.outputs]\n",
    "    except Exception:\n",
    "        output_shapes = [\"(unavailable)\"]\n",
    "    \n",
    "    print(f\"{'Total parameters:':<22} {total_params:,}\")\n",
    "    print(f\"{'Total layers:':<22} {total_layers}\")\n",
    "    print(f\"{'Trainable weights:':<22} {total_weights}\")\n",
    "    print(f\"{'Final output shape(s):':<22} {output_shapes if output_shapes else '(N/A)'}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    header = f\"{'Idx':>3} | {'Layer Type':<24} | {'Layer Name':<23} | {'Weight Name':<28} | {'Shape':<15} | {'Params':>8}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    \n",
    "    for i, layer in enumerate(model.layers):\n",
    "        layer_type = layer.__class__.__name__\n",
    "        layer_name = layer.name\n",
    "        weights = layer.trainable_weights\n",
    "        layer_weight_count = len(weights)\n",
    "\n",
    "        if layer_weight_count == 0:\n",
    "            print(f\"{i:03} | {layer_type:<24} | {layer_name:<23} | {'-':<28} | {'-':<15} | {'0':>8}\")\n",
    "        else:\n",
    "            for j, w in enumerate(weights):\n",
    "                n = int(np.prod(w.shape)) if hasattr(w, \"shape\") else \"?\"\n",
    "                shape_str = str(tuple(w.shape))\n",
    "                weight_name = w.name\n",
    "                if j == 0:\n",
    "                    print(f\"{i:03} | {layer_type:<24} | {layer_name:<23} | {weight_name:<28} | {shape_str:<15} | {n:>8,}\")\n",
    "                else:\n",
    "                    print(f\"    | {'':<24} | {'':<23} | {weight_name:<28} | {shape_str:<15} | {n:>8,}\")\n",
    "        if layer_weight_count > 1:\n",
    "            print(f\"    | {'':<24} | {'':<23} | {'':<28} | {'':<15} | {'':>8}\")\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"Note: Only trainable weights are listed above. Output shapes may be unavailable\\n\"\n",
    "          \"for subclassed models or models not built symbolically.\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Usage:\n",
    "format_model_summary(GPT_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2ab03dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_book_training_data(book_text: str, \n",
    "#                              token_to_id_dict: Dict[str, int], \n",
    "#                              context_length: int = 512,\n",
    "#                              pad_value: int = 0):\n",
    "#     \"\"\"\n",
    "#     Prepare training data from a Gutenberg book\n",
    "#     \"\"\"\n",
    "#     # 1. Tokenize the entire book\n",
    "#     token_ids = [token_to_id_dict.get(c, pad_value) for c in book_text]\n",
    "    \n",
    "#     # 2. Create sliding windows\n",
    "#     inputs = []\n",
    "#     targets = []\n",
    "    \n",
    "#     # Slide window across the entire book\n",
    "#     for i in range(0, len(token_ids) - context_length, context_length):\n",
    "#         # Extract window of context_length + 1 tokens\n",
    "#         window = token_ids[i:i + context_length + 1]\n",
    "        \n",
    "#         if len(window) < context_length + 1:\n",
    "#             break  # Skip incomplete windows at the end\n",
    "        \n",
    "#         # Create input-target pair\n",
    "#         input_seq = window[:-1]   # [t1, t2, ..., t512]\n",
    "#         target_seq = window[1:]   # [t2, t3, ..., t513]\n",
    "        \n",
    "#         inputs.append(input_seq)\n",
    "#         targets.append(target_seq)\n",
    "    \n",
    "#     # 3. Convert to numpy arrays\n",
    "#     inputs = np.array(inputs, dtype=np.int32)\n",
    "#     targets = np.array(targets, dtype=np.int32)\n",
    "    \n",
    "#     # 4. Create padding masks (all 1s since we're using full context)\n",
    "#     masks = np.ones_like(inputs, dtype=np.int32)\n",
    "    \n",
    "#     return inputs, targets, masks\n",
    "\n",
    "# # Usage:\n",
    "# with open(r'/home/akshat/GPT_from_scratch/text_data/pg76702.txt', 'r', encoding='utf-8') as f:\n",
    "#     book_text = f.read()\n",
    "\n",
    "# inputs, targets, masks = prepare_book_training_data(\n",
    "#     book_text, \n",
    "#     token_to_id_dict, \n",
    "#     context_length=512\n",
    "# )\n",
    "\n",
    "# print(f\"Created {len(inputs)} training examples\")\n",
    "# print(f\"Input shape: {inputs.shape}\")\n",
    "# print(f\"Target shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ea8b1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'/home/akshat/GPT_from_scratch/text_data/pg76702.txt', 'r') as f:\n",
    "#     book_text = f.read()\n",
    "\n",
    "# print(f\"Total characters: {len(book_text)}\")\n",
    "# print(f\"Expected examples (rough): {len(book_text) // 512}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fc7c7",
   "metadata": {},
   "source": [
    "''' Stop '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "649d5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to TensorFlow tensors\n",
    "# input_ids = tf.constant(inputs, dtype=tf.int32)\n",
    "# target_ids = tf.constant(targets, dtype=tf.int32)\n",
    "# attention_masks = tf.constant(masks, dtype=tf.int32)\n",
    "\n",
    "# model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,8,0.00001,4,0.1,sinusoidal_lookup_table)\n",
    "\n",
    "# # Compile your model\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.AdamW(learning_rate=1e-4), # type: ignore\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # Train with .fit()\n",
    "# history = model.fit(\n",
    "#     x=[input_ids, ,  # Your model expects (token_ids, attention_mask)\n",
    "#     y=target_ids,\n",
    "#     batch_size=16,  # Start small since 677 examples isn't huge\n",
    "#     epochs=50,\n",
    "#     validation_split=0.1,  # Use 10% for validation\n",
    "#     callbacks=[\n",
    "#         keras.callbacks.ModelCheckpoint('best_model.keras', save_best_only=True),\n",
    "#         keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "#         keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e775cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text(model, start_text, token_to_id, id_to_token, max_len=100, temperature=1.0):\n",
    "#     # Encode start text\n",
    "#     token_ids, attention_mask = tokenize_and_build_token_id(\n",
    "#         token_to_id, [start_text], max_seq_len=512\n",
    "#     )\n",
    "    \n",
    "#     generated = list(token_ids[0].numpy())  # flatten out\n",
    "#     mask = list(attention_mask[0].numpy())\n",
    "    \n",
    "#     for _ in range(max_len):\n",
    "#         # Trim to last 512 tokens\n",
    "#         x_tokens = np.array([generated[-512:]])\n",
    "#         x_mask   = np.array([mask[-512:]])\n",
    "\n",
    "#         # Forward pass with both inputs\n",
    "#         logits = model((x_tokens, x_mask), training=False)\n",
    "\n",
    "#         # Take last position logits\n",
    "#         next_logits = logits[0, -1] / temperature\n",
    "#         probs = tf.nn.softmax(next_logits).numpy()\n",
    "\n",
    "#         # Sample next token\n",
    "#         next_id = np.random.choice(len(probs), p=probs)\n",
    "\n",
    "#         # Append\n",
    "#         generated.append(next_id)\n",
    "#         mask.append(1)  # mark as valid token\n",
    "\n",
    "#     # Decode\n",
    "#     return ''.join(id_to_token[i] for i in generated if i in id_to_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d50c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_token_dict = {v: k for k, v in token_to_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "43978b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = \"Akshat Khatri\"\n",
    "# result = generate_text(model, start, token_to_id_dict, id_to_token_dict, max_len=100, temperature=0.8)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94cf8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset('wikitext', 'wikitext-103-v1')# Concatenate train + validation + test\n",
    "# all_texts = []\n",
    "# for split in [\"train\", \"validation\", \"test\"]:\n",
    "#     all_texts.extend(dataset[split][\"text\"])\n",
    "\n",
    "# # Remove empty lines\n",
    "# all_texts = [t.strip() for t in all_texts if t.strip() != \"\"]\n",
    "\n",
    "# # Join into one giant string\n",
    "# big_text = \"\\n\".join(all_texts)\n",
    "\n",
    "# # Write to file\n",
    "# with open(\"wikitext_full.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(big_text)\n",
    "\n",
    "# print(\"Saved dataset to wikitext_full.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c759f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, targets, masks = prepare_book_training_data(\n",
    "#     book_text, \n",
    "#     token_to_id_dict, \n",
    "#     context_length=512\n",
    "# )\n",
    "\n",
    "# print(f\"Created {len(inputs)} training examples\")\n",
    "# print(f\"Input shape: {inputs.shape}\")\n",
    "# print(f\"Target shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d5f51f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Assuming you already have:\n",
    "# # - prepare_book_training_data()\n",
    "# # - token_to_id_dict\n",
    "\n",
    "# file_path = r\"/home/akshat/GPT_from_scratch/text_data/wikitext_full.txt\"\n",
    "\n",
    "# inputs_list, targets_list, masks_list = [], [], []\n",
    "\n",
    "# buffer = \"\"\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     for line in f:\n",
    "#         buffer += line.strip() + \" \"\n",
    "#         # Process every ~5000 chars to avoid memory spike\n",
    "#         if len(buffer) > 5000:\n",
    "#             inp, tgt, msk = prepare_book_training_data(\n",
    "#                 buffer, token_to_id_dict, context_length=512\n",
    "#             )\n",
    "#             inputs_list.append(inp)\n",
    "#             targets_list.append(tgt)\n",
    "#             masks_list.append(msk)\n",
    "#             buffer = \"\"  # reset buffer\n",
    "\n",
    "# # Process any leftover buffer\n",
    "# if buffer.strip():\n",
    "#     inp, tgt, msk = prepare_book_training_data(\n",
    "#         buffer, token_to_id_dict, context_length=512\n",
    "#     )\n",
    "#     inputs_list.append(inp)\n",
    "#     targets_list.append(tgt)\n",
    "#     masks_list.append(msk)\n",
    "\n",
    "# # Concatenate all batches into final arrays\n",
    "# inputs = np.concatenate(inputs_list, axis=0)\n",
    "# targets = np.concatenate(targets_list, axis=0)\n",
    "# masks = np.concatenate(masks_list, axis=0)\n",
    "\n",
    "# print(f\"Created {len(inputs)} training examples\")\n",
    "# print(f\"Input shape: {inputs.shape}\")\n",
    "# print(f\"Target shape: {targets.shape}\")\n",
    "# print(f\"Masks shape: {masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "20b06fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_tf_example(input_ids: List[int], target_ids: List[int], attention_mask: List[int]) -> bytes:\n",
    "    \"\"\"\n",
    "    Create a serialized TFRecord example from input-target pair.\n",
    "    \n",
    "    Args:\n",
    "        input_ids: Token sequence for model input\n",
    "        target_ids: Token sequence for model targets (shifted by 1)\n",
    "        attention_mask: Mask for valid tokens (1) vs padding (0)\n",
    "        \n",
    "    Returns:\n",
    "        Serialized TFRecord example\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        'input_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=input_ids)),\n",
    "        'target_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=target_ids)),\n",
    "        'attention_mask': tf.train.Feature(int64_list=tf.train.Int64List(value=attention_mask))\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example.SerializeToString()\n",
    "\n",
    "\n",
    "def convert_text_to_tfrecord(\n",
    "    text_file_path: str,\n",
    "    token_to_id_dict: Dict[str, int],\n",
    "    output_dir: str,\n",
    "    context_length: int = 512,\n",
    "    records_per_file: int = 1000,\n",
    "    pad_value: int = 0\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert text file to TFRecord files for GPT training.\n",
    "    \n",
    "    Process:\n",
    "    1. Read and tokenize entire text file\n",
    "    2. Create sliding windows of context_length + 1 tokens\n",
    "    3. Split each window into input/target pairs (shifted by 1)\n",
    "    4. Save as TFRecord files with specified number of records per file\n",
    "    \n",
    "    Args:\n",
    "        text_file_path: Path to your text file (e.g., WikiText-103)\n",
    "        token_to_id_dict: Character-to-ID mapping dictionary\n",
    "        output_dir: Directory to save TFRecord files\n",
    "        context_length: Sequence length for training\n",
    "        records_per_file: Number of examples per TFRecord file\n",
    "        pad_value: Token ID used for unknown characters\n",
    "        \n",
    "    Returns:\n",
    "        Path to output directory containing TFRecord files\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Reading text file: {text_file_path}\")\n",
    "    \n",
    "    # Step 1: Load and tokenize text\n",
    "    with open(text_file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    print(f\"Text length: {len(text):,} characters\")\n",
    "    \n",
    "    # Convert each character to token ID\n",
    "    print(\"Tokenizing text...\")\n",
    "    token_ids = [token_to_id_dict.get(char, pad_value) for char in text]\n",
    "    print(f\"Token length: {len(token_ids):,} tokens\")\n",
    "    \n",
    "    # Step 2: Calculate output size\n",
    "    num_examples = (len(token_ids) - context_length) // context_length\n",
    "    print(f\"Will create {num_examples:,} training examples\")\n",
    "    \n",
    "    # Step 3: Process sliding windows and write TFRecord files\n",
    "    file_count = 0\n",
    "    examples_in_current_file = 0\n",
    "    writer = None\n",
    "    \n",
    "    print(\"Creating TFRecord files...\")\n",
    "    \n",
    "    # Slide window across token sequence\n",
    "    for i in tqdm(range(0, len(token_ids) - context_length, context_length)):\n",
    "        \n",
    "        # Extract window of tokens\n",
    "        window = token_ids[i:i + context_length + 1]\n",
    "        if len(window) < context_length + 1:\n",
    "            break\n",
    "            \n",
    "        # Create input-target pair (GPT training format)\n",
    "        input_ids = window[:-1]    # First 512 tokens: [t1, t2, ..., t512]\n",
    "        target_ids = window[1:]    # Shifted by 1: [t2, t3, ..., t513]\n",
    "        attention_mask = [1] * context_length  # All valid tokens (no padding)\n",
    "        \n",
    "        # Start new TFRecord file if needed\n",
    "        if writer is None or examples_in_current_file >= records_per_file:\n",
    "            if writer is not None:\n",
    "                writer.close()\n",
    "            \n",
    "            tfrecord_filename = os.path.join(output_dir, f'train_{file_count:04d}.tfrecord')\n",
    "            writer = tf.io.TFRecordWriter(tfrecord_filename)\n",
    "            file_count += 1\n",
    "            examples_in_current_file = 0\n",
    "        \n",
    "        # Write training example to current TFRecord file\n",
    "        tf_example = create_tf_example(input_ids, target_ids, attention_mask)\n",
    "        writer.write(tf_example)\n",
    "        examples_in_current_file += 1\n",
    "    \n",
    "    # Cleanup\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "    \n",
    "    # Step 4: Save summary information\n",
    "    print(f\"\\nConversion complete!\")\n",
    "    print(f\"Created {file_count} TFRecord files in: {output_dir}\")\n",
    "    print(f\"Total examples: {num_examples:,}\")\n",
    "    \n",
    "    # Write metadata file\n",
    "    metadata = {\n",
    "        'context_length': context_length,\n",
    "        'vocab_size': len(token_to_id_dict),\n",
    "        'num_examples': num_examples,\n",
    "        'num_files': file_count,\n",
    "        'records_per_file': records_per_file\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(output_dir, 'metadata.txt')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        for key, value in metadata.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "\n",
    "def create_tf_data_pipeline(\n",
    "    tfrecord_dir: str,\n",
    "    context_length: int = 512,\n",
    "    batch_size: int = 32,\n",
    "    shuffle_buffer: int = 1000,\n",
    "    prefetch_buffer: int = tf.data.AUTOTUNE\n",
    ") -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Create tf.data pipeline from TFRecord files for training.\n",
    "    \n",
    "    Process:\n",
    "    1. Find all TFRecord files in directory\n",
    "    2. Create dataset that reads and parses TFRecord examples\n",
    "    3. Apply shuffling, batching, and prefetching for efficient training\n",
    "    \n",
    "    Args:\n",
    "        tfrecord_dir: Directory containing TFRecord files\n",
    "        context_length: Expected sequence length in records\n",
    "        batch_size: Number of examples per training batch\n",
    "        shuffle_buffer: Size of shuffle buffer (larger = more random)\n",
    "        prefetch_buffer: Number of batches to prefetch (AUTOTUNE = automatic)\n",
    "        \n",
    "    Returns:\n",
    "        tf.data.Dataset ready for model.fit()\n",
    "    \"\"\"\n",
    "    # Step 1: Find TFRecord files\n",
    "    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "    print(f\"Found {len(tfrecord_files)} TFRecord files\")\n",
    "    \n",
    "    # Step 2: Define how to parse each TFRecord example\n",
    "    feature_description = {\n",
    "        'input_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'target_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'attention_mask': tf.io.FixedLenFeature([context_length], tf.int64)\n",
    "    }\n",
    "    \n",
    "    def parse_tfrecord_example(example_proto):\n",
    "        \"\"\"Parse a single TFRecord example into model inputs and targets.\"\"\"\n",
    "        # Parse the serialized example\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        \n",
    "        # Convert to correct data types\n",
    "        input_ids = tf.cast(parsed_features['input_ids'], tf.int32)\n",
    "        target_ids = tf.cast(parsed_features['target_ids'], tf.int32)\n",
    "        attention_mask = tf.cast(parsed_features['attention_mask'], tf.int32)\n",
    "        \n",
    "        # Return in format expected by your GPT model: ((input_ids, attention_mask), targets)\n",
    "        model_inputs = (input_ids, attention_mask)\n",
    "        model_targets = target_ids\n",
    "        \n",
    "        return model_inputs, model_targets\n",
    "    \n",
    "    # Step 3: Create and configure dataset pipeline\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    dataset = dataset.map(parse_tfrecord_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(prefetch_buffer)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Example usage (commented out)\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Example usage for WikiText-103 or similar large text files\n",
    "    \"\"\"\n",
    "    \n",
    "    # # Step 1: Define your vocabulary (replace with actual token_to_id_dict)\n",
    "    # example_vocab = your_token_to_id_dict\n",
    "    \n",
    "    # # Step 2: Convert text to TFRecord format (run once)\n",
    "    # tfrecord_dir = convert_text_to_tfrecord(\n",
    "    #     text_file_path=r'/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "    #     token_to_id_dict=example_vocab,\n",
    "    #     output_dir='./tfrecords',\n",
    "    #     context_length=512,\n",
    "    #     records_per_file=1000\n",
    "    # )\n",
    "    \n",
    "    # # Step 3: Create training pipeline (use for training)\n",
    "    # train_dataset = create_tf_data_pipeline(\n",
    "    #     tfrecord_dir=tfrecord_dir,\n",
    "    #     context_length=512,\n",
    "    #     batch_size=16\n",
    "    # )\n",
    "    \n",
    "    # print(\"TFRecord pipeline ready for training!\")\n",
    "    # # Now you can use train_dataset with your model's .fit() method\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "253d99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Define your vocabulary (replace with actual token_to_id_dict)\n",
    "# example_vocab = token_to_id_dict\n",
    "\n",
    "# # Step 2: Convert text to TFRecord format (run once)\n",
    "# tfrecord_dir = convert_text_to_tfrecord(\n",
    "#     text_file_path=r'/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=example_vocab,\n",
    "#     output_dir='./tfrecords',\n",
    "#     context_length=128,\n",
    "#     records_per_file=1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9caffa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create training and validation pipeline (use for training)\n",
    "def create_train_val_datasets(tfrecord_dir: str, \n",
    "                             context_length: int,\n",
    "                             batch_size: int = 32,\n",
    "                             val_split: float = 0.1):\n",
    "    \"\"\"\n",
    "    Create training and validation datasets from TFRecord files\n",
    "    \"\"\"\n",
    "    # Find all TFRecord files\n",
    "    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "    print(f\"Found {len(tfrecord_files)} TFRecord files\")\n",
    "    \n",
    "    # Split files for train/val\n",
    "    num_val_files = max(1, int(len(tfrecord_files) * val_split))\n",
    "    val_files = tfrecord_files[:num_val_files]\n",
    "    train_files = tfrecord_files[num_val_files:]\n",
    "    \n",
    "    print(f\"Using {len(train_files)} files for training, {len(val_files)} for validation\")\n",
    "    \n",
    "    # Feature description\n",
    "    feature_description = {\n",
    "        'input_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'target_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'attention_mask': tf.io.FixedLenFeature([context_length], tf.int64)\n",
    "    }\n",
    "    \n",
    "    def parse_function(example_proto):\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        \n",
    "        input_ids = tf.cast(parsed_features['input_ids'], tf.int32)\n",
    "        target_ids = tf.cast(parsed_features['target_ids'], tf.int32)\n",
    "        attention_mask = tf.cast(parsed_features['attention_mask'], tf.int32)\n",
    "        \n",
    "        # Return in format your model expects: ([input_ids, attention_mask], targets)\n",
    "        return (input_ids, attention_mask), target_ids\n",
    "    \n",
    "    # Create training dataset\n",
    "    train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "    train_dataset = train_dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.shuffle(5000)  # Shuffle buffer\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Create validation dataset\n",
    "    val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "    val_dataset = val_dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a91e6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# def create_tf_example(input_ids: List[int], target_ids: List[int], attention_mask: List[int]) -> bytes:\n",
    "#     \"\"\"\n",
    "#     Create a serialized TFRecord example from input-target pair.\n",
    "    \n",
    "#     Args:\n",
    "#         input_ids: Token sequence for model input\n",
    "#         target_ids: Token sequence for model targets (shifted by 1)\n",
    "#         attention_mask: Mask for valid tokens (1) vs padding (0)\n",
    "        \n",
    "#     Returns:\n",
    "#         Serialized TFRecord example\n",
    "#     \"\"\"\n",
    "#     feature = {\n",
    "#         'input_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=input_ids)),\n",
    "#         'target_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=target_ids)),\n",
    "#         'attention_mask': tf.train.Feature(int64_list=tf.train.Int64List(value=attention_mask))\n",
    "#     }\n",
    "    \n",
    "#     example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "#     return example.SerializeToString()\n",
    "\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def convert_text_to_tfrecord_sp(\n",
    "#     text_file_path: str,\n",
    "#     sp_model_path: str,\n",
    "#     output_dir: str,\n",
    "#     context_length: int = 512,\n",
    "#     records_per_file: int = 1000,\n",
    "#     overlap_size: int = 64,\n",
    "#     chunk_size: int = 100_000  # Number of characters read at a time\n",
    "# ) -> str:\n",
    "#     \"\"\"\n",
    "#     Streaming version of text to TFRecord conversion with SentencePiece.\n",
    "#     Reads and tokenizes file incrementally to limit memory usage.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     file_size = os.path.getsize(text_file_path)\n",
    "#     print(f\"Reading and tokenizing text in chunks from: {text_file_path}\")\n",
    "    \n",
    "#     # Load SentencePiece processor\n",
    "#     sp = spm.SentencePieceProcessor()\n",
    "#     sp.load(sp_model_path)\n",
    "    \n",
    "#     print(f\"Loaded SentencePiece model from: {sp_model_path}\")\n",
    "#     print(f\"Vocabulary size: {sp.get_piece_size()}\")\n",
    "\n",
    "#     buffer_tokens = []\n",
    "#     step_size = context_length - overlap_size\n",
    "#     file_count = 0\n",
    "#     examples_in_current_file = 0\n",
    "#     writer = None\n",
    "    \n",
    "#     with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "#         with tqdm(total=file_size, unit='B', unit_scale=True, desc='Processing text') as pbar:\n",
    "#             while True:\n",
    "#                 chunk = file.read(chunk_size)\n",
    "#                 if not chunk:\n",
    "#                     break\n",
    "#                 buffer_tokens.extend(sp.encode_as_ids(chunk))\n",
    "#                 pbar.update(len(chunk.encode('utf-8')))  # update by bytes read\n",
    "                \n",
    "#                 # Process windows to create examples\n",
    "#                 while len(buffer_tokens) >= context_length + 1:\n",
    "#                     window = buffer_tokens[:context_length + 1]\n",
    "#                     input_ids = window[:-1]\n",
    "#                     target_ids = window[1:]\n",
    "#                     attention_mask = [1] * context_length\n",
    "                    \n",
    "#                     if writer is None or examples_in_current_file >= records_per_file:\n",
    "#                         if writer:\n",
    "#                             writer.close()\n",
    "#                         tfrecord_path = os.path.join(output_dir, f'train_{file_count:04d}.tfrecord')\n",
    "#                         writer = tf.io.TFRecordWriter(tfrecord_path)\n",
    "#                         file_count += 1\n",
    "#                         examples_in_current_file = 0\n",
    "                    \n",
    "#                     tf_example = create_tf_example(input_ids, target_ids, attention_mask)\n",
    "#                     writer.write(tf_example)\n",
    "#                     examples_in_current_file += 1\n",
    "                    \n",
    "#                     # Slide window forward by step_size tokens\n",
    "#                     buffer_tokens = buffer_tokens[step_size:]\n",
    "\n",
    "#     # Process any remaining tokens\n",
    "#     while len(buffer_tokens) >= context_length + 1:\n",
    "#         window = buffer_tokens[:context_length + 1]\n",
    "#         input_ids = window[:-1]\n",
    "#         target_ids = window[1:]\n",
    "#         attention_mask = [1] * context_length\n",
    "        \n",
    "#         if writer is None or examples_in_current_file >= records_per_file:\n",
    "#             if writer:\n",
    "#                 writer.close()\n",
    "#             tfrecord_path = os.path.join(output_dir, f'train_{file_count:04d}.tfrecord')\n",
    "#             writer = tf.io.TFRecordWriter(tfrecord_path)\n",
    "#             file_count += 1\n",
    "#             examples_in_current_file = 0\n",
    "\n",
    "#         tf_example = create_tf_example(input_ids, target_ids, attention_mask)\n",
    "#         writer.write(tf_example)\n",
    "#         examples_in_current_file += 1\n",
    "#         buffer_tokens = buffer_tokens[step_size:]\n",
    "\n",
    "#     if writer:\n",
    "#         writer.close()\n",
    "\n",
    "#     num_examples = file_count * records_per_file  # Approximate count\n",
    "\n",
    "#     print(f\"\\nConversion complete!\")\n",
    "#     print(f\"Created {file_count} TFRecord files in: {output_dir}\")\n",
    "#     print(f\"Approximate total examples: {num_examples}\")\n",
    "\n",
    "#     metadata = {\n",
    "#         'context_length': context_length,\n",
    "#         'vocab_size': sp.get_piece_size(),\n",
    "#         'num_examples': num_examples,\n",
    "#         'num_files': file_count,\n",
    "#         'records_per_file': records_per_file,\n",
    "#         'overlap_size': overlap_size,\n",
    "#         'sp_model_path': sp_model_path,\n",
    "#         'tokenization': 'SentencePiece'\n",
    "#     }\n",
    "\n",
    "#     metadata_path = os.path.join(output_dir, 'metadata.txt')\n",
    "#     with open(metadata_path, 'w') as f:\n",
    "#         for key, value in metadata.items():\n",
    "#             f.write(f\"{key}: {value}\\n\")\n",
    "#     print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "#     return output_dir\n",
    "\n",
    "\n",
    "\n",
    "# def create_tf_data_pipeline_sp(\n",
    "#     tfrecord_dir: str,\n",
    "#     context_length: int = 512,\n",
    "#     batch_size: int = 32,\n",
    "#     shuffle_buffer: int = 1000,\n",
    "#     prefetch_buffer: int = tf.data.AUTOTUNE\n",
    "# ) -> tf.data.Dataset:\n",
    "#     \"\"\"\n",
    "#     Create tf.data pipeline from TFRecord files for training (SentencePiece version).\n",
    "    \n",
    "#     Process:\n",
    "#     1. Find all TFRecord files in directory\n",
    "#     2. Create dataset that reads and parses TFRecord examples\n",
    "#     3. Apply shuffling, batching, and prefetching for efficient training\n",
    "    \n",
    "#     Args:\n",
    "#         tfrecord_dir: Directory containing TFRecord files\n",
    "#         context_length: Expected sequence length in records\n",
    "#         batch_size: Number of examples per training batch\n",
    "#         shuffle_buffer: Size of shuffle buffer (larger = more random)\n",
    "#         prefetch_buffer: Number of batches to prefetch (AUTOTUNE = automatic)\n",
    "        \n",
    "#     Returns:\n",
    "#         tf.data.Dataset ready for model.fit()\n",
    "#     \"\"\"\n",
    "#     # Step 1: Find TFRecord files\n",
    "#     tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "#     print(f\"Found {len(tfrecord_files)} TFRecord files\")\n",
    "    \n",
    "#     if not tfrecord_files:\n",
    "#         raise FileNotFoundError(f\"No TFRecord files found in {tfrecord_dir}\")\n",
    "    \n",
    "#     # Step 2: Define how to parse each TFRecord example\n",
    "#     feature_description = {\n",
    "#         'input_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "#         'target_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "#         'attention_mask': tf.io.FixedLenFeature([context_length], tf.int64)\n",
    "#     }\n",
    "    \n",
    "#     def parse_tfrecord_example(example_proto):\n",
    "#         \"\"\"Parse a single TFRecord example into model inputs and targets.\"\"\"\n",
    "#         # Parse the serialized example\n",
    "#         parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        \n",
    "#         # Convert to correct data types\n",
    "#         input_ids = tf.cast(parsed_features['input_ids'], tf.int32)\n",
    "#         target_ids = tf.cast(parsed_features['target_ids'], tf.int32)\n",
    "#         attention_mask = tf.cast(parsed_features['attention_mask'], tf.int32)\n",
    "        \n",
    "#         # Return in format expected by your GPT model: ((input_ids, attention_mask), targets)\n",
    "#         model_inputs = (input_ids, attention_mask)\n",
    "#         model_targets = target_ids\n",
    "        \n",
    "#         return model_inputs, model_targets\n",
    "    \n",
    "#     # Step 3: Create and configure dataset pipeline\n",
    "#     dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "#     dataset = dataset.map(parse_tfrecord_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     dataset = dataset.shuffle(shuffle_buffer)\n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     dataset = dataset.prefetch(prefetch_buffer)\n",
    "    \n",
    "#     return dataset\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     \"\"\"\n",
    "# #     Example usage assuming you have a pre-trained SentencePiece model\n",
    "# #     \"\"\"\n",
    "    \n",
    "# #     # Your pre-trained SentencePiece model path\n",
    "# #     sp_model_path = '/home/akshat/GPT_from_scratch/notebooks/spm_gpt.model'  # You provide this\n",
    "    \n",
    "# #     # Step 1: Convert text to TFRecords using your pre-trained model\n",
    "# #     tfrecord_dir = convert_text_to_tfrecord_sp(\n",
    "# #         text_file_path=r'/home/akshat/GPT_from_scratch/text_data/BookCorpus3_cleaned.txt',\n",
    "# #         sp_model_path=sp_model_path,  # Your trained model\n",
    "# #         output_dir='./tfrecords',\n",
    "# #         context_length=CONTEXT_LEN,  # Match your CONTEXT_LEN\n",
    "# #         records_per_file=1000,\n",
    "# #         overlap_size = CONTEXT_LEN // 2,\n",
    "# #         chunk_size = 150000\n",
    "# #     )\n",
    "    \n",
    "# #     # # Step 2: Create training pipeline\n",
    "# #     # train_dataset = create_tf_data_pipeline_sp(\n",
    "# #     #     tfrecord_dir=tfrecord_dir,\n",
    "# #     #     context_length=128,  # Match your CONTEXT_LEN\n",
    "# #     #     batch_size=16\n",
    "# #     # )\n",
    "    \n",
    "# #     print(\"SentencePiece TFRecord pipeline ready for training!\")\n",
    "    \n",
    "# #     # Step 3: Load your SentencePiece model for vocab size and generation\n",
    "# #     sp = spm.SentencePieceProcessor()\n",
    "# #     sp.load(sp_model_path)\n",
    "# #     VOCAB_SIZE = sp.get_piece_size()\n",
    "    \n",
    "# #     print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "    \n",
    "#     # Now you can use:\n",
    "#     # - sp for tokenization in generation\n",
    "#     # - train_dataset for model.fit()\n",
    "#     # - VOCAB_SIZE for your model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6ba0fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create DATASETS\n",
    "# train_dataset, val_dataset = create_train_val_datasets(\n",
    "#     tfrecord_dir='./tfrecords',\n",
    "#     context_length=CONTEXT_LEN,\n",
    "#     batch_size=16,\n",
    "#     val_split=0.1\n",
    "# )\n",
    "\n",
    "\n",
    "# print(\"TFRecord pipeline ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4819661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef29291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Remove existing tfrecords directory\n",
    "# if os.path.exists('./tfrecords'):\n",
    "#     shutil.rmtree('./tfrecords')\n",
    "#     print(\"Removed existing tfrecords directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd300a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9252ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SOLUTION 1: Recreate TFRecords with correct context length\n",
    "# # Delete the existing tfrecords directory and recreate with CONTEXT_LEN\n",
    "\n",
    "\n",
    "# # Recreate with correct context length\n",
    "# tfrecord_dir = convert_text_to_tfrecord(\n",
    "#     text_file_path=r'/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,  # Make sure this variable is defined\n",
    "#     output_dir='./tfrecords',\n",
    "#     context_length=CONTEXT_LEN,  # Use your actual context length (128)\n",
    "#     records_per_file=1000\n",
    "# )\n",
    "\n",
    "# # Now create datasets with matching context length\n",
    "# train_dataset, val_dataset = create_train_val_datasets(\n",
    "#     tfrecord_dir='./tfrecords',\n",
    "#     context_length=CONTEXT_LEN,  # This will now match\n",
    "#     batch_size=16,\n",
    "#     val_split=0.1\n",
    "# )\n",
    "\n",
    "# # Calculate steps per epoch\n",
    "# records_per_file = 1000  \n",
    "# tfrecord_files = tf.io.gfile.glob(os.path.join(\"./tfrecords\", \"*.tfrecord\"))\n",
    "# total_examples = len(tfrecord_files) * records_per_file\n",
    "# train_examples = int(total_examples * 0.9)\n",
    "# steps_per_epoch = train_examples // 16\n",
    "\n",
    "# print(f\"Files: {len(tfrecord_files)}\")\n",
    "# print(f\"Total examples: {total_examples}\")\n",
    "# print(f\"Steps per epoch: {steps_per_epoch}\") # When combined with batch_size sees the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5a189899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def prepare_tfrecords(\n",
    "    text_file_path: str,\n",
    "    token_to_id_dict: dict,\n",
    "    context_length: int = 128,\n",
    "    records_per_file: int = 1000,\n",
    "    output_base_dir: str = './tfrecords',\n",
    "    version_name: str = None,\n",
    "    batch_size: int = 16,\n",
    "    val_split: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Create TFRecords from text and return train/val datasets.\n",
    "    Stores TFRecords in a versioned folder to avoid overwriting previous ones.\n",
    "\n",
    "    Args:\n",
    "        text_file_path: Path to input text file.\n",
    "        token_to_id_dict: Character-to-id dictionary.\n",
    "        context_length: Sequence length for training.\n",
    "        records_per_file: Number of examples per TFRecord file.\n",
    "        output_base_dir: Base folder to store TFRecords.\n",
    "        version_name: Optional unique folder name. If None, uses context_length.\n",
    "        batch_size: Batch size for dataset.\n",
    "        val_split: Fraction of data to use as validation.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset, val_dataset, steps_per_epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine output folder\n",
    "    if version_name is None:\n",
    "        version_name = f\"context_{context_length}_bs{batch_size}\"\n",
    "    output_dir = os.path.join(output_base_dir, version_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Convert text to TFRecords\n",
    "    tfrecord_dir = convert_text_to_tfrecord(\n",
    "        text_file_path=text_file_path,\n",
    "        token_to_id_dict=token_to_id_dict,\n",
    "        output_dir=output_dir,\n",
    "        context_length=context_length,\n",
    "        records_per_file=records_per_file\n",
    "    )\n",
    "\n",
    "    # Create train/val datasets\n",
    "    train_dataset, val_dataset = create_train_val_datasets(\n",
    "        tfrecord_dir=tfrecord_dir,\n",
    "        context_length=context_length,\n",
    "        batch_size=batch_size,\n",
    "        val_split=val_split\n",
    "    )\n",
    "    def count_tfrecord_examples(tfrecord_files):\n",
    "        count = 0\n",
    "        for tfrecord_file in tfrecord_files:\n",
    "            for _ in tf.data.TFRecordDataset(tfrecord_file):\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    # inside prepare_tfrecords\n",
    "    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "    total_examples = count_tfrecord_examples(tfrecord_files)\n",
    "    train_examples = int(total_examples * (1 - val_split))\n",
    "    steps_per_epoch = train_examples // batch_size\n",
    "\n",
    "    print(f\"TFRecord folder: {tfrecord_dir}\")\n",
    "    print(f\"Total examples: {total_examples}\")\n",
    "    print(f\"Train examples: {train_examples}\")\n",
    "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "    return train_dataset, val_dataset, steps_per_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b03ad574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset,val_dataset,steps_per_epoch = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d131044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_24, val_ds_24, steps_24 = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=24\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a6f3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_32, val_ds_32, steps_32 = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9916a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_44, val_ds_44, steps_44 = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=44\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e9933902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading text file: /home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt\n",
      "Text length: 4,347,531 characters\n",
      "Tokenizing text...\n",
      "Token length: 4,347,531 tokens\n",
      "Will create 33,964 training examples\n",
      "Creating TFRecord files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33965/33965 [00:01<00:00, 26769.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversion complete!\n",
      "Created 34 TFRecord files in: ./tfrecords/context_128_bs64\n",
      "Total examples: 33,964\n",
      "Metadata saved to: ./tfrecords/context_128_bs64/metadata.txt\n",
      "Found 34 TFRecord files\n",
      "Using 31 files for training, 3 for validation\n",
      "TFRecord folder: ./tfrecords/context_128_bs64\n",
      "Total examples: 33965\n",
      "Train examples: 30568\n",
      "Steps per epoch: 477\n"
     ]
    }
   ],
   "source": [
    "train_ds_64, val_ds_64, steps_64 = prepare_tfrecords(\n",
    "    text_file_path='/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt',\n",
    "    token_to_id_dict=token_to_id_dict,\n",
    "    context_length=CONTEXT_LEN,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "train_ds_64 = train_ds_64.shuffle(10000)\n",
    "val_ds_64 = val_ds_64.shuffle(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e152da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODER_BLOCKS = 5\n",
    "# ATTENTION_HEADS = 8\n",
    "\n",
    "# GPT_model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,ATTENTION_HEADS,0.00001,DECODER_BLOCKS,0.3)\n",
    "# _ = GPT_model((token_ids, attention_mask))\n",
    "# GPT_model.summary(expand_nested=True)\n",
    "\n",
    "# # training (stable): use logits\n",
    "# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# opt = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-4, clipnorm=1.0)\n",
    "# GPT_model.compile(optimizer=opt, loss=loss) # type: ignore\n",
    "\n",
    "# # inference probs (when you actually need them)\n",
    "# logits = GPT_model((token_ids, attention_mask), training=False)\n",
    "# probs = keras.ops.softmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECODER_BLOCKS = 1\n",
    "ATTENTION_HEADS = 2\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,ATTENTION_HEADS,0.00001,DECODER_BLOCKS,DROPOUT_RATE)\n",
    "\n",
    "# Compile your model (same as before)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-4, clipnorm=1.0)\n",
    "model.compile(optimizer=opt, loss=loss,metrics=['accuracy']) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f699204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Total epochs: 100\n",
      "Steps per epoch: 477\n",
      "Total steps: 47700\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:47:57.025887: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:47:57.805676: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:47:58.603023: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-08-30 05:47:58.867344: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 320 bytes spill stores, 320 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/477\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0125 - loss: 4.3998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:11.561710: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:48:12.216843: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:48:12.217100: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:48:12.217368: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:48:12.950478: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 356 bytes spill stores, 356 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:13.171887: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:14.325902: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:14.346160: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4107', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:14.528715: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 320 bytes spill stores, 320 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0219 - loss: 4.2359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:26.773636: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:48:29.787357: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:48:30.133876: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_01_val_loss_3.2356.keras\n",
      "\n",
      "Epoch 1: val_loss improved from None to 3.23563, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:33.442291: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "2025-08-30 05:48:33.442345: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:33.442375: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.0509 - loss: 3.9237 - val_accuracy: 0.1615 - val_loss: 3.2356\n",
      "Epoch 2/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.1318 - loss: 3.3174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:34.254991: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:48:34.255101: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_02_val_loss_3.2246.keras\n",
      "\n",
      "Epoch 2: val_loss improved from 3.23563 to 3.22456, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:34.875962: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:34.876018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:34.876050: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1319 - loss: 3.3143 - val_accuracy: 0.1633 - val_loss: 3.2246\n",
      "Epoch 3/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1556 - loss: 3.1781\n",
      "Epoch 3: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_03_val_loss_2.7940.keras\n",
      "\n",
      "Epoch 3: val_loss improved from 3.22456 to 2.79397, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:39.775665: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:39.775701: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:39.775723: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1768 - loss: 3.0698 - val_accuracy: 0.2366 - val_loss: 2.7940\n",
      "Epoch 4/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2213 - loss: 2.8717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:40.047517: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:40.047553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:40.047576: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_04_val_loss_2.7887.keras\n",
      "\n",
      "Epoch 4: val_loss improved from 2.79397 to 2.78873, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:40.298954: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:40.298990: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:40.299011: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2209 - loss: 2.8740 - val_accuracy: 0.2371 - val_loss: 2.7887\n",
      "Epoch 5/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2310 - loss: 2.7915\n",
      "Epoch 5: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_05_val_loss_2.6042.keras\n",
      "\n",
      "Epoch 5: val_loss improved from 2.78873 to 2.60420, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:45.673637: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:45.673692: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2365 - loss: 2.7335 - val_accuracy: 0.2501 - val_loss: 2.6042\n",
      "Epoch 6/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2451 - loss: 2.6488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:45.949938: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:45.949974: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:45.949996: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_06_val_loss_2.6029.keras\n",
      "\n",
      "Epoch 6: val_loss improved from 2.60420 to 2.60287, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:46.180428: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:46.180463: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:46.180486: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2456 - loss: 2.6485 - val_accuracy: 0.2502 - val_loss: 2.6029\n",
      "Epoch 7/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2455 - loss: 2.6134\n",
      "Epoch 7: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_07_val_loss_2.5269.keras\n",
      "\n",
      "Epoch 7: val_loss improved from 2.60287 to 2.52689, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:51.997628: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:51.997665: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:51.997699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.2467 - loss: 2.5898 - val_accuracy: 0.2526 - val_loss: 2.5269\n",
      "Epoch 8/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2477 - loss: 2.5591\n",
      "Epoch 8: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_08_val_loss_2.5254.keras\n",
      "\n",
      "Epoch 8: val_loss improved from 2.52689 to 2.52541, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:52.534110: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:52.534147: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:52.534168: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2479 - loss: 2.5525 - val_accuracy: 0.2524 - val_loss: 2.5254\n",
      "Epoch 9/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2495 - loss: 2.5352\n",
      "Epoch 9: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_09_val_loss_2.4857.keras\n",
      "\n",
      "Epoch 9: val_loss improved from 2.52541 to 2.48573, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:57.679829: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:57.679867: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:57.679899: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2515 - loss: 2.5224 - val_accuracy: 0.2593 - val_loss: 2.4857\n",
      "Epoch 10/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2524 - loss: 2.5192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:57.961112: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:57.961152: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:57.961178: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_10_val_loss_2.4845.keras\n",
      "\n",
      "Epoch 10: val_loss improved from 2.48573 to 2.48451, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:58.222612: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:58.222661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:58.222687: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2591 - loss: 2.4941 - val_accuracy: 0.2589 - val_loss: 2.4845\n",
      "Epoch 11/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2595 - loss: 2.4846\n",
      "Epoch 11: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_11_val_loss_2.4221.keras\n",
      "\n",
      "Epoch 11: val_loss improved from 2.48451 to 2.42211, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:03.239920: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:03.239960: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:03.239984: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2653 - loss: 2.4672 - val_accuracy: 0.2830 - val_loss: 2.4221\n",
      "Epoch 12/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2789 - loss: 2.4432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:03.495291: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_12_val_loss_2.4216.keras\n",
      "\n",
      "Epoch 12: val_loss improved from 2.42211 to 2.42159, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:03.729935: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:03.729975: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:03.729998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.2759 - loss: 2.4277 - val_accuracy: 0.2818 - val_loss: 2.4216\n",
      "Epoch 13/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2796 - loss: 2.4208\n",
      "Epoch 13: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_13_val_loss_2.3846.keras\n",
      "\n",
      "Epoch 13: val_loss improved from 2.42159 to 2.38459, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:08.525764: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:08.525847: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:08.525897: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2826 - loss: 2.4090 - val_accuracy: 0.2929 - val_loss: 2.3846\n",
      "Epoch 14/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2876 - loss: 2.3941\n",
      "Epoch 14: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_14_val_loss_2.3832.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:08.799223: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:08.799291: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:08.993301: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:08.993343: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:08.993365: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: val_loss improved from 2.38459 to 2.38316, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.2850 - loss: 2.3937 - val_accuracy: 0.2911 - val_loss: 2.3832\n",
      "Epoch 15/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2897 - loss: 2.3822\n",
      "Epoch 15: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_15_val_loss_2.3570.keras\n",
      "\n",
      "Epoch 15: val_loss improved from 2.38316 to 2.35702, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:14.575851: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:14.575890: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:14.575911: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2915 - loss: 2.3742 - val_accuracy: 0.2980 - val_loss: 2.3570\n",
      "Epoch 16/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2958 - loss: 2.3704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:14.862239: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_16_val_loss_2.3561.keras\n",
      "\n",
      "Epoch 16: val_loss improved from 2.35702 to 2.35614, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:15.156398: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:15.156437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:15.156458: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2936 - loss: 2.3624 - val_accuracy: 0.3004 - val_loss: 2.3561\n",
      "Epoch 17/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2972 - loss: 2.3521\n",
      "Epoch 17: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_17_val_loss_2.3279.keras\n",
      "\n",
      "Epoch 17: val_loss improved from 2.35614 to 2.32791, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:19.848763: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:19.848799: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:19.848821: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2988 - loss: 2.3453 - val_accuracy: 0.3060 - val_loss: 2.3279\n",
      "Epoch 18/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3062 - loss: 2.3160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:20.130623: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_18_val_loss_2.3278.keras\n",
      "\n",
      "Epoch 18: val_loss improved from 2.32791 to 2.32778, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:20.356863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:20.356899: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:20.356920: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3041 - loss: 2.3269 - val_accuracy: 0.3057 - val_loss: 2.3278\n",
      "Epoch 19/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3043 - loss: 2.3243\n",
      "Epoch 19: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_19_val_loss_2.2985.keras\n",
      "\n",
      "Epoch 19: val_loss improved from 2.32778 to 2.29853, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:24.537849: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:24.538041: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:24.538084: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3062 - loss: 2.3168 - val_accuracy: 0.3153 - val_loss: 2.2985\n",
      "Epoch 20/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3123 - loss: 2.3105\n",
      "Epoch 20: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_20_val_loss_2.2979.keras\n",
      "\n",
      "Epoch 20: val_loss improved from 2.29853 to 2.29789, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:25.114429: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:25.114465: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:25.114486: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3117 - loss: 2.3020 - val_accuracy: 0.3158 - val_loss: 2.2979\n",
      "Epoch 21/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3130 - loss: 2.2963\n",
      "Epoch 21: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_21_val_loss_2.2681.keras\n",
      "\n",
      "Epoch 21: val_loss improved from 2.29789 to 2.26807, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:29.486793: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:29.486831: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:29.486853: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3152 - loss: 2.2896 - val_accuracy: 0.3248 - val_loss: 2.2681\n",
      "Epoch 22/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3201 - loss: 2.2594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:29.746451: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:29.746490: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:29.746512: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_22_val_loss_2.2675.keras\n",
      "\n",
      "Epoch 22: val_loss improved from 2.26807 to 2.26749, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:29.994153: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:29.994190: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:29.994215: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3207 - loss: 2.2715 - val_accuracy: 0.3254 - val_loss: 2.2675\n",
      "Epoch 23/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3216 - loss: 2.2696\n",
      "Epoch 23: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_23_val_loss_2.2404.keras\n",
      "\n",
      "Epoch 23: val_loss improved from 2.26749 to 2.24037, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:34.340750: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:34.340788: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:34.340811: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3238 - loss: 2.2634 - val_accuracy: 0.3331 - val_loss: 2.2404\n",
      "Epoch 24/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3308 - loss: 2.2316\n",
      "Epoch 24: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_24_val_loss_2.2403.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:34.609260: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:34.805869: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: val_loss improved from 2.24037 to 2.24032, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.3265 - loss: 2.2461 - val_accuracy: 0.3342 - val_loss: 2.2403\n",
      "Epoch 25/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3294 - loss: 2.2455\n",
      "Epoch 25: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_25_val_loss_2.2152.keras\n",
      "\n",
      "Epoch 25: val_loss improved from 2.24032 to 2.21518, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:39.082269: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:39.082307: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:39.082329: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3316 - loss: 2.2388 - val_accuracy: 0.3428 - val_loss: 2.2152\n",
      "Epoch 26/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3446 - loss: 2.2045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:39.346857: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_26_val_loss_2.2147.keras\n",
      "\n",
      "Epoch 26: val_loss improved from 2.21518 to 2.21469, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:39.569906: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:39.569944: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:39.569966: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3350 - loss: 2.2299 - val_accuracy: 0.3429 - val_loss: 2.2147\n",
      "Epoch 27/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3372 - loss: 2.2211\n",
      "Epoch 27: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_27_val_loss_2.1913.keras\n",
      "\n",
      "Epoch 27: val_loss improved from 2.21469 to 2.19127, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:43.384212: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:43.384257: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:43.384279: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3387 - loss: 2.2160 - val_accuracy: 0.3491 - val_loss: 2.1913\n",
      "Epoch 28/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3435 - loss: 2.2082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:43.666028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:43.666066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:43.666090: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_28_val_loss_2.1906.keras\n",
      "\n",
      "Epoch 28: val_loss improved from 2.19127 to 2.19065, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:43.867382: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:43.867426: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:43.867450: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3429 - loss: 2.2066 - val_accuracy: 0.3492 - val_loss: 2.1906\n",
      "Epoch 29/1000\n",
      "\u001b[1m471/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3430 - loss: 2.2005\n",
      "Epoch 29: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_29_val_loss_2.1673.keras\n",
      "\n",
      "Epoch 29: val_loss improved from 2.19065 to 2.16727, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:48.412749: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:48.412835: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3450 - loss: 2.1941 - val_accuracy: 0.3557 - val_loss: 2.1673\n",
      "Epoch 30/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3418 - loss: 2.2051\n",
      "Epoch 30: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_30_val_loss_2.1681.keras\n",
      "\n",
      "Epoch 30: val_loss did not improve from 2.16727\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3478 - loss: 2.1874 - val_accuracy: 0.3558 - val_loss: 2.1681\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:48.968343: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:48.968383: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:48.968404: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3498 - loss: 2.1783\n",
      "Epoch 31: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_31_val_loss_2.1441.keras\n",
      "\n",
      "Epoch 31: val_loss improved from 2.16727 to 2.14412, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:53.744027: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:53.744066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:53.744088: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3513 - loss: 2.1729 - val_accuracy: 0.3620 - val_loss: 2.1441\n",
      "Epoch 32/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3632 - loss: 2.1522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:54.004119: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_32_val_loss_2.1444.keras\n",
      "\n",
      "Epoch 32: val_loss did not improve from 2.14412\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.3546 - loss: 2.1649 - val_accuracy: 0.3619 - val_loss: 2.1444\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:54.249050: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:54.249087: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:54.249108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3557 - loss: 2.1573\n",
      "Epoch 33: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_33_val_loss_2.1235.keras\n",
      "\n",
      "Epoch 33: val_loss improved from 2.14412 to 2.12355, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:58.563602: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:58.563663: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3568 - loss: 2.1530 - val_accuracy: 0.3675 - val_loss: 2.1235\n",
      "Epoch 34/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3682 - loss: 2.1251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:58.840606: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:59.038529: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:59.038570: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:59.038591: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_34_val_loss_2.1234.keras\n",
      "\n",
      "Epoch 34: val_loss improved from 2.12355 to 2.12337, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.3588 - loss: 2.1435 - val_accuracy: 0.3673 - val_loss: 2.1234\n",
      "Epoch 35/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3603 - loss: 2.1401\n",
      "Epoch 35: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_35_val_loss_2.1074.keras\n",
      "\n",
      "Epoch 35: val_loss improved from 2.12337 to 2.10742, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:04.327186: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:04.327226: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:04.327249: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3614 - loss: 2.1362 - val_accuracy: 0.3712 - val_loss: 2.1074\n",
      "Epoch 36/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3668 - loss: 2.1225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:04.655182: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_36_val_loss_2.1060.keras\n",
      "\n",
      "Epoch 36: val_loss improved from 2.10742 to 2.10602, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:04.885376: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:50:04.885459: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3664 - loss: 2.1236 - val_accuracy: 0.3713 - val_loss: 2.1060\n",
      "Epoch 37/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3641 - loss: 2.1254\n",
      "Epoch 37: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_37_val_loss_2.0919.keras\n",
      "\n",
      "Epoch 37: val_loss improved from 2.10602 to 2.09188, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:09.972355: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3652 - loss: 2.1214 - val_accuracy: 0.3751 - val_loss: 2.0919\n",
      "Epoch 38/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3608 - loss: 2.1380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:10.240634: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:10.240686: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:10.240717: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_38_val_loss_2.0920.keras\n",
      "\n",
      "Epoch 38: val_loss did not improve from 2.09188\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.3669 - loss: 2.1130 - val_accuracy: 0.3755 - val_loss: 2.0920\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:10.470397: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:10.470436: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:10.470458: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3672 - loss: 2.1117\n",
      "Epoch 39: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_39_val_loss_2.0794.keras\n",
      "\n",
      "Epoch 39: val_loss improved from 2.09188 to 2.07936, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:14.871451: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:14.871492: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:14.871514: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3677 - loss: 2.1091 - val_accuracy: 0.3779 - val_loss: 2.0794\n",
      "Epoch 40/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3810 - loss: 2.0897\n",
      "Epoch 40: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_40_val_loss_2.0798.keras\n",
      "\n",
      "Epoch 40: val_loss did not improve from 2.07936\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.3730 - loss: 2.1069 - val_accuracy: 0.3779 - val_loss: 2.0798\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:15.352005: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:15.352045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:15.352055: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3695 - loss: 2.1021\n",
      "Epoch 41: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_41_val_loss_2.0680.keras\n",
      "\n",
      "Epoch 41: val_loss improved from 2.07936 to 2.06800, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:20.264525: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:20.264564: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:20.264586: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3701 - loss: 2.0993 - val_accuracy: 0.3805 - val_loss: 2.0680\n",
      "Epoch 42/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3796 - loss: 2.0571\n",
      "Epoch 42: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_42_val_loss_2.0682.keras\n",
      "\n",
      "Epoch 42: val_loss did not improve from 2.06800\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.3724 - loss: 2.0856 - val_accuracy: 0.3797 - val_loss: 2.0682\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:20.766950: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:20.766991: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:20.767012: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3720 - loss: 2.0922\n",
      "Epoch 43: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_43_val_loss_2.0608.keras\n",
      "\n",
      "Epoch 43: val_loss improved from 2.06800 to 2.06083, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:26.320045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:26.320086: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:26.320108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3719 - loss: 2.0900 - val_accuracy: 0.3810 - val_loss: 2.0608\n",
      "Epoch 44/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3760 - loss: 2.0864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:26.601341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:26.601396: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:26.601431: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_44_val_loss_2.0593.keras\n",
      "\n",
      "Epoch 44: val_loss improved from 2.06083 to 2.05929, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:26.889699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:26.889739: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:26.889760: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3765 - loss: 2.0792 - val_accuracy: 0.3820 - val_loss: 2.0593\n",
      "Epoch 45/1000\n",
      "\u001b[1m469/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3734 - loss: 2.0837\n",
      "Epoch 45: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_45_val_loss_2.0511.keras\n",
      "\n",
      "Epoch 45: val_loss improved from 2.05929 to 2.05108, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:31.955981: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:31.956019: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:31.956039: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3736 - loss: 2.0822 - val_accuracy: 0.3830 - val_loss: 2.0511\n",
      "Epoch 46/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3745 - loss: 2.0810\n",
      "Epoch 46: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_46_val_loss_2.0509.keras\n",
      "\n",
      "Epoch 46: val_loss improved from 2.05108 to 2.05094, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:32.446706: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:50:32.446759: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.3737 - loss: 2.0785 - val_accuracy: 0.3835 - val_loss: 2.0509\n",
      "Epoch 47/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3747 - loss: 2.0772\n",
      "Epoch 47: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_47_val_loss_2.0439.keras\n",
      "\n",
      "Epoch 47: val_loss improved from 2.05094 to 2.04388, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:37.797441: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:37.797480: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:37.797501: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3750 - loss: 2.0754 - val_accuracy: 0.3852 - val_loss: 2.0439\n",
      "Epoch 48/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3674 - loss: 2.0842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:38.084927: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:38.084971: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:38.084998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_48_val_loss_2.0441.keras\n",
      "\n",
      "Epoch 48: val_loss did not improve from 2.04388\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.3742 - loss: 2.0752 - val_accuracy: 0.3850 - val_loss: 2.0441\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:38.318091: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-08-30 05:50:38.318133: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:38.318140: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:38.318159: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3762 - loss: 2.0707\n",
      "Epoch 49: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_49_val_loss_2.0379.keras\n",
      "\n",
      "Epoch 49: val_loss improved from 2.04388 to 2.03794, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:43.717617: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:43.717670: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:43.717691: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3765 - loss: 2.0695 - val_accuracy: 0.3855 - val_loss: 2.0379\n",
      "Epoch 50/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3750 - loss: 2.0787"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:43.984188: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_50_val_loss_2.0372.keras\n",
      "\n",
      "Epoch 50: val_loss improved from 2.03794 to 2.03716, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:44.246211: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:44.246259: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:44.246288: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3710 - loss: 2.0798 - val_accuracy: 0.3866 - val_loss: 2.0372\n",
      "Epoch 51/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3771 - loss: 2.0664\n",
      "Epoch 51: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_51_val_loss_2.0321.keras\n",
      "\n",
      "Epoch 51: val_loss improved from 2.03716 to 2.03208, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:49.699731: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:49.699785: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3776 - loss: 2.0642 - val_accuracy: 0.3877 - val_loss: 2.0321\n",
      "Epoch 52/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3788 - loss: 2.0670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:49.969729: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:49.969777: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:49.969809: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_52_val_loss_2.0329.keras\n",
      "\n",
      "Epoch 52: val_loss did not improve from 2.03208\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3762 - loss: 2.0656 - val_accuracy: 0.3870 - val_loss: 2.0329\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:50.248155: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3780 - loss: 2.0608\n",
      "Epoch 53: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_53_val_loss_2.0284.keras\n",
      "\n",
      "Epoch 53: val_loss improved from 2.03208 to 2.02836, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:55.510638: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:55.510677: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:55.510699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3785 - loss: 2.0599 - val_accuracy: 0.3883 - val_loss: 2.0284\n",
      "Epoch 54/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3726 - loss: 2.0647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:55.788540: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:55.788583: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:55.788607: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_54_val_loss_2.0283.keras\n",
      "\n",
      "Epoch 54: val_loss improved from 2.02836 to 2.02831, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:56.019367: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:56.019407: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:56.019429: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3794 - loss: 2.0542 - val_accuracy: 0.3878 - val_loss: 2.0283\n",
      "Epoch 55/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3797 - loss: 2.0562\n",
      "Epoch 55: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_55_val_loss_2.0234.keras\n",
      "\n",
      "Epoch 55: val_loss improved from 2.02831 to 2.02336, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:01.411671: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:01.411719: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:01.411741: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3797 - loss: 2.0556 - val_accuracy: 0.3892 - val_loss: 2.0234\n",
      "Epoch 56/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3751 - loss: 2.0656\n",
      "Epoch 56: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_56_val_loss_2.0236.keras\n",
      "\n",
      "Epoch 56: val_loss did not improve from 2.02336\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.3798 - loss: 2.0550 - val_accuracy: 0.3891 - val_loss: 2.0236\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:01.906783: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:01.906825: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:01.906846: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3800 - loss: 2.0538\n",
      "Epoch 57: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_57_val_loss_2.0202.keras\n",
      "\n",
      "Epoch 57: val_loss improved from 2.02336 to 2.02016, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:06.375003: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:06.375042: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:06.375062: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3805 - loss: 2.0528 - val_accuracy: 0.3896 - val_loss: 2.0202\n",
      "Epoch 58/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3875 - loss: 2.0138\n",
      "Epoch 58: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_58_val_loss_2.0196.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:06.631333: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:06.631371: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:06.631394: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:06.817201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:06.817239: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:06.817261: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58: val_loss improved from 2.02016 to 2.01957, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.3837 - loss: 2.0423 - val_accuracy: 0.3897 - val_loss: 2.0196\n",
      "Epoch 59/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3811 - loss: 2.0498\n",
      "Epoch 59: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_59_val_loss_2.0166.keras\n",
      "\n",
      "Epoch 59: val_loss improved from 2.01957 to 2.01658, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3809 - loss: 2.0497 - val_accuracy: 0.3905 - val_loss: 2.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:11.058637: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:11.058675: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:11.058703: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3894 - loss: 2.0451\n",
      "Epoch 60: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_60_val_loss_2.0164.keras\n",
      "\n",
      "Epoch 60: val_loss improved from 2.01658 to 2.01639, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:11.545123: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:11.545163: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:11.545185: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3853 - loss: 2.0399 - val_accuracy: 0.3907 - val_loss: 2.0164\n",
      "Epoch 61/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3815 - loss: 2.0474\n",
      "Epoch 61: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_61_val_loss_2.0141.keras\n",
      "\n",
      "Epoch 61: val_loss improved from 2.01639 to 2.01412, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:15.206931: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:15.206971: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:15.206993: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3815 - loss: 2.0470 - val_accuracy: 0.3912 - val_loss: 2.0141\n",
      "Epoch 62/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3851 - loss: 2.0230\n",
      "Epoch 62: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_62_val_loss_2.0146.keras\n",
      "\n",
      "Epoch 62: val_loss did not improve from 2.01412\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.3820 - loss: 2.0457 - val_accuracy: 0.3915 - val_loss: 2.0146\n",
      "Epoch 63/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:15.692666: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:15.692707: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:15.692731: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3820 - loss: 2.0460\n",
      "Epoch 63: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_63_val_loss_2.0131.keras\n",
      "\n",
      "Epoch 63: val_loss improved from 2.01412 to 2.01309, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:19.721935: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:19.721973: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:19.721995: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3822 - loss: 2.0443 - val_accuracy: 0.3914 - val_loss: 2.0131\n",
      "Epoch 64/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3827 - loss: 2.0547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:19.988639: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_64_val_loss_2.0126.keras\n",
      "\n",
      "Epoch 64: val_loss improved from 2.01309 to 2.01264, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:20.196905: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:20.196964: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:20.196986: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.3823 - loss: 2.0471 - val_accuracy: 0.3910 - val_loss: 2.0126\n",
      "Epoch 65/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3834 - loss: 2.0424\n",
      "Epoch 65: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_65_val_loss_2.0108.keras\n",
      "\n",
      "Epoch 65: val_loss improved from 2.01264 to 2.01082, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:24.086314: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:24.086354: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:24.086401: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3826 - loss: 2.0432 - val_accuracy: 0.3917 - val_loss: 2.0108\n",
      "Epoch 66/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3698 - loss: 2.0734\n",
      "Epoch 66: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_66_val_loss_2.0107.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:24.342887: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:24.529368: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:24.529406: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:24.529427: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66: val_loss improved from 2.01082 to 2.01072, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.3822 - loss: 2.0418 - val_accuracy: 0.3921 - val_loss: 2.0107\n",
      "Epoch 67/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3826 - loss: 2.0422\n",
      "Epoch 67: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_67_val_loss_2.0088.keras\n",
      "\n",
      "Epoch 67: val_loss improved from 2.01072 to 2.00883, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3828 - loss: 2.0417 - val_accuracy: 0.3922 - val_loss: 2.0088\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:29.370231: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:29.370273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:29.370295: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3812 - loss: 2.0355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:29.614325: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_68_val_loss_2.0089.keras\n",
      "\n",
      "Epoch 68: val_loss did not improve from 2.00883\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.3813 - loss: 2.0475 - val_accuracy: 0.3920 - val_loss: 2.0089\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:29.865234: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:29.865273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:29.865294: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3825 - loss: 2.0426\n",
      "Epoch 69: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_69_val_loss_2.0082.keras\n",
      "\n",
      "Epoch 69: val_loss improved from 2.00883 to 2.00816, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3831 - loss: 2.0407 - val_accuracy: 0.3924 - val_loss: 2.0082\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:34.746031: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3783 - loss: 2.0424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:34.989791: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:34.989831: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:34.989855: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_70_val_loss_2.0081.keras\n",
      "\n",
      "Epoch 70: val_loss improved from 2.00816 to 2.00813, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:35.219410: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:35.219449: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:35.219471: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.3835 - loss: 2.0348 - val_accuracy: 0.3927 - val_loss: 2.0081\n",
      "Epoch 71/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3833 - loss: 2.0403\n",
      "Epoch 71: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_71_val_loss_2.0072.keras\n",
      "\n",
      "Epoch 71: val_loss improved from 2.00813 to 2.00720, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:40.152616: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:40.152654: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:40.152676: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3832 - loss: 2.0397 - val_accuracy: 0.3922 - val_loss: 2.0072\n",
      "Epoch 72/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3828 - loss: 2.0569\n",
      "Epoch 72: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_72_val_loss_2.0064.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:40.396071: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:40.587487: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:40.587527: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:40.587548: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72: val_loss improved from 2.00720 to 2.00635, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.3832 - loss: 2.0421 - val_accuracy: 0.3927 - val_loss: 2.0064\n",
      "Epoch 73/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3836 - loss: 2.0393\n",
      "Epoch 73: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_73_val_loss_2.0055.keras\n",
      "\n",
      "Epoch 73: val_loss improved from 2.00635 to 2.00553, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:45.351607: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:45.351645: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:45.351669: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3836 - loss: 2.0390 - val_accuracy: 0.3925 - val_loss: 2.0055\n",
      "Epoch 74/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3807 - loss: 2.0593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:45.606041: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:45.803258: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:45.803298: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:45.803319: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_74_val_loss_2.0056.keras\n",
      "\n",
      "Epoch 74: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.3835 - loss: 2.0418 - val_accuracy: 0.3931 - val_loss: 2.0056\n",
      "Epoch 75/1000\n",
      "\u001b[1m469/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3839 - loss: 2.0365\n",
      "Epoch 75: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_75_val_loss_2.0062.keras\n",
      "\n",
      "Epoch 75: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0382 - val_accuracy: 0.3926 - val_loss: 2.0062\n",
      "Epoch 76/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3705 - loss: 2.0623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:49.854537: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:49.854575: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:49.854597: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:50.054393: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:50.054432: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:50.054455: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_76_val_loss_2.0065.keras\n",
      "\n",
      "Epoch 76: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.3797 - loss: 2.0445 - val_accuracy: 0.3921 - val_loss: 2.0065\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:50.248995: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:50.249034: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:50.249056: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0376\n",
      "Epoch 77: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_77_val_loss_2.0059.keras\n",
      "\n",
      "Epoch 77: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3836 - loss: 2.0382 - val_accuracy: 0.3929 - val_loss: 2.0059\n",
      "Epoch 78/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3955 - loss: 2.0214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:54.439337: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:54.439375: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:54.439397: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_78_val_loss_2.0058.keras\n",
      "\n",
      "Epoch 78: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.3847 - loss: 2.0353 - val_accuracy: 0.3930 - val_loss: 2.0058\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:54.883123: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:54.883159: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:54.883179: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3832 - loss: 2.0387\n",
      "Epoch 79: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_79_val_loss_2.0067.keras\n",
      "\n",
      "Epoch 79: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3835 - loss: 2.0382 - val_accuracy: 0.3926 - val_loss: 2.0067\n",
      "Epoch 80/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3857 - loss: 2.0235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:58.752010: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:58.752047: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:58.752071: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:58.949437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:58.949480: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:58.949508: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_80_val_loss_2.0062.keras\n",
      "\n",
      "Epoch 80: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.3839 - loss: 2.0347 - val_accuracy: 0.3924 - val_loss: 2.0062\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:59.200276: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:59.200314: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:59.200337: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3838 - loss: 2.0364\n",
      "Epoch 81: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_81_val_loss_2.0057.keras\n",
      "\n",
      "Epoch 81: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3837 - loss: 2.0380 - val_accuracy: 0.3926 - val_loss: 2.0057\n",
      "Epoch 82/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3827 - loss: 2.0352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:03.809529: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:03.809566: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:03.809587: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:04.016692: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:04.016735: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:04.016760: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_82_val_loss_2.0051.keras\n",
      "\n",
      "Epoch 82: val_loss improved from 2.00553 to 2.00512, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:04.280803: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:04.280855: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3833 - loss: 2.0381 - val_accuracy: 0.3932 - val_loss: 2.0051\n",
      "Epoch 83/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3840 - loss: 2.0376\n",
      "Epoch 83: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_83_val_loss_2.0054.keras\n",
      "\n",
      "Epoch 83: val_loss did not improve from 2.00512\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3839 - loss: 2.0372 - val_accuracy: 0.3929 - val_loss: 2.0054\n",
      "Epoch 84/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3857 - loss: 2.0232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:09.301391: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:09.301446: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3824 - loss: 2.0430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:09.543365: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:09.543410: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:09.543437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_84_val_loss_2.0057.keras\n",
      "\n",
      "Epoch 84: val_loss did not improve from 2.00512\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.3813 - loss: 2.0502 - val_accuracy: 0.3932 - val_loss: 2.0057\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:09.771305: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:09.771342: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:09.771364: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3836 - loss: 2.0384\n",
      "Epoch 85: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_85_val_loss_2.0053.keras\n",
      "\n",
      "Epoch 85: val_loss did not improve from 2.00512\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3836 - loss: 2.0377 - val_accuracy: 0.3931 - val_loss: 2.0053\n",
      "Epoch 86/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3834 - loss: 2.0336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:14.504773: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:14.504816: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:14.504841: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:14.716273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:14.716341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_86_val_loss_2.0049.keras\n",
      "\n",
      "Epoch 86: val_loss improved from 2.00512 to 2.00494, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:14.990301: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:14.990341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:14.990363: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3879 - loss: 2.0290 - val_accuracy: 0.3928 - val_loss: 2.0049\n",
      "Epoch 87/1000\n",
      "\u001b[1m469/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3834 - loss: 2.0391\n",
      "Epoch 87: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_87_val_loss_2.0047.keras\n",
      "\n",
      "Epoch 87: val_loss improved from 2.00494 to 2.00475, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:19.034513: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:19.034554: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:19.034576: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0374 - val_accuracy: 0.3934 - val_loss: 2.0047\n",
      "Epoch 88/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3849 - loss: 2.0506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:19.294366: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_88_val_loss_2.0054.keras\n",
      "\n",
      "Epoch 88: val_loss did not improve from 2.00475\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.3857 - loss: 2.0343 - val_accuracy: 0.3930 - val_loss: 2.0054\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:19.499347: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:19.499385: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:19.499407: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3842 - loss: 2.0366\n",
      "Epoch 89: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_89_val_loss_2.0042.keras\n",
      "\n",
      "Epoch 89: val_loss improved from 2.00475 to 2.00420, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:23.188267: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:23.188321: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0375 - val_accuracy: 0.3934 - val_loss: 2.0042\n",
      "Epoch 90/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3905 - loss: 2.0259\n",
      "Epoch 90: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_90_val_loss_2.0046.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:23.453364: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:23.453420: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:23.639614: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:23.639652: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:23.639673: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90: val_loss did not improve from 2.00420\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.3850 - loss: 2.0280 - val_accuracy: 0.3929 - val_loss: 2.0046\n",
      "Epoch 91/1000\n",
      "\u001b[1m468/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3837 - loss: 2.0381\n",
      "Epoch 91: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_91_val_loss_2.0051.keras\n",
      "\n",
      "Epoch 91: val_loss did not improve from 2.00420\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3839 - loss: 2.0371 - val_accuracy: 0.3930 - val_loss: 2.0051\n",
      "Epoch 92/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3835 - loss: 2.0358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:27.148125: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:27.148167: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:27.148208: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:27.345091: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:27.345130: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:27.345155: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_92_val_loss_2.0041.keras\n",
      "\n",
      "Epoch 92: val_loss improved from 2.00420 to 2.00406, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:27.555043: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:27.555085: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:27.555108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.3842 - loss: 2.0384 - val_accuracy: 0.3931 - val_loss: 2.0041\n",
      "Epoch 93/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3839 - loss: 2.0366\n",
      "Epoch 93: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_93_val_loss_2.0045.keras\n",
      "\n",
      "Epoch 93: val_loss did not improve from 2.00406\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3841 - loss: 2.0363 - val_accuracy: 0.3935 - val_loss: 2.0045\n",
      "Epoch 94/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3816 - loss: 2.0404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:31.721559: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:31.721599: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:31.721621: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:31.970860: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_94_val_loss_2.0034.keras\n",
      "\n",
      "Epoch 94: val_loss improved from 2.00406 to 2.00335, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:32.180602: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:32.180651: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:32.180683: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3831 - loss: 2.0383 - val_accuracy: 0.3940 - val_loss: 2.0034\n",
      "Epoch 95/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3839 - loss: 2.0352\n",
      "Epoch 95: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_95_val_loss_2.0033.keras\n",
      "\n",
      "Epoch 95: val_loss improved from 2.00335 to 2.00327, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:36.931278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:36.931337: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:36.931370: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3841 - loss: 2.0359 - val_accuracy: 0.3938 - val_loss: 2.0033\n",
      "Epoch 96/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3953 - loss: 2.0233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:37.211502: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:37.211547: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:37.211572: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_96_val_loss_2.0034.keras\n",
      "\n",
      "Epoch 96: val_loss did not improve from 2.00327\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.3851 - loss: 2.0379 - val_accuracy: 0.3932 - val_loss: 2.0034\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:37.452130: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:37.452172: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:37.452196: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3845 - loss: 2.0353\n",
      "Epoch 97: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_97_val_loss_2.0020.keras\n",
      "\n",
      "Epoch 97: val_loss improved from 2.00327 to 2.00205, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:42.267436: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:42.267474: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:42.267496: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3843 - loss: 2.0354 - val_accuracy: 0.3938 - val_loss: 2.0020\n",
      "Epoch 98/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3905 - loss: 2.0367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:42.561439: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:42.561478: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:42.561501: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_98_val_loss_2.0007.keras\n",
      "\n",
      "Epoch 98: val_loss improved from 2.00205 to 2.00073, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:42.797816: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3878 - loss: 2.0288 - val_accuracy: 0.3939 - val_loss: 2.0007\n",
      "Epoch 99/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3845 - loss: 2.0337\n",
      "Epoch 99: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_99_val_loss_2.0002.keras\n",
      "\n",
      "Epoch 99: val_loss improved from 2.00073 to 2.00018, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:48.185401: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:48.185439: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:48.185463: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3844 - loss: 2.0341 - val_accuracy: 0.3940 - val_loss: 2.0002\n",
      "Epoch 100/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3882 - loss: 2.0257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:48.501064: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_100_val_loss_2.0009.keras\n",
      "\n",
      "Epoch 100: val_loss did not improve from 2.00018\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3854 - loss: 2.0319 - val_accuracy: 0.3938 - val_loss: 2.0009\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:48.814945: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:48.814984: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:48.815008: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3857 - loss: 2.0310\n",
      "Epoch 101: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_101_val_loss_1.9985.keras\n",
      "\n",
      "Epoch 101: val_loss improved from 2.00018 to 1.99855, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:54.586529: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:54.586569: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:54.586592: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3850 - loss: 2.0326 - val_accuracy: 0.3944 - val_loss: 1.9985\n",
      "Epoch 102/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3814 - loss: 2.0381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:54.904916: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:54.904981: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:54.905029: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_102_val_loss_1.9986.keras\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.99855\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3819 - loss: 2.0382 - val_accuracy: 0.3947 - val_loss: 1.9986\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:55.159259: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:55.159300: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:55.159323: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3852 - loss: 2.0309\n",
      "Epoch 103: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_103_val_loss_1.9962.keras\n",
      "\n",
      "Epoch 103: val_loss improved from 1.99855 to 1.99623, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:00.369278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:00.369319: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:00.369343: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3852 - loss: 2.0311 - val_accuracy: 0.3950 - val_loss: 1.9962\n",
      "Epoch 104/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3893 - loss: 2.0133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:00.652201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_104_val_loss_1.9965.keras\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.99623\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3816 - loss: 2.0376 - val_accuracy: 0.3949 - val_loss: 1.9965\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:00.923162: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:00.923202: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:00.923224: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3856 - loss: 2.0303\n",
      "Epoch 105: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_105_val_loss_1.9945.keras\n",
      "\n",
      "Epoch 105: val_loss improved from 1.99623 to 1.99452, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:06.987221: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:06.987330: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:06.987387: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3856 - loss: 2.0293 - val_accuracy: 0.3959 - val_loss: 1.9945\n",
      "Epoch 106/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3880 - loss: 2.0314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:07.310756: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:07.310808: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:07.310842: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_106_val_loss_1.9941.keras\n",
      "\n",
      "Epoch 106: val_loss improved from 1.99452 to 1.99409, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:07.591117: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:07.591164: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:07.591190: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3852 - loss: 2.0345 - val_accuracy: 0.3959 - val_loss: 1.9941\n",
      "Epoch 107/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3857 - loss: 2.0274\n",
      "Epoch 107: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_107_val_loss_1.9938.keras\n",
      "\n",
      "Epoch 107: val_loss improved from 1.99409 to 1.99384, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:13.687951: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:13.687995: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:13.688018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3857 - loss: 2.0273 - val_accuracy: 0.3957 - val_loss: 1.9938\n",
      "Epoch 108/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3895 - loss: 2.0245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:13.980469: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:13.980524: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:13.980553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_108_val_loss_1.9918.keras\n",
      "\n",
      "Epoch 108: val_loss improved from 1.99384 to 1.99180, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:14.240278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:14.240315: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:14.240338: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3869 - loss: 2.0252 - val_accuracy: 0.3964 - val_loss: 1.9918\n",
      "Epoch 109/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3862 - loss: 2.0253\n",
      "Epoch 109: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_109_val_loss_1.9893.keras\n",
      "\n",
      "Epoch 109: val_loss improved from 1.99180 to 1.98931, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:20.213761: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:20.213802: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:20.213824: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3865 - loss: 2.0247 - val_accuracy: 0.3968 - val_loss: 1.9893\n",
      "Epoch 110/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3903 - loss: 2.0175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:20.576075: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:20.576144: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:20.576195: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_110_val_loss_1.9897.keras\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.98931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:20.874943: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3904 - loss: 2.0174 - val_accuracy: 0.3966 - val_loss: 1.9897\n",
      "Epoch 111/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3867 - loss: 2.0244\n",
      "Epoch 111: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_111_val_loss_1.9858.keras\n",
      "\n",
      "Epoch 111: val_loss improved from 1.98931 to 1.98577, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:26.634782: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:26.634834: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3873 - loss: 2.0223 - val_accuracy: 0.3976 - val_loss: 1.9858\n",
      "Epoch 112/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3911 - loss: 2.0133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:26.919957: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:26.919994: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:26.920018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_112_val_loss_1.9852.keras\n",
      "\n",
      "Epoch 112: val_loss improved from 1.98577 to 1.98522, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:27.145827: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:27.145864: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:27.145886: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3872 - loss: 2.0170 - val_accuracy: 0.3978 - val_loss: 1.9852\n",
      "Epoch 113/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3874 - loss: 2.0195\n",
      "Epoch 113: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_113_val_loss_1.9826.keras\n",
      "\n",
      "Epoch 113: val_loss improved from 1.98522 to 1.98257, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:32.574719: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:32.574768: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:32.574794: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3878 - loss: 2.0194 - val_accuracy: 0.3977 - val_loss: 1.9826\n",
      "Epoch 114/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3904 - loss: 2.0115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:32.892334: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:32.892382: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:32.892408: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 114: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_114_val_loss_1.9822.keras\n",
      "\n",
      "Epoch 114: val_loss improved from 1.98257 to 1.98216, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:33.139021: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:33.139066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:33.139090: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3900 - loss: 2.0124 - val_accuracy: 0.3982 - val_loss: 1.9822\n",
      "Epoch 115/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3881 - loss: 2.0170\n",
      "Epoch 115: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_115_val_loss_1.9786.keras\n",
      "\n",
      "Epoch 115: val_loss improved from 1.98216 to 1.97857, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:39.334397: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:39.334432: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:39.334454: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3883 - loss: 2.0166 - val_accuracy: 0.3991 - val_loss: 1.9786\n",
      "Epoch 116/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3906 - loss: 2.0109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:39.643519: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:39.643572: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:39.643598: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_116_val_loss_1.9790.keras\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.97857\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3916 - loss: 2.0140 - val_accuracy: 0.3992 - val_loss: 1.9790\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:39.925168: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:39.925204: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:39.925225: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3888 - loss: 2.0129\n",
      "Epoch 117: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_117_val_loss_1.9751.keras\n",
      "\n",
      "Epoch 117: val_loss improved from 1.97857 to 1.97506, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:45.622018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:45.622053: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:45.622074: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3891 - loss: 2.0128 - val_accuracy: 0.4003 - val_loss: 1.9751\n",
      "Epoch 118/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3867 - loss: 2.0152\n",
      "Epoch 118: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_118_val_loss_1.9748.keras\n",
      "\n",
      "Epoch 118: val_loss improved from 1.97506 to 1.97481, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:46.184316: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:46.184354: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:46.184378: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3874 - loss: 2.0133 - val_accuracy: 0.3998 - val_loss: 1.9748\n",
      "Epoch 119/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3899 - loss: 2.0096\n",
      "Epoch 119: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_119_val_loss_1.9711.keras\n",
      "\n",
      "Epoch 119: val_loss improved from 1.97481 to 1.97105, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:51.568784: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:51.568821: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:51.568842: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3899 - loss: 2.0094 - val_accuracy: 0.4011 - val_loss: 1.9711\n",
      "Epoch 120/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3865 - loss: 2.0212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:51.859634: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:51.859672: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:51.859698: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_120_val_loss_1.9708.keras\n",
      "\n",
      "Epoch 120: val_loss improved from 1.97105 to 1.97082, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:52.168054: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:52.168094: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:52.168119: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3902 - loss: 2.0096 - val_accuracy: 0.4010 - val_loss: 1.9708\n",
      "Epoch 121/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3910 - loss: 2.0062\n",
      "Epoch 121: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_121_val_loss_1.9655.keras\n",
      "\n",
      "Epoch 121: val_loss improved from 1.97082 to 1.96552, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:57.885294: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3910 - loss: 2.0055 - val_accuracy: 0.4019 - val_loss: 1.9655\n",
      "Epoch 122/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3947 - loss: 2.0034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:58.200570: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:58.200649: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:58.200712: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 122: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_122_val_loss_1.9658.keras\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.96552\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.3925 - loss: 2.0027 - val_accuracy: 0.4020 - val_loss: 1.9658\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:58.425373: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:58.425442: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:58.425482: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3912 - loss: 2.0032\n",
      "Epoch 123: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_123_val_loss_1.9630.keras\n",
      "\n",
      "Epoch 123: val_loss improved from 1.96552 to 1.96304, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:04.189805: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:04.189845: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:04.189868: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3917 - loss: 2.0017 - val_accuracy: 0.4021 - val_loss: 1.9630\n",
      "Epoch 124/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3967 - loss: 1.9794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:04.476247: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:04.476288: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:04.476311: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_124_val_loss_1.9628.keras\n",
      "\n",
      "Epoch 124: val_loss improved from 1.96304 to 1.96277, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:04.739045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:04.739086: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:04.739109: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3937 - loss: 1.9977 - val_accuracy: 0.4024 - val_loss: 1.9628\n",
      "Epoch 125/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3920 - loss: 2.0008\n",
      "Epoch 125: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_125_val_loss_1.9567.keras\n",
      "\n",
      "Epoch 125: val_loss improved from 1.96277 to 1.95671, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:09.966262: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:09.966301: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:09.966322: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3925 - loss: 1.9984 - val_accuracy: 0.4036 - val_loss: 1.9567\n",
      "Epoch 126/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3927 - loss: 1.9879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:10.257890: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:10.257930: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:10.257954: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 126: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_126_val_loss_1.9574.keras\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.95671\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.3930 - loss: 1.9889 - val_accuracy: 0.4035 - val_loss: 1.9574\n",
      "Epoch 127/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:10.510961: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:10.511001: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:10.511023: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3933 - loss: 1.9941\n",
      "Epoch 127: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_127_val_loss_1.9525.keras\n",
      "\n",
      "Epoch 127: val_loss improved from 1.95671 to 1.95250, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:16.157195: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:16.157234: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:16.157256: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3934 - loss: 1.9940 - val_accuracy: 0.4047 - val_loss: 1.9525\n",
      "Epoch 128/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3989 - loss: 1.9894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:16.456676: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 128: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_128_val_loss_1.9526.keras\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.95250\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3971 - loss: 1.9891 - val_accuracy: 0.4047 - val_loss: 1.9526\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:16.709079: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:16.709119: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:16.709142: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3942 - loss: 1.9909\n",
      "Epoch 129: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_129_val_loss_1.9494.keras\n",
      "\n",
      "Epoch 129: val_loss improved from 1.95250 to 1.94941, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:21.973870: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:21.973909: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:21.973919: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3945 - loss: 1.9895 - val_accuracy: 0.4059 - val_loss: 1.9494\n",
      "Epoch 130/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3989 - loss: 1.9817\n",
      "Epoch 130: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_130_val_loss_1.9498.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:22.259383: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:54:22.452216: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130: val_loss did not improve from 1.94941\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.3977 - loss: 1.9819 - val_accuracy: 0.4056 - val_loss: 1.9498\n",
      "Epoch 131/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3951 - loss: 1.9876\n",
      "Epoch 131: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_131_val_loss_1.9445.keras\n",
      "\n",
      "Epoch 131: val_loss improved from 1.94941 to 1.94449, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:26.526537: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:26.526577: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:26.526598: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3956 - loss: 1.9855 - val_accuracy: 0.4061 - val_loss: 1.9445\n",
      "Epoch 132/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3911 - loss: 1.9753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:26.790254: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 132: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_132_val_loss_1.9428.keras\n",
      "\n",
      "Epoch 132: val_loss improved from 1.94449 to 1.94278, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:26.997928: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:26.997966: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:26.997987: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3939 - loss: 1.9835 - val_accuracy: 0.4070 - val_loss: 1.9428\n",
      "Epoch 133/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3959 - loss: 1.9834\n",
      "Epoch 133: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_133_val_loss_1.9379.keras\n",
      "\n",
      "Epoch 133: val_loss improved from 1.94278 to 1.93793, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:32.547377: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:32.547422: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:32.547445: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3964 - loss: 1.9809 - val_accuracy: 0.4084 - val_loss: 1.9379\n",
      "Epoch 134/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3985 - loss: 1.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:33.016068: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 134: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_134_val_loss_1.9385.keras\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.93793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:33.331878: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:33.331921: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:33.331943: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3978 - loss: 1.9802 - val_accuracy: 0.4076 - val_loss: 1.9385\n",
      "Epoch 135/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3974 - loss: 1.9775\n",
      "Epoch 135: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_135_val_loss_1.9329.keras\n",
      "\n",
      "Epoch 135: val_loss improved from 1.93793 to 1.93293, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:40.873077: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:40.873152: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:40.873201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.3974 - loss: 1.9771 - val_accuracy: 0.4098 - val_loss: 1.9329\n",
      "Epoch 136/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.3976 - loss: 1.9733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:41.351028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 136: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_136_val_loss_1.9338.keras\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.93293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:41.722292: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:41.722377: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:41.722428: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3957 - loss: 1.9737 - val_accuracy: 0.4096 - val_loss: 1.9338\n",
      "Epoch 137/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3981 - loss: 1.9738\n",
      "Epoch 137: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_137_val_loss_1.9292.keras\n",
      "\n",
      "Epoch 137: val_loss improved from 1.93293 to 1.92917, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:48.927022: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:48.927061: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:48.927084: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.3984 - loss: 1.9724 - val_accuracy: 0.4097 - val_loss: 1.9292\n",
      "Epoch 138/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.3965 - loss: 1.9891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:49.401613: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:49.401699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:49.401756: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 138: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_138_val_loss_1.9280.keras\n",
      "\n",
      "Epoch 138: val_loss improved from 1.92917 to 1.92795, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:49.753697: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3982 - loss: 1.9825 - val_accuracy: 0.4104 - val_loss: 1.9280\n",
      "Epoch 139/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3989 - loss: 1.9709\n",
      "Epoch 139: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_139_val_loss_1.9242.keras\n",
      "\n",
      "Epoch 139: val_loss improved from 1.92795 to 1.92421, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:56.888413: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:56.888457: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:56.888480: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.3995 - loss: 1.9686 - val_accuracy: 0.4109 - val_loss: 1.9242\n",
      "Epoch 140/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.3987 - loss: 1.9633\n",
      "Epoch 140: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_140_val_loss_1.9240.keras\n",
      "\n",
      "Epoch 140: val_loss improved from 1.92421 to 1.92398, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:57.790173: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:57.790257: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:57.790306: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3982 - loss: 1.9676 - val_accuracy: 0.4115 - val_loss: 1.9240\n",
      "Epoch 141/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4001 - loss: 1.9657\n",
      "Epoch 141: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_141_val_loss_1.9206.keras\n",
      "\n",
      "Epoch 141: val_loss improved from 1.92398 to 1.92058, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:05.844648: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.4005 - loss: 1.9645 - val_accuracy: 0.4118 - val_loss: 1.9206\n",
      "Epoch 142/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.4053 - loss: 1.9495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:06.396380: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 142: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_142_val_loss_1.9214.keras\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.92058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:06.768705: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:06.768761: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:06.768787: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4050 - loss: 1.9566 - val_accuracy: 0.4118 - val_loss: 1.9214\n",
      "Epoch 143/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4015 - loss: 1.9618\n",
      "Epoch 143: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_143_val_loss_1.9147.keras\n",
      "\n",
      "Epoch 143: val_loss improved from 1.92058 to 1.91466, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:13.058172: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:13.058217: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:13.058240: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4017 - loss: 1.9604 - val_accuracy: 0.4135 - val_loss: 1.9147\n",
      "Epoch 144/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.4028 - loss: 1.9548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:13.434305: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 144: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_144_val_loss_1.9147.keras\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.91466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:13.717864: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:13.717907: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:13.717929: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4028 - loss: 1.9541 - val_accuracy: 0.4136 - val_loss: 1.9147\n",
      "Epoch 145/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4028 - loss: 1.9565\n",
      "Epoch 145: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_145_val_loss_1.9101.keras\n",
      "\n",
      "Epoch 145: val_loss improved from 1.91466 to 1.91012, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:20.687663: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:20.687784: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:20.687836: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4028 - loss: 1.9559 - val_accuracy: 0.4151 - val_loss: 1.9101\n",
      "Epoch 146/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.4050 - loss: 1.9465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:21.119454: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:21.119502: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:21.119528: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_146_val_loss_1.9093.keras\n",
      "\n",
      "Epoch 146: val_loss improved from 1.91012 to 1.90930, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:21.450975: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4037 - loss: 1.9524 - val_accuracy: 0.4154 - val_loss: 1.9093\n",
      "Epoch 147/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4032 - loss: 1.9545\n",
      "Epoch 147: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_147_val_loss_1.9066.keras\n",
      "\n",
      "Epoch 147: val_loss improved from 1.90930 to 1.90657, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:28.460328: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:28.460371: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:28.460394: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4039 - loss: 1.9523 - val_accuracy: 0.4151 - val_loss: 1.9066\n",
      "Epoch 148/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4040 - loss: 1.9505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:28.776569: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 148: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_148_val_loss_1.9054.keras\n",
      "\n",
      "Epoch 148: val_loss improved from 1.90657 to 1.90538, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:29.055732: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:29.055773: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:29.055795: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4031 - loss: 1.9499 - val_accuracy: 0.4161 - val_loss: 1.9054\n",
      "Epoch 149/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4045 - loss: 1.9495\n",
      "Epoch 149: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_149_val_loss_1.9024.keras\n",
      "\n",
      "Epoch 149: val_loss improved from 1.90538 to 1.90237, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:35.122104: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:35.122145: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:35.122171: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4048 - loss: 1.9482 - val_accuracy: 0.4169 - val_loss: 1.9024\n",
      "Epoch 150/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3993 - loss: 1.9800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:35.415621: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_150_val_loss_1.9012.keras\n",
      "\n",
      "Epoch 150: val_loss improved from 1.90237 to 1.90120, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:35.690090: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:35.690130: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:35.690152: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4026 - loss: 1.9567 - val_accuracy: 0.4165 - val_loss: 1.9012\n",
      "Epoch 151/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4056 - loss: 1.9460\n",
      "Epoch 151: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_151_val_loss_1.8981.keras\n",
      "\n",
      "Epoch 151: val_loss improved from 1.90120 to 1.89812, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:41.696289: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:41.696348: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:41.696384: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4060 - loss: 1.9440 - val_accuracy: 0.4180 - val_loss: 1.8981\n",
      "Epoch 152/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4047 - loss: 1.9539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:41.998573: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 152: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_152_val_loss_1.8976.keras\n",
      "\n",
      "Epoch 152: val_loss improved from 1.89812 to 1.89761, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:42.281220: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:42.281276: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:42.281308: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4072 - loss: 1.9506 - val_accuracy: 0.4173 - val_loss: 1.8976\n",
      "Epoch 153/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4065 - loss: 1.9413\n",
      "Epoch 153: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_153_val_loss_1.8942.keras\n",
      "\n",
      "Epoch 153: val_loss improved from 1.89761 to 1.89420, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:48.203386: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:48.203423: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:48.203445: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4067 - loss: 1.9404 - val_accuracy: 0.4186 - val_loss: 1.8942\n",
      "Epoch 154/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4077 - loss: 1.9343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:48.500133: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:48.500220: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:48.500273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 154: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_154_val_loss_1.8937.keras\n",
      "\n",
      "Epoch 154: val_loss improved from 1.89420 to 1.89369, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:48.794654: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:48.794698: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:48.794721: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4073 - loss: 1.9365 - val_accuracy: 0.4190 - val_loss: 1.8937\n",
      "Epoch 155/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4073 - loss: 1.9385\n",
      "Epoch 155: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_155_val_loss_1.8904.keras\n",
      "\n",
      "Epoch 155: val_loss improved from 1.89369 to 1.89044, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:55.016667: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:55.016746: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:55.016796: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4077 - loss: 1.9371 - val_accuracy: 0.4195 - val_loss: 1.8904\n",
      "Epoch 156/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4050 - loss: 1.9447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:55.363548: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:55.363604: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:55.363632: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 156: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_156_val_loss_1.8901.keras\n",
      "\n",
      "Epoch 156: val_loss improved from 1.89044 to 1.89011, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:55.656425: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:55.656467: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:55.656489: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4055 - loss: 1.9417 - val_accuracy: 0.4196 - val_loss: 1.8901\n",
      "Epoch 157/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4084 - loss: 1.9343\n",
      "Epoch 157: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_157_val_loss_1.8889.keras\n",
      "\n",
      "Epoch 157: val_loss improved from 1.89011 to 1.88889, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:02.273915: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:02.273976: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:02.274017: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4085 - loss: 1.9338 - val_accuracy: 0.4203 - val_loss: 1.8889\n",
      "Epoch 158/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.4120 - loss: 1.9189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:02.667781: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 158: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_158_val_loss_1.8863.keras\n",
      "\n",
      "Epoch 158: val_loss improved from 1.88889 to 1.88628, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:02.939702: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:02.939767: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:02.939811: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4087 - loss: 1.9324 - val_accuracy: 0.4201 - val_loss: 1.8863\n",
      "Epoch 159/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4094 - loss: 1.9307\n",
      "Epoch 159: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_159_val_loss_1.8838.keras\n",
      "\n",
      "Epoch 159: val_loss improved from 1.88628 to 1.88378, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:09.048154: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:09.048196: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:09.048220: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4094 - loss: 1.9304 - val_accuracy: 0.4202 - val_loss: 1.8838\n",
      "Epoch 160/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4058 - loss: 1.9365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:09.376884: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:09.376927: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:09.376952: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_160_val_loss_1.8816.keras\n",
      "\n",
      "Epoch 160: val_loss improved from 1.88378 to 1.88160, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:09.655109: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:09.655148: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:09.655171: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4074 - loss: 1.9322 - val_accuracy: 0.4223 - val_loss: 1.8816\n",
      "Epoch 161/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4099 - loss: 1.9272\n",
      "Epoch 161: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_161_val_loss_1.8805.keras\n",
      "\n",
      "Epoch 161: val_loss improved from 1.88160 to 1.88047, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:15.147803: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:15.147843: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:15.147865: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4102 - loss: 1.9269 - val_accuracy: 0.4218 - val_loss: 1.8805\n",
      "Epoch 162/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4108 - loss: 1.9398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:15.409690: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:15.409728: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:15.409752: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 162: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_162_val_loss_1.8799.keras\n",
      "\n",
      "Epoch 162: val_loss improved from 1.88047 to 1.87995, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:15.675836: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:15.675877: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:15.675900: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4112 - loss: 1.9196 - val_accuracy: 0.4223 - val_loss: 1.8799\n",
      "Epoch 163/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4108 - loss: 1.9251\n",
      "Epoch 163: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_163_val_loss_1.8752.keras\n",
      "\n",
      "Epoch 163: val_loss improved from 1.87995 to 1.87518, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:21.125815: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:21.125887: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:21.125933: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4110 - loss: 1.9233 - val_accuracy: 0.4240 - val_loss: 1.8752\n",
      "Epoch 164/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4143 - loss: 1.9157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:21.418128: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 164: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_164_val_loss_1.8750.keras\n",
      "\n",
      "Epoch 164: val_loss improved from 1.87518 to 1.87495, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:21.701544: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:21.701583: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:21.701605: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4157 - loss: 1.9120 - val_accuracy: 0.4230 - val_loss: 1.8750\n",
      "Epoch 165/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4120 - loss: 1.9199\n",
      "Epoch 165: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_165_val_loss_1.8718.keras\n",
      "\n",
      "Epoch 165: val_loss improved from 1.87495 to 1.87184, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:27.321196: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:27.321231: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:27.321254: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4118 - loss: 1.9210 - val_accuracy: 0.4241 - val_loss: 1.8718\n",
      "Epoch 166/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4177 - loss: 1.8994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:27.609863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:27.609923: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:27.609959: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 166: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_166_val_loss_1.8708.keras\n",
      "\n",
      "Epoch 166: val_loss improved from 1.87184 to 1.87083, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:27.890143: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:27.890183: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:27.890205: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4141 - loss: 1.9109 - val_accuracy: 0.4244 - val_loss: 1.8708\n",
      "Epoch 167/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4120 - loss: 1.9180\n",
      "Epoch 167: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_167_val_loss_1.8694.keras\n",
      "\n",
      "Epoch 167: val_loss improved from 1.87083 to 1.86935, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:33.736165: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:33.736203: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:33.736225: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4122 - loss: 1.9178 - val_accuracy: 0.4254 - val_loss: 1.8694\n",
      "Epoch 168/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4139 - loss: 1.9142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:34.037692: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 168: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_168_val_loss_1.8686.keras\n",
      "\n",
      "Epoch 168: val_loss improved from 1.86935 to 1.86861, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:34.260958: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:34.260997: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:34.261018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4105 - loss: 1.9268 - val_accuracy: 0.4260 - val_loss: 1.8686\n",
      "Epoch 169/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4127 - loss: 1.9161\n",
      "Epoch 169: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_169_val_loss_1.8648.keras\n",
      "\n",
      "Epoch 169: val_loss improved from 1.86861 to 1.86478, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:38.633892: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:38.633937: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:38.633961: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4130 - loss: 1.9153 - val_accuracy: 0.4265 - val_loss: 1.8648\n",
      "Epoch 170/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4156 - loss: 1.9245\n",
      "Epoch 170: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_170_val_loss_1.8649.keras\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.86478\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.4128 - loss: 1.9205 - val_accuracy: 0.4264 - val_loss: 1.8649\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:39.149910: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4135 - loss: 1.9129\n",
      "Epoch 171: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_171_val_loss_1.8623.keras\n",
      "\n",
      "Epoch 171: val_loss improved from 1.86478 to 1.86228, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:44.315676: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:44.315715: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:44.315737: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4137 - loss: 1.9126 - val_accuracy: 0.4268 - val_loss: 1.8623\n",
      "Epoch 172/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4198 - loss: 1.8981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:44.629398: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:44.629444: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:44.629472: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 172: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_172_val_loss_1.8618.keras\n",
      "\n",
      "Epoch 172: val_loss improved from 1.86228 to 1.86181, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:44.885579: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:44.885628: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:44.885649: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4112 - loss: 1.9170 - val_accuracy: 0.4270 - val_loss: 1.8618\n",
      "Epoch 173/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4141 - loss: 1.9105\n",
      "Epoch 173: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_173_val_loss_1.8599.keras\n",
      "\n",
      "Epoch 173: val_loss improved from 1.86181 to 1.85993, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:50.140054: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:50.140108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4144 - loss: 1.9100 - val_accuracy: 0.4274 - val_loss: 1.8599\n",
      "Epoch 174/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4154 - loss: 1.9079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:50.408689: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:50.408745: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:50.408781: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 174: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_174_val_loss_1.8619.keras\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.85993\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4126 - loss: 1.9158 - val_accuracy: 0.4271 - val_loss: 1.8619\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:50.676701: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:50.676739: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:50.676761: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4147 - loss: 1.9082\n",
      "Epoch 175: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_175_val_loss_1.8589.keras\n",
      "\n",
      "Epoch 175: val_loss improved from 1.85993 to 1.85886, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:56.393560: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:56.393608: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4147 - loss: 1.9077 - val_accuracy: 0.4280 - val_loss: 1.8589\n",
      "Epoch 176/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4167 - loss: 1.8985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:56.696312: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 176: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_176_val_loss_1.8583.keras\n",
      "\n",
      "Epoch 176: val_loss improved from 1.85886 to 1.85831, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:56.929134: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:56.929201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4169 - loss: 1.8994 - val_accuracy: 0.4283 - val_loss: 1.8583\n",
      "Epoch 177/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4153 - loss: 1.9063\n",
      "Epoch 177: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_177_val_loss_1.8554.keras\n",
      "\n",
      "Epoch 177: val_loss improved from 1.85831 to 1.85538, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:02.419331: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:02.419366: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:02.419388: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4154 - loss: 1.9058 - val_accuracy: 0.4297 - val_loss: 1.8554\n",
      "Epoch 178/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4140 - loss: 1.9078\n",
      "Epoch 178: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_178_val_loss_1.8548.keras\n",
      "\n",
      "Epoch 178: val_loss improved from 1.85538 to 1.85477, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:02.956086: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:02.956129: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:02.956153: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4132 - loss: 1.9111 - val_accuracy: 0.4287 - val_loss: 1.8548\n",
      "Epoch 179/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4156 - loss: 1.9047\n",
      "Epoch 179: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_179_val_loss_1.8520.keras\n",
      "\n",
      "Epoch 179: val_loss improved from 1.85477 to 1.85200, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:08.350310: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:08.350351: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:08.350375: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4158 - loss: 1.9033 - val_accuracy: 0.4297 - val_loss: 1.8520\n",
      "Epoch 180/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4169 - loss: 1.9026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:08.637026: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:08.637073: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:08.637102: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_180_val_loss_1.8528.keras\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.85200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.4176 - loss: 1.8978 - val_accuracy: 0.4296 - val_loss: 1.8528\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:08.845878: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:08.845917: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:08.845939: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m470/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4162 - loss: 1.9018\n",
      "Epoch 181: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_181_val_loss_1.8506.keras\n",
      "\n",
      "Epoch 181: val_loss improved from 1.85200 to 1.85058, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:13.304620: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:13.304659: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:13.304680: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4165 - loss: 1.9014 - val_accuracy: 0.4300 - val_loss: 1.8506\n",
      "Epoch 182/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4124 - loss: 1.9231\n",
      "Epoch 182: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_182_val_loss_1.8497.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:13.599987: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:13.600028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:13.600052: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:57:13.790931: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:13.790970: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:13.790993: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 182: val_loss improved from 1.85058 to 1.84974, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.4144 - loss: 1.9079 - val_accuracy: 0.4298 - val_loss: 1.8497\n",
      "Epoch 183/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4170 - loss: 1.9006\n",
      "Epoch 183: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_183_val_loss_1.8495.keras\n",
      "\n",
      "Epoch 183: val_loss improved from 1.84974 to 1.84955, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:17.986921: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:17.986966: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:17.986987: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4168 - loss: 1.8999 - val_accuracy: 0.4301 - val_loss: 1.8495\n",
      "Epoch 184/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4253 - loss: 1.8691\n",
      "Epoch 184: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_184_val_loss_1.8478.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:18.275812: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:18.275865: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:18.275890: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:57:18.467609: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:18.467645: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:18.467667: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 184: val_loss improved from 1.84955 to 1.84780, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.4216 - loss: 1.8830 - val_accuracy: 0.4303 - val_loss: 1.8478\n",
      "Epoch 185/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4169 - loss: 1.8990\n",
      "Epoch 185: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_185_val_loss_1.8492.keras\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.84780\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4172 - loss: 1.8981 - val_accuracy: 0.4301 - val_loss: 1.8492\n",
      "Epoch 186/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4208 - loss: 1.8846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:24.148148: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:24.148188: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:24.148211: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4210 - loss: 1.8877 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:24.390535: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:24.390577: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:24.390600: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 186: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_186_val_loss_1.8471.keras\n",
      "\n",
      "Epoch 186: val_loss improved from 1.84780 to 1.84708, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:24.657801: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:24.657840: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:24.657863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4204 - loss: 1.8883 - val_accuracy: 0.4303 - val_loss: 1.8471\n",
      "Epoch 187/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4177 - loss: 1.8968\n",
      "Epoch 187: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_187_val_loss_1.8442.keras\n",
      "\n",
      "Epoch 187: val_loss improved from 1.84708 to 1.84422, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:30.244436: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:30.244485: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:30.244506: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4176 - loss: 1.8970 - val_accuracy: 0.4313 - val_loss: 1.8442\n",
      "Epoch 188/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4037 - loss: 1.9358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:30.562892: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 188: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_188_val_loss_1.8447.keras\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.84422\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.4180 - loss: 1.8938 - val_accuracy: 0.4313 - val_loss: 1.8447\n",
      "Epoch 189/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:30.803937: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:30.803977: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:30.803998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4183 - loss: 1.8938\n",
      "Epoch 189: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_189_val_loss_1.8443.keras\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.84422\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4179 - loss: 1.8951 - val_accuracy: 0.4318 - val_loss: 1.8443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:36.364936: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:36.364998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4156 - loss: 1.8964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:36.636972: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:36.637011: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:36.637035: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 190: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_190_val_loss_1.8432.keras\n",
      "\n",
      "Epoch 190: val_loss improved from 1.84422 to 1.84322, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:36.849400: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:36.849441: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:36.849463: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4177 - loss: 1.8934 - val_accuracy: 0.4315 - val_loss: 1.8432\n",
      "Epoch 191/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4181 - loss: 1.8959\n",
      "Epoch 191: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_191_val_loss_1.8425.keras\n",
      "\n",
      "Epoch 191: val_loss improved from 1.84322 to 1.84254, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:43.825490: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:57:43.825578: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4184 - loss: 1.8938 - val_accuracy: 0.4322 - val_loss: 1.8425\n",
      "Epoch 192/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4170 - loss: 1.8960\n",
      "Epoch 192: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_192_val_loss_1.8410.keras\n",
      "\n",
      "Epoch 192: val_loss improved from 1.84254 to 1.84103, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:44.471311: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:44.471403: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:44.471451: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4165 - loss: 1.8923 - val_accuracy: 0.4325 - val_loss: 1.8410\n",
      "Epoch 193/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4180 - loss: 1.8934\n",
      "Epoch 193: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_193_val_loss_1.8414.keras\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.84103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:50.441269: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:50.441328: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4186 - loss: 1.8929 - val_accuracy: 0.4316 - val_loss: 1.8414\n",
      "Epoch 194/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4184 - loss: 1.8811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:50.796991: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 194: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_194_val_loss_1.8405.keras\n",
      "\n",
      "Epoch 194: val_loss improved from 1.84103 to 1.84047, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:51.117372: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:51.117425: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:51.117456: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4196 - loss: 1.8818 - val_accuracy: 0.4318 - val_loss: 1.8405\n",
      "Epoch 195/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4192 - loss: 1.8908\n",
      "Epoch 195: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_195_val_loss_1.8401.keras\n",
      "\n",
      "Epoch 195: val_loss improved from 1.84047 to 1.84012, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:57.715096: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:57.715161: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:57.715195: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.4190 - loss: 1.8908 - val_accuracy: 0.4323 - val_loss: 1.8401\n",
      "Epoch 196/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4161 - loss: 1.8981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:58.100941: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:58.101016: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:58.101069: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 196: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_196_val_loss_1.8401.keras\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.84012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:58.419448: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:58.419532: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:58.419586: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4189 - loss: 1.8874 - val_accuracy: 0.4326 - val_loss: 1.8401\n",
      "Epoch 197/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4192 - loss: 1.8912\n",
      "Epoch 197: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_197_val_loss_1.8386.keras\n",
      "\n",
      "Epoch 197: val_loss improved from 1.84012 to 1.83861, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:05.104183: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:05.104223: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:05.104245: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4194 - loss: 1.8901 - val_accuracy: 0.4330 - val_loss: 1.8386\n",
      "Epoch 198/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4161 - loss: 1.8993\n",
      "Epoch 198: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_198_val_loss_1.8397.keras\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.83861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:05.737384: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:05.737468: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:05.737535: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4178 - loss: 1.8937 - val_accuracy: 0.4328 - val_loss: 1.8397\n",
      "Epoch 199/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4195 - loss: 1.8890\n",
      "Epoch 199: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_199_val_loss_1.8371.keras\n",
      "\n",
      "Epoch 199: val_loss improved from 1.83861 to 1.83715, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:12.003472: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:12.003537: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:12.003576: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4196 - loss: 1.8894 - val_accuracy: 0.4332 - val_loss: 1.8371\n",
      "Epoch 200/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4202 - loss: 1.8936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:12.362553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:12.362638: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:12.362684: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_200_val_loss_1.8368.keras\n",
      "\n",
      "Epoch 200: val_loss improved from 1.83715 to 1.83679, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:12.620317: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:12.620355: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:12.620376: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4169 - loss: 1.8961 - val_accuracy: 0.4331 - val_loss: 1.8368\n",
      "Epoch 201/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4200 - loss: 1.8883\n",
      "Epoch 201: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_201_val_loss_1.8362.keras\n",
      "\n",
      "Epoch 201: val_loss improved from 1.83679 to 1.83625, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:18.448857: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:18.448908: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4196 - loss: 1.8884 - val_accuracy: 0.4336 - val_loss: 1.8362\n",
      "Epoch 202/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4263 - loss: 1.8937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:18.765170: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:18.765210: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:18.765233: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 202: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_202_val_loss_1.8362.keras\n",
      "\n",
      "Epoch 202: val_loss improved from 1.83625 to 1.83619, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:18.987689: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:18.987747: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:18.987759: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4187 - loss: 1.8917 - val_accuracy: 0.4333 - val_loss: 1.8362\n",
      "Epoch 203/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4196 - loss: 1.8894\n",
      "Epoch 203: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_203_val_loss_1.8361.keras\n",
      "\n",
      "Epoch 203: val_loss improved from 1.83619 to 1.83613, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:24.971824: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:24.971863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:24.971885: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4199 - loss: 1.8878 - val_accuracy: 0.4337 - val_loss: 1.8361\n",
      "Epoch 204/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4226 - loss: 1.8899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:25.254080: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 204: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_204_val_loss_1.8354.keras\n",
      "\n",
      "Epoch 204: val_loss improved from 1.83613 to 1.83538, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:25.472925: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:25.472968: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:25.472992: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4196 - loss: 1.8874 - val_accuracy: 0.4337 - val_loss: 1.8354\n",
      "Epoch 205/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4199 - loss: 1.8867\n",
      "Epoch 205: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_205_val_loss_1.8355.keras\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.83538\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4199 - loss: 1.8871 - val_accuracy: 0.4334 - val_loss: 1.8355\n",
      "Epoch 206/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4163 - loss: 1.9176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:30.031874: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:30.031914: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:30.031937: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:30.252211: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:30.252253: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:30.252278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 206: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_206_val_loss_1.8340.keras\n",
      "\n",
      "Epoch 206: val_loss improved from 1.83538 to 1.83396, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:30.453344: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:30.453380: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:30.453400: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4223 - loss: 1.8877 - val_accuracy: 0.4339 - val_loss: 1.8340\n",
      "Epoch 207/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4207 - loss: 1.8861\n",
      "Epoch 207: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_207_val_loss_1.8341.keras\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.83396\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4203 - loss: 1.8866 - val_accuracy: 0.4338 - val_loss: 1.8341\n",
      "Epoch 208/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4192 - loss: 1.8805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:34.287092: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:34.287129: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:34.287151: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:34.510491: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:34.510535: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:34.510558: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 208: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_208_val_loss_1.8354.keras\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.83396\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.4174 - loss: 1.8854 - val_accuracy: 0.4336 - val_loss: 1.8354\n",
      "Epoch 209/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:34.722622: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:34.722661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:34.722683: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4200 - loss: 1.8858\n",
      "Epoch 209: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_209_val_loss_1.8349.keras\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.83396\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4203 - loss: 1.8859 - val_accuracy: 0.4334 - val_loss: 1.8349\n",
      "Epoch 210/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4244 - loss: 1.8902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:38.925517: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:38.925571: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:39.150548: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 210: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_210_val_loss_1.8338.keras\n",
      "\n",
      "Epoch 210: val_loss improved from 1.83396 to 1.83377, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:39.360553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:39.360593: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:39.360615: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4197 - loss: 1.8925 - val_accuracy: 0.4339 - val_loss: 1.8338\n",
      "Epoch 211/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4200 - loss: 1.8866\n",
      "Epoch 211: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_211_val_loss_1.8336.keras\n",
      "\n",
      "Epoch 211: val_loss improved from 1.83377 to 1.83361, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:43.945601: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:43.945639: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:43.945661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4204 - loss: 1.8857 - val_accuracy: 0.4339 - val_loss: 1.8336\n",
      "Epoch 212/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4202 - loss: 1.9039\n",
      "Epoch 212: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_212_val_loss_1.8336.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:44.228004: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:44.228044: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:44.228066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:44.423691: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:44.423732: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:44.423754: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 212: val_loss did not improve from 1.83361\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.4225 - loss: 1.8797 - val_accuracy: 0.4339 - val_loss: 1.8336\n",
      "Epoch 213/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4208 - loss: 1.8856\n",
      "Epoch 213: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_213_val_loss_1.8320.keras\n",
      "\n",
      "Epoch 213: val_loss improved from 1.83361 to 1.83200, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:48.166123: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4208 - loss: 1.8850 - val_accuracy: 0.4343 - val_loss: 1.8320\n",
      "Epoch 214/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4147 - loss: 1.8967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:48.431437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 214: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_214_val_loss_1.8328.keras\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.4211 - loss: 1.8802 - val_accuracy: 0.4345 - val_loss: 1.8328\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:48.664912: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:48.664950: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:48.664973: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4205 - loss: 1.8848\n",
      "Epoch 215: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_215_val_loss_1.8340.keras\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4207 - loss: 1.8846 - val_accuracy: 0.4339 - val_loss: 1.8340\n",
      "Epoch 216/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4175 - loss: 1.8922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:53.012326: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:53.012364: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:53.012386: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:53.224264: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:53.224304: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:53.224328: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 216: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_216_val_loss_1.8330.keras\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.4218 - loss: 1.8846 - val_accuracy: 0.4342 - val_loss: 1.8330\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:53.450131: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:53.450168: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:53.450191: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4212 - loss: 1.8847\n",
      "Epoch 217: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_217_val_loss_1.8325.keras\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4211 - loss: 1.8842 - val_accuracy: 0.4342 - val_loss: 1.8325\n",
      "Epoch 218/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4078 - loss: 1.9121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:57.357876: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:57.357917: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:57.357942: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 218: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_218_val_loss_1.8327.keras\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.4191 - loss: 1.8862 - val_accuracy: 0.4339 - val_loss: 1.8327\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:57.775433: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:57.775469: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:57.775490: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4210 - loss: 1.8843\n",
      "Epoch 219: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_219_val_loss_1.8328.keras\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4208 - loss: 1.8844 - val_accuracy: 0.4339 - val_loss: 1.8328\n",
      "Epoch 220/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4122 - loss: 1.9098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:03.588362: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-08-30 05:59:03.588404: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:03.588411: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:03.588432: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4209 - loss: 1.8903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:03.814316: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:03.814410: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 220: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_220_val_loss_1.8326.keras\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4236 - loss: 1.8803 - val_accuracy: 0.4341 - val_loss: 1.8326\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:04.123593: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:04.123635: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:04.123661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4207 - loss: 1.8845\n",
      "Epoch 221: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_221_val_loss_1.8323.keras\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4210 - loss: 1.8841 - val_accuracy: 0.4341 - val_loss: 1.8323\n",
      "Epoch 222/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4183 - loss: 1.8761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:09.041899: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:09.041940: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:09.041963: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 222: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_222_val_loss_1.8331.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:09.255621: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:09.255667: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:09.255697: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:09.450973: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:09.451012: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:09.451035: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 222: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.4218 - loss: 1.8741 - val_accuracy: 0.4336 - val_loss: 1.8331\n",
      "Epoch 223/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4212 - loss: 1.8828\n",
      "Epoch 223: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_223_val_loss_1.8313.keras\n",
      "\n",
      "Epoch 223: val_loss improved from 1.83200 to 1.83129, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:13.937850: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:13.937888: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:13.937911: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4208 - loss: 1.8840 - val_accuracy: 0.4345 - val_loss: 1.8313\n",
      "Epoch 224/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4379 - loss: 1.8542\n",
      "Epoch 224: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_224_val_loss_1.8324.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:14.194228: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:14.387029: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:14.387068: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:14.387089: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 224: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.4235 - loss: 1.8803 - val_accuracy: 0.4340 - val_loss: 1.8324\n",
      "Epoch 225/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4212 - loss: 1.8825\n",
      "Epoch 225: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_225_val_loss_1.8321.keras\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4210 - loss: 1.8840 - val_accuracy: 0.4339 - val_loss: 1.8321\n",
      "Epoch 226/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4207 - loss: 1.8796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:20.112736: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:20.112778: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:20.112800: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 226: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_226_val_loss_1.8315.keras\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.4221 - loss: 1.8769 - val_accuracy: 0.4348 - val_loss: 1.8315\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:20.564988: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:20.565028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:20.565051: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4211 - loss: 1.8832\n",
      "Epoch 227: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_227_val_loss_1.8314.keras\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4210 - loss: 1.8839 - val_accuracy: 0.4343 - val_loss: 1.8314\n",
      "Epoch 228/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4264 - loss: 1.8770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:26.196775: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:26.196816: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:26.196837: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:26.408379: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:26.408424: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:26.408448: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 228: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_228_val_loss_1.8326.keras\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.4208 - loss: 1.8815 - val_accuracy: 0.4345 - val_loss: 1.8326\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:26.643549: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:26.643589: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:26.643612: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4209 - loss: 1.8847\n",
      "Epoch 229: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_229_val_loss_1.8323.keras\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4210 - loss: 1.8831 - val_accuracy: 0.4339 - val_loss: 1.8323\n",
      "Epoch 230/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4213 - loss: 1.8930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:32.535014: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4215 - loss: 1.8924\n",
      "Epoch 230: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_230_val_loss_1.8325.keras\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4205 - loss: 1.8958 - val_accuracy: 0.4343 - val_loss: 1.8325\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:33.029431: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:33.029472: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:33.029494: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4210 - loss: 1.8838\n",
      "Epoch 231: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_231_val_loss_1.8331.keras\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4211 - loss: 1.8834 - val_accuracy: 0.4339 - val_loss: 1.8331\n",
      "Epoch 232/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4307 - loss: 1.8457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:37.746615: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:37.746655: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:37.746677: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:37.964604: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 232: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_232_val_loss_1.8322.keras\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.83129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:38.251228: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:38.251307: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:38.251354: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4238 - loss: 1.8775 - val_accuracy: 0.4341 - val_loss: 1.8322\n",
      "Epoch 233/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4210 - loss: 1.8840\n",
      "Epoch 233: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_233_val_loss_1.8321.keras\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4211 - loss: 1.8837 - val_accuracy: 0.4345 - val_loss: 1.8321\n",
      "Epoch 233: early stopping\n",
      "Restoring model weights from the end of the best epoch: 223.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:45.027896: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:45.027970: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:45.028045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "Best validation loss: 1.8313\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    # Save model every epoch with epoch number\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='/home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_{epoch:02d}_val_loss_{val_loss:.4f}.keras',\n",
    "        save_freq='epoch',\n",
    "        save_best_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save best model separately\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # More reasonable early stopping\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,  # Wait 50 epochs before stopping\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "\n",
    "    keras.callbacks.CSVLogger('training_log.csv'),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=\"./char_logs\", \n",
    "        histogram_freq=1, \n",
    "        profile_batch=0,\n",
    "        write_graph=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Training\n",
    "print(\"Starting training...\")\n",
    "print(f\"Total epochs: 100\")\n",
    "print(f\"Steps per epoch: {steps_64}\")\n",
    "print(f\"Total steps: {100 * steps_64}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_64,\n",
    "    validation_data=val_ds_64,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=steps_64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "if 'learning_rate' in history.history:\n",
    "    plt.plot(history.history['learning_rate'])\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "train_perplexity = [np.exp(loss) for loss in history.history['loss']]\n",
    "val_perplexity = [np.exp(loss) for loss in history.history['val_loss']]\n",
    "plt.plot(train_perplexity, label='Train Perplexity')\n",
    "plt.plot(val_perplexity, label='Val Perplexity')\n",
    "plt.title('Perplexity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c498d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now training should work\n",
    "# history = model.fit(\n",
    "#     train_ds_32,\n",
    "#     validation_data=val_ds_32,\n",
    "#     epochs=50,\n",
    "#     steps_per_epoch=steps_32,\n",
    "#     callbacks=[\n",
    "#         keras.callbacks.ModelCheckpoint(filepath='model_epoch_{epoch:02d}.keras',save_freq='epoch'),  # saves with epoch number   save_freq='epoch',                        # save every epoch    save_best_only=False,                     # save all epochs    verbose=1)\n",
    "#         keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True, verbose=1),\n",
    "#         keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=10, verbose=1),\n",
    "#         keras.callbacks.CSVLogger('training_log.csv'),\n",
    "#         keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1, profile_batch=0)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e45dbc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Positional embeddings are working. Shape: (1, 128, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    }
   ],
   "source": [
    "# pick a small dummy batch\n",
    "import tensorflow as tf\n",
    "\n",
    "dum_model = GPT(D_MODEL, VOCAB_SIZE, CONTEXT_LEN, 8, 0.00001, 4, 0.1)\n",
    "dummy_input = tf.constant([[0] * CONTEXT_LEN], dtype=tf.int32)  # batch_size=1, length=CONTEXT_LEN\n",
    "dum_model.save('model_epoch_1.keras')\n",
    "# run the embeddings layer only\n",
    "pos_layer = dum_model.get_layer('init_embeddings')  # or however your layer is named\n",
    "try:\n",
    "    pos_emb = pos_layer(dummy_input)\n",
    "    print(\"✅ Positional embeddings are working. Shape:\", pos_emb.shape)\n",
    "except Exception as e:\n",
    "    print(\"❌ Embedding test failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc2606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0b33b98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'final_gpt_model.keras'\n",
      "Training history saved as 'training_history.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Save the final model\n",
    "model.save('final_gpt_model.keras')\n",
    "print(\"Model saved as 'final_gpt_model.keras'\")\n",
    "\n",
    "# Optional: Save training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"Training history saved as 'training_history.pkl'\")\n",
    "\n",
    "# Step 5: Load model later (when needed)\n",
    "def load_trained_model():\n",
    "    \"\"\"Load your saved model\"\"\"\n",
    "    loaded_model = keras.models.load_model('best_model.keras')  # or 'final_gpt_model.keras'\n",
    "    return loaded_model\n",
    "\n",
    "# Usage for inference later:\n",
    "# model = load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "87a42df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_model.save('dum_GPT.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "306ce64e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[307]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_299_val_loss_0.0130.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Loaded best_model.keras\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_299_val_loss_0.0130.keras. Please ensure the file is an accessible `.keras` zip file.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[307]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_163_val_loss_0.0303.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Loaded epoch 163 model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_163_val_loss_0.0303.keras. Please ensure the file is an accessible `.keras` zip file.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[307]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Loaded epoch 163 model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Loaded epoch 161 model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m CONTEXT_LEN = model._context_length  \u001b[38;5;66;03m# Use the model's actual context length\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# token_to_id_dict = tokenize_and_build_vocabulary_tf([r'/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt'])\n",
    "id_to_token_dict = {id_val: token for token, id_val in token_to_id_dict.items()}\n",
    "\n",
    "# Use the latest and best model - try the best_model.keras first, then latest checkpoint\n",
    "try:\n",
    "    model = keras.models.load_model(r'/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_299_val_loss_0.0130.keras')\n",
    "    print(\"✅ Loaded best_model.keras\")\n",
    "except:\n",
    "    try:\n",
    "        model = keras.models.load_model(r'/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_163_val_loss_0.0303.keras')\n",
    "        print(\"✅ Loaded epoch 163 model\")\n",
    "    except:\n",
    "        model = keras.models.load_model(r'/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras')\n",
    "        print(\"✅ Loaded epoch 161 model\")\n",
    "\n",
    "CONTEXT_LEN = model._context_length  # Use the model's actual context length\n",
    "\n",
    "# Debug: Print vocabulary info\n",
    "print(f\"Vocabulary size: {len(token_to_id_dict)}\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "\n",
    "# Get model info from your custom GPT model\n",
    "try:\n",
    "    print(f\"Model vocab size: {model._vocab_size}\")\n",
    "    print(f\"Model context length: {model._context_length}\")\n",
    "    print(f\"Model d_model: {model._d_model}\")\n",
    "    print(f\"Model attention heads: {model._attention_heads}\")\n",
    "    print(f\"Model decoder blocks: {model._decoder_blocks}\")\n",
    "    print(f\"Vocab size matches model: {model._vocab_size == len(token_to_id_dict)}\")\n",
    "    \n",
    "    if model._vocab_size != len(token_to_id_dict):\n",
    "        print(f\"⚠️  VOCAB SIZE MISMATCH! Model expects {model._vocab_size}, got {len(token_to_id_dict)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error getting model info: {e}\")\n",
    "\n",
    "print(f\"Sample characters in vocab: {list(token_to_id_dict.keys())[:30]}\")\n",
    "print(f\"Common characters present: {['a' in token_to_id_dict, 'e' in token_to_id_dict, ' ' in token_to_id_dict, '.' in token_to_id_dict]}\")\n",
    "\n",
    "# Check for problematic characters in the gibberish output\n",
    "gibberish = \"4ff.mtm 64m86rfstmfm?.fmmftms777mtmkf  tm7n7m77m77\"\n",
    "print(f\"Checking gibberish characters:\")\n",
    "for char in set(gibberish):\n",
    "    if char in token_to_id_dict:\n",
    "        print(f\"  '{char}' -> ID {token_to_id_dict[char]} ✓\")\n",
    "    else:\n",
    "        print(f\"  '{char}' -> NOT IN VOCAB ✗\")\n",
    "\n",
    "def encode_text(text, token_to_id_dict):\n",
    "    \"\"\"Encode text to token IDs using character-level tokenizer - convert to lowercase since dataset is lowercase\"\"\"\n",
    "    # Convert input to lowercase since your dataset was lowercased\n",
    "    text = text.lower()\n",
    "    \n",
    "    token_ids = []\n",
    "    for char in text:\n",
    "        if char in token_to_id_dict:\n",
    "            token_ids.append(token_to_id_dict[char])\n",
    "        else:\n",
    "            print(f\"Warning: '{char}' (ord: {ord(char)}) not in vocabulary, skipping\")\n",
    "            continue\n",
    "    return token_ids\n",
    "\n",
    "def decode_ids(token_ids, id_to_token_dict):\n",
    "    \"\"\"Decode token IDs back to text using character-level tokenizer\"\"\"\n",
    "    text = \"\"\n",
    "    for token_id in token_ids:\n",
    "        if token_id in id_to_token_dict:\n",
    "            text += id_to_token_dict[token_id]\n",
    "        else:\n",
    "            print(f\"Warning: token ID {token_id} not in vocabulary\")\n",
    "    return text\n",
    "\n",
    "def get_special_token_ids():\n",
    "    \"\"\"Get special token IDs - adjust these based on your tokenizer setup\"\"\"\n",
    "    # For Jane Austen data, likely no special PAD token, use newline as EOS\n",
    "    pad_id = token_to_id_dict.get('<PAD>', None)\n",
    "    eos_id = token_to_id_dict.get('\\n', None)  # Use newline as natural stopping point\n",
    "    print(f\"Special tokens - PAD: {pad_id}, EOS (newline): {eos_id}\")\n",
    "    return pad_id, eos_id\n",
    "\n",
    "def top_k_sampling(logits, k=10):\n",
    "    \"\"\"Sample from logits using top-k sampling\"\"\"\n",
    "    # Ensure we don't sample more than available tokens\n",
    "    k = min(k, len(logits))\n",
    "    \n",
    "    values, indices = tf.math.top_k(logits, k=k)\n",
    "    last_val = values[-1]\n",
    "    filtered_logits = tf.where(\n",
    "        logits < last_val,\n",
    "        tf.fill(tf.shape(logits), float('-inf')),\n",
    "        logits\n",
    "    )\n",
    "    probs = tf.nn.softmax(filtered_logits).numpy()\n",
    "    \n",
    "    # Add small epsilon to avoid numerical issues\n",
    "    probs = probs + 1e-10\n",
    "    probs = probs / np.sum(probs)\n",
    "    \n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "def generate_response(prompt, max_length=100, temperature=0.7, top_k=10, use_argmax=False):\n",
    "    if not prompt.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    print(f\"\\n--- Generation Debug ---\")\n",
    "    print(f\"Input prompt: '{prompt}' (will be lowercased)\")\n",
    "    \n",
    "    # Tokenize prompt with character-level tokenizer\n",
    "    input_tokens = encode_text(prompt, token_to_id_dict)\n",
    "    print(f\"Input tokens: {input_tokens}\")\n",
    "    print(f\"Input tokens decoded back: '{decode_ids(input_tokens, id_to_token_dict)}'\")\n",
    "    \n",
    "    if not input_tokens:\n",
    "        return \"Error: Could not tokenize input\"\n",
    "    \n",
    "    # Truncate if longer than context length\n",
    "    if len(input_tokens) > CONTEXT_LEN:\n",
    "        input_tokens = input_tokens[-CONTEXT_LEN:]\n",
    "    \n",
    "    generated_tokens = input_tokens.copy()\n",
    "    pad_id, eos_id = get_special_token_ids()\n",
    "    \n",
    "    print(f\"Starting generation with {len(input_tokens)} input tokens...\")\n",
    "    \n",
    "    for step in range(max_length):\n",
    "        # Prepare inputs - pad from left to maintain most recent context\n",
    "        input_ids = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "        attention_mask = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "        \n",
    "        # Place tokens at the end of the context window\n",
    "        current_len = min(len(generated_tokens), CONTEXT_LEN)\n",
    "        start_idx = CONTEXT_LEN - current_len\n",
    "        input_ids[0, start_idx:] = generated_tokens[-current_len:]\n",
    "        attention_mask[0, start_idx:] = 1\n",
    "        \n",
    "        # Model forward pass\n",
    "        try:\n",
    "            logits = model((input_ids, attention_mask), training=False)\n",
    "            next_token_logits = logits[0, -1, :]\n",
    "            \n",
    "            # Apply temperature\n",
    "            if not use_argmax:\n",
    "                next_token_logits = next_token_logits / temperature\n",
    "        except Exception as e:\n",
    "            print(f\"Model forward pass error: {e}\")\n",
    "            break\n",
    "        \n",
    "        # Sample next token\n",
    "        try:\n",
    "            if use_argmax:\n",
    "                # Use argmax (greedy) sampling for testing\n",
    "                next_token = int(np.argmax(next_token_logits))\n",
    "            else:\n",
    "                # Use top-k sampling\n",
    "                next_token = top_k_sampling(next_token_logits, k=top_k)\n",
    "        except Exception as e:\n",
    "            print(f\"Sampling error: {e}\")\n",
    "            break\n",
    "        \n",
    "        # Debug: Print first few tokens\n",
    "        if step < 10:\n",
    "            sampled_char = id_to_token_dict.get(next_token, f\"<UNK:{next_token}>\")\n",
    "            prob = float(tf.nn.softmax(next_token_logits)[next_token])\n",
    "            print(f\"Step {step}: Token {next_token} -> '{sampled_char}' (prob: {prob:.4f})\")\n",
    "        \n",
    "        # Check if token is valid\n",
    "        if next_token >= len(id_to_token_dict):\n",
    "            print(f\"Warning: Invalid token {next_token}, vocab size is {len(id_to_token_dict)}\")\n",
    "            break\n",
    "        \n",
    "        # Stop on special tokens\n",
    "        if pad_id is not None and next_token == pad_id:\n",
    "            print(f\"Stopping at step {step}: hit PAD token\")\n",
    "            break\n",
    "        if eos_id is not None and next_token == eos_id and step > 10:  # Don't stop too early\n",
    "            print(f\"Stopping at step {step}: hit EOS token (newline)\")\n",
    "            break\n",
    "        \n",
    "        generated_tokens.append(int(next_token))\n",
    "        \n",
    "        # Maintain sliding window\n",
    "        if len(generated_tokens) > CONTEXT_LEN:\n",
    "            generated_tokens = generated_tokens[-CONTEXT_LEN:]\n",
    "    \n",
    "    # Decode only the newly generated tokens\n",
    "    new_tokens = generated_tokens[len(input_tokens):]\n",
    "    response = decode_ids(new_tokens, id_to_token_dict)\n",
    "    print(f\"Generated {len(new_tokens)} new tokens: {new_tokens[:20]}...\")  # Show first 20\n",
    "    print(f\"Generated response: '{response}'\")\n",
    "    print(f\"--- End Debug ---\\n\")\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "def chat_fn(message, history, temperature, max_length, top_k, use_argmax):\n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "    \n",
    "    bot_response = generate_response(message, max_length=max_length, temperature=temperature, top_k=top_k, use_argmax=use_argmax)\n",
    "    history.append((message, bot_response))\n",
    "    return \"\", history\n",
    "\n",
    "# Quick test with the better model\n",
    "print(\"Testing improved model:\")\n",
    "test_cases = [\"the\", \"elizabeth\", \"it is a\"]\n",
    "\n",
    "for prompt in test_cases:\n",
    "    print(f\"\\nTesting with: '{prompt}'\")\n",
    "    tokens = encode_text(prompt, token_to_id_dict)\n",
    "    \n",
    "    # Create model input\n",
    "    input_ids = np.zeros((1, 256), dtype=np.int32)\n",
    "    attention_mask = np.zeros((1, 256), dtype=np.int32)\n",
    "    input_ids[0, -len(tokens):] = tokens\n",
    "    attention_mask[0, -len(tokens):] = 1\n",
    "    \n",
    "    # Get model predictions\n",
    "    logits = model((input_ids, attention_mask), training=False)\n",
    "    next_token_logits = logits[0, -1, :]\n",
    "    \n",
    "    # Show top 5 predictions\n",
    "    top_probs, top_indices = tf.nn.top_k(tf.nn.softmax(next_token_logits), k=5)\n",
    "    print(\"Top 5 predictions:\")\n",
    "    for i in range(5):\n",
    "        token_id = int(top_indices[i])\n",
    "        prob = float(top_probs[i])\n",
    "        char = id_to_token_dict.get(token_id, f\"UNK_{token_id}\")\n",
    "        print(f\"  {i+1}. '{char}' (ID: {token_id}) - {prob:.4f}\")\n",
    "\n",
    "# Test with longer context\n",
    "print(f\"\\nTesting with longer Jane Austen context:\")\n",
    "long_prompt = \"it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a\"\n",
    "tokens = encode_text(long_prompt, token_to_id_dict)\n",
    "print(f\"Context: '{long_prompt}'\")\n",
    "print(f\"Context length: {len(tokens)} tokens\")\n",
    "\n",
    "# Use reasonable context length\n",
    "context_tokens = tokens[-100:] if len(tokens) > 100 else tokens\n",
    "\n",
    "input_ids = np.zeros((1, 256), dtype=np.int32)\n",
    "attention_mask = np.zeros((1, 256), dtype=np.int32)\n",
    "input_ids[0, -len(context_tokens):] = context_tokens\n",
    "attention_mask[0, -len(context_tokens):] = 1\n",
    "\n",
    "logits = model((input_ids, attention_mask), training=False)\n",
    "next_token_logits = logits[0, -1, :]\n",
    "\n",
    "top_probs, top_indices = tf.nn.top_k(tf.nn.softmax(next_token_logits), k=5)\n",
    "print(\"Top 5 predictions after long context:\")\n",
    "for i in range(5):\n",
    "    token_id = int(top_indices[i])\n",
    "    prob = float(top_probs[i])\n",
    "    char = id_to_token_dict.get(token_id, f\"UNK_{token_id}\")\n",
    "    print(f\"  {i+1}. '{char}' (ID: {token_id}) - {prob:.4f}\")\n",
    "\n",
    "with gr.Blocks(title=\"My Character-Level GPT Bot Trained in Tensorflow\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# 🤖 Chat with Akshat's Character-Level GPT Model\")\n",
    "    gr.Markdown(\"Ask me anything! I'm a GPT model trained from scratch with character-level tokenization on Jane Austen data. Be gentle with me :)\")\n",
    "    \n",
    "    # Add vocab info\n",
    "    gr.Markdown(f\"**Model Info:** Vocabulary size: {len(token_to_id_dict)} characters\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(label=\"Conversation\", height=400, show_copy_button=True)\n",
    "    \n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(label=\"Your message\", placeholder=\"Type your message here...\", scale=4)\n",
    "        send_btn = gr.Button(\"Send\", scale=1, variant=\"primary\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        temperature = gr.Slider(minimum=0.1, maximum=1.5, value=0.3, step=0.05, label=\"Temperature\")\n",
    "        max_length = gr.Slider(minimum=10, maximum=200, value=30, step=10, label=\"Max Length\")\n",
    "        top_k = gr.Slider(minimum=1, maximum=50, value=5, step=1, label=\"Top-K Sampling\")\n",
    "        use_argmax = gr.Checkbox(label=\"Use Argmax (Greedy) - for testing\", value=True)\n",
    "    \n",
    "    clear_btn = gr.Button(\"Clear Chat\", variant=\"secondary\")\n",
    "    \n",
    "    # Event handlers\n",
    "    msg.submit(chat_fn, [msg, chatbot, temperature, max_length, top_k, use_argmax], [msg, chatbot])\n",
    "    send_btn.click(chat_fn, [msg, chatbot, temperature, max_length, top_k, use_argmax], [msg, chatbot])\n",
    "    clear_btn.click(lambda: [], None, chatbot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        share=True,          # Generate public share link\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=6019,\n",
    "        show_error=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468aeb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:  VxxZEtRh5HHeYXZtxnhx5ICxxetRx5(ZxZMqx55xejhPxYW4Rx\n",
      "GPT:  RcT2-LeJPeRHVpMKhzo37xBoxti\n",
      "GPT:  qt-45HxGefn5ZZx48.UxMeTRuOLzRHxt\n",
      "GPT:  RxHxtX5RmeMxHd2tZ\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[277]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Simple console loop\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     prompt = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prompt.lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1275\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1273\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1320\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1318\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1319\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, max_length=50, temperature=1.0):\n",
    "    input_tokens = [token_to_id_dict.get(c, 0) for c in prompt if c in token_to_id_dict]\n",
    "    if len(input_tokens) == 0:\n",
    "        input_tokens = [0]\n",
    "\n",
    "    if len(input_tokens) > CONTEXT_LEN:\n",
    "        input_tokens = input_tokens[-CONTEXT_LEN:]\n",
    "\n",
    "    input_ids = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "    input_ids[0, -len(input_tokens):] = input_tokens\n",
    "\n",
    "    attention_mask = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "    attention_mask[0, -len(input_tokens):] = 1\n",
    "\n",
    "    generated_tokens = input_tokens.copy()\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        predictions = model.predict([input_ids, attention_mask], verbose=0)\n",
    "        next_token_logits = predictions[0, -1, :] / temperature\n",
    "        probabilities = tf.nn.softmax(next_token_logits).numpy()\n",
    "        next_token = np.random.choice(len(probabilities), p=probabilities)\n",
    "\n",
    "        if next_token == 0:\n",
    "            break\n",
    "\n",
    "        generated_tokens.append(next_token)\n",
    "\n",
    "        # Update input_ids and attention_mask\n",
    "        if len(generated_tokens) > CONTEXT_LEN:\n",
    "            generated_tokens = generated_tokens[-CONTEXT_LEN:]\n",
    "\n",
    "        input_ids[0, -len(generated_tokens):] = generated_tokens\n",
    "        attention_mask[0, -len(generated_tokens):] = 1\n",
    "\n",
    "    id_to_token = {v: k for k, v in token_to_id_dict.items()}\n",
    "    return ''.join([id_to_token.get(t, '') for t in generated_tokens[len(input_tokens):]]).strip()\n",
    "\n",
    "\n",
    "# Simple console loop\n",
    "while True:\n",
    "    prompt = input(\"You: \")\n",
    "    if prompt.lower() in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "    response = generate_text(prompt, max_length=50, temperature=0.8)\n",
    "    print(\"GPT: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb3680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7fccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_token_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d11a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(sinusoidal_lookup_table.shape)  # should be (CONTEXT_LEN, D_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67921403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting comprehensive testing for YOUR custom model implementation...\n",
      "\n",
      "🔍 Testing sinusoidal lookup table creation...\n",
      "✅ Sinusoidal lookup table created successfully. Shape: (128, 128)\n",
      "   Table type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "   Table dtype: <dtype: 'float32'>\n",
      "\n",
      "🔍 Testing InitializePositionalEmbeddings layer...\n",
      "❌ Positional embeddings test failed: Unrecognized keyword arguments passed to InitializePositionalEmbeddings: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n",
      "\n",
      "🔍 Testing LayerNormalization layer...\n",
      "✅ LayerNormalization working. Input shape: (2, 128, 128), Output shape: (2, 128, 128)\n",
      "   Output mean (should be ~0): 0.000000\n",
      "   Output variance (should be ~1): 0.999990\n",
      "\n",
      "🔍 Testing YOUR SelfAttentionLayer...\n",
      "   Input embeddings shape: (2, 128, 128)\n",
      "   Attention mask shape: (2, 128)\n",
      "   Mask sample - seq 1: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] ... [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "✅ SelfAttentionLayer working. Output shape: (2, 128, 128)\n",
      "   Output range: [-0.7532, 0.7810]\n",
      "   Output mean: 0.0010\n",
      "   Output std: 0.0782\n",
      "   Attention heads: 8\n",
      "   d_head: 16\n",
      "   d_model: 128\n",
      "\n",
      "🔍 Testing YOUR DecoderBlock...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_206177/3617421218.py\", line 29, in test_positional_embeddings\n",
      "    pos_layer = InitializePositionalEmbeddings(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_206177/3965528913.py\", line 11, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 291, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Unrecognized keyword arguments passed to InitializePositionalEmbeddings: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Input shape: (2, 128, 128)\n",
      "   Attention mask shape: (2, 128)\n",
      "✅ DecoderBlock working (training=False). Output shape: (2, 128, 128)\n",
      "✅ DecoderBlock working (training=True). Output shape: (2, 128, 128)\n",
      "   Input mean: 0.0003, Output mean: -0.0041\n",
      "   Output range: [-4.3376, 4.7553]\n",
      "\n",
      "🔍 Testing YOUR complete GPT model...\n",
      "❌ Full model test failed: Unrecognized keyword arguments passed to GPT: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n",
      "\n",
      "🔍 Testing the specific embedding issue from your original code...\n",
      "❌ Original embedding test still fails: GPT.__init__() takes from 1 to 8 positional arguments but 9 were given\n",
      "\n",
      "======================================================================\n",
      "🎯 TESTING SUMMARY FOR YOUR CUSTOM MODEL:\n",
      "======================================================================\n",
      "Sinusoidal Lookup Table........................... ✅ PASSED\n",
      "Positional Embeddings............................. ❌ FAILED\n",
      "Layer Normalization............................... ✅ PASSED\n",
      "YOUR Self Attention Layer......................... ✅ PASSED\n",
      "YOUR Decoder Block................................ ✅ PASSED\n",
      "YOUR Full Model Forward Pass...................... ❌ FAILED\n",
      "YOUR Original Embedding Issue..................... ❌ FAILED\n",
      "Model Compilation & Training...................... ❌ FAILED\n",
      "\n",
      "🏆 Overall: 4/8 tests passed\n",
      "⚠️  Some tests failed. Please fix the issues before training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_206177/3617421218.py\", line 186, in test_your_full_model\n",
      "    model = GPT(\n",
      "            ^^^^\n",
      "  File \"/tmp/ipykernel_206177/1791215164.py\", line 64, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/models/model.py\", line 158, in __init__\n",
      "    Layer.__init__(self, *args, **kwargs)\n",
      "  File \"/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 291, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Unrecognized keyword arguments passed to GPT: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_206177/3617421218.py\", line 255, in test_specific_embedding_issue\n",
      "    dum_model = GPT(D_MODEL, VOCAB_SIZE, CONTEXT_LEN, 8, 0.00001, 4, 0.1, sinusoidal_lookup_table)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: GPT.__init__() takes from 1 to 8 positional arguments but 9 were given\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "# Model configuration\n",
    "CONTEXT_LEN = 128\n",
    "D_MODEL = 128\n",
    "VOCAB_SIZE = 94\n",
    "\n",
    "def test_sinusoidal_lookup_table():\n",
    "    \"\"\"Test the sinusoidal lookup table creation\"\"\"\n",
    "    print(\"🔍 Testing sinusoidal lookup table creation...\")\n",
    "    try:\n",
    "        sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL, CONTEXT_LEN)\n",
    "        print(f\"✅ Sinusoidal lookup table created successfully. Shape: {sinusoidal_lookup_table.shape}\")\n",
    "        print(f\"   Table type: {type(sinusoidal_lookup_table)}\")\n",
    "        print(f\"   Table dtype: {sinusoidal_lookup_table.dtype}\")\n",
    "        return sinusoidal_lookup_table\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Sinusoidal lookup table creation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_positional_embeddings(sinusoidal_lookup_table):\n",
    "    \"\"\"Test the positional embeddings layer\"\"\"\n",
    "    print(\"\\n🔍 Testing InitializePositionalEmbeddings layer...\")\n",
    "    \n",
    "    try:\n",
    "        # Create the layer\n",
    "        pos_layer = InitializePositionalEmbeddings(\n",
    "            d_model=D_MODEL,\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            sinusoidal_lookup_table=sinusoidal_lookup_table,\n",
    "            name=\"test_pos_embeddings\"\n",
    "        )\n",
    "        \n",
    "        # Test input\n",
    "        dummy_input = tf.constant([[1, 2, 3, 4, 5] + [0] * (CONTEXT_LEN - 5)], dtype=tf.int32)\n",
    "        print(f\"   Input shape: {dummy_input.shape}\")\n",
    "        \n",
    "        # Forward pass\n",
    "        pos_emb = pos_layer(dummy_input)\n",
    "        print(f\"✅ Positional embeddings working. Output shape: {pos_emb.shape}\")\n",
    "        print(f\"   Expected shape: (1, {CONTEXT_LEN}, {D_MODEL})\")\n",
    "        \n",
    "        # Check if embeddings are reasonable\n",
    "        print(f\"   Output range: [{tf.reduce_min(pos_emb):.4f}, {tf.reduce_max(pos_emb):.4f}]\")\n",
    "        print(f\"   Output mean: {tf.reduce_mean(pos_emb):.4f}\")\n",
    "        \n",
    "        return pos_layer, pos_emb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Positional embeddings test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_layer_normalization():\n",
    "    \"\"\"Test LayerNormalization layer\"\"\"\n",
    "    print(\"\\n🔍 Testing LayerNormalization layer...\")\n",
    "    \n",
    "    try:\n",
    "        ln = LayerNormalization(eps=1e-5, name=\"test_ln\")\n",
    "        test_input = tf.random.normal((2, CONTEXT_LEN, D_MODEL))\n",
    "        \n",
    "        output = ln(test_input)\n",
    "        print(f\"✅ LayerNormalization working. Input shape: {test_input.shape}, Output shape: {output.shape}\")\n",
    "        \n",
    "        # Check normalization properties\n",
    "        mean = tf.reduce_mean(output, axis=-1)\n",
    "        var = tf.reduce_mean(tf.square(output - tf.expand_dims(mean, -1)), axis=-1)\n",
    "        print(f\"   Output mean (should be ~0): {tf.reduce_mean(mean):.6f}\")\n",
    "        print(f\"   Output variance (should be ~1): {tf.reduce_mean(var):.6f}\")\n",
    "        \n",
    "        return ln, output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LayerNormalization test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_your_self_attention():\n",
    "    \"\"\"Test YOUR custom SelfAttentionLayer\"\"\"\n",
    "    print(\"\\n🔍 Testing YOUR SelfAttentionLayer...\")\n",
    "    \n",
    "    try:\n",
    "        # Create your attention layer with correct parameter name\n",
    "        attn_layer = SelfAttentionLayer(attention_heads=8, name=\"test_attention\")\n",
    "        \n",
    "        # Prepare test inputs\n",
    "        batch_size = 2\n",
    "        seq_len = CONTEXT_LEN\n",
    "        embeddings = tf.random.normal((batch_size, seq_len, D_MODEL))\n",
    "        \n",
    "        # Create attention mask (1 for real tokens, 0 for padding)\n",
    "        attention_mask = tf.ones((batch_size, seq_len), dtype=tf.float32)\n",
    "        # Make some positions masked (set to 0)\n",
    "        attention_mask = attention_mask.numpy()\n",
    "        attention_mask[0, 50:] = 0  # Mask second half of first sequence\n",
    "        attention_mask[1, 80:] = 0  # Mask last part of second sequence\n",
    "        attention_mask = tf.constant(attention_mask)\n",
    "        \n",
    "        print(f\"   Input embeddings shape: {embeddings.shape}\")\n",
    "        print(f\"   Attention mask shape: {attention_mask.shape}\")\n",
    "        print(f\"   Mask sample - seq 1: {attention_mask[0, :10].numpy()} ... {attention_mask[0, -10:].numpy()}\")\n",
    "        \n",
    "        # Test with your layer's expected input format: (embeddings, mask)\n",
    "        output = attn_layer([embeddings, attention_mask])\n",
    "        print(f\"✅ SelfAttentionLayer working. Output shape: {output.shape}\")\n",
    "        \n",
    "        # Check output properties\n",
    "        print(f\"   Output range: [{tf.reduce_min(output):.4f}, {tf.reduce_max(output):.4f}]\")\n",
    "        print(f\"   Output mean: {tf.reduce_mean(output):.4f}\")\n",
    "        print(f\"   Output std: {tf.math.reduce_std(output):.4f}\")\n",
    "        \n",
    "        # Verify attention heads are working\n",
    "        print(f\"   Attention heads: {attn_layer.attention_heads}\")\n",
    "        print(f\"   d_head: {attn_layer.d_head}\")\n",
    "        print(f\"   d_model: {attn_layer.d_model}\")\n",
    "        \n",
    "        return attn_layer, output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ SelfAttentionLayer test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_your_decoder_block():\n",
    "    \"\"\"Test YOUR custom DecoderBlock\"\"\"\n",
    "    print(\"\\n🔍 Testing YOUR DecoderBlock...\")\n",
    "    \n",
    "    try:\n",
    "        # Create your decoder block\n",
    "        decoder = DecoderBlock(\n",
    "            d_model=D_MODEL,\n",
    "            n_heads=8,\n",
    "            dropout_rate=0.1,\n",
    "            epsilon=1e-5,\n",
    "            name=\"test_decoder\"\n",
    "        )\n",
    "        \n",
    "        # Prepare test inputs\n",
    "        batch_size = 2\n",
    "        seq_len = CONTEXT_LEN\n",
    "        test_input = tf.random.normal((batch_size, seq_len, D_MODEL))\n",
    "        attention_mask = tf.ones((batch_size, seq_len), dtype=tf.float32)\n",
    "        \n",
    "        # Make some positions masked\n",
    "        attention_mask = attention_mask.numpy()\n",
    "        attention_mask[0, 60:] = 0\n",
    "        attention_mask[1, 90:] = 0\n",
    "        attention_mask = tf.constant(attention_mask)\n",
    "        \n",
    "        print(f\"   Input shape: {test_input.shape}\")\n",
    "        print(f\"   Attention mask shape: {attention_mask.shape}\")\n",
    "        \n",
    "        # Test training=False\n",
    "        output = decoder(test_input, attention_mask, training=False)\n",
    "        print(f\"✅ DecoderBlock working (training=False). Output shape: {output.shape}\")\n",
    "        \n",
    "        # Test training=True\n",
    "        output_train = decoder(test_input, attention_mask, training=True)\n",
    "        print(f\"✅ DecoderBlock working (training=True). Output shape: {output_train.shape}\")\n",
    "        \n",
    "        # Check residual connections work (output should be different from input)\n",
    "        input_mean = tf.reduce_mean(test_input)\n",
    "        output_mean = tf.reduce_mean(output)\n",
    "        print(f\"   Input mean: {input_mean:.4f}, Output mean: {output_mean:.4f}\")\n",
    "        print(f\"   Output range: [{tf.reduce_min(output):.4f}, {tf.reduce_max(output):.4f}]\")\n",
    "        \n",
    "        return decoder, output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ DecoderBlock test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_your_full_model(sinusoidal_lookup_table):\n",
    "    \"\"\"Test YOUR complete GPT model\"\"\"\n",
    "    print(\"\\n🔍 Testing YOUR complete GPT model...\")\n",
    "    \n",
    "    try:\n",
    "        # Create model exactly as you do\n",
    "        model = GPT(\n",
    "            d_model=D_MODEL,\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            context_length=CONTEXT_LEN,\n",
    "            attention_heads=8,\n",
    "            epsilon=1e-5,\n",
    "            decoder_blocks=4,\n",
    "            dropout_rate=0.1,\n",
    "            sinusoidal_lookup_table=sinusoidal_lookup_table,\n",
    "            name=\"test_gpt\"\n",
    "        )\n",
    "        \n",
    "        # Prepare test inputs\n",
    "        token_ids = tf.constant([[1, 2, 3, 4, 5] + [0] * (CONTEXT_LEN - 5)], dtype=tf.int32)\n",
    "        attention_mask = tf.ones((1, CONTEXT_LEN), dtype=tf.float32)\n",
    "        \n",
    "        # Set mask to 0 for padding tokens\n",
    "        attention_mask = attention_mask.numpy()\n",
    "        attention_mask[0, 5:] = 0  # Only first 5 tokens are real\n",
    "        attention_mask = tf.constant(attention_mask)\n",
    "        \n",
    "        print(f\"   Token IDs shape: {token_ids.shape}\")\n",
    "        print(f\"   Token IDs sample: {token_ids[0, :10].numpy()}\")\n",
    "        print(f\"   Attention mask shape: {attention_mask.shape}\")\n",
    "        print(f\"   Mask sample: {attention_mask[0, :10].numpy()}\")\n",
    "        \n",
    "        # Test forward pass\n",
    "        logits = model([token_ids, attention_mask], training=False)\n",
    "        print(f\"✅ Full model forward pass successful!\")\n",
    "        print(f\"   Output logits shape: {logits.shape}\")\n",
    "        print(f\"   Expected shape: (1, {CONTEXT_LEN}, {VOCAB_SIZE})\")\n",
    "        \n",
    "        # Check output properties\n",
    "        print(f\"   Logits range: [{tf.reduce_min(logits):.4f}, {tf.reduce_max(logits):.4f}]\")\n",
    "        print(f\"   Logits mean: {tf.reduce_mean(logits):.4f}\")\n",
    "        \n",
    "        # Test with different batch size\n",
    "        token_ids_batch = tf.constant([\n",
    "            [1, 2, 3] + [0] * (CONTEXT_LEN - 3),\n",
    "            [4, 5, 6, 7] + [0] * (CONTEXT_LEN - 4)\n",
    "        ], dtype=tf.int32)\n",
    "        attention_mask_batch = tf.ones((2, CONTEXT_LEN), dtype=tf.float32)\n",
    "        attention_mask_batch = attention_mask_batch.numpy()\n",
    "        attention_mask_batch[0, 3:] = 0  # First seq has 3 real tokens\n",
    "        attention_mask_batch[1, 4:] = 0  # Second seq has 4 real tokens\n",
    "        attention_mask_batch = tf.constant(attention_mask_batch)\n",
    "        \n",
    "        logits_batch = model([token_ids_batch, attention_mask_batch], training=False)\n",
    "        print(f\"✅ Batch processing successful! Output shape: {logits_batch.shape}\")\n",
    "        \n",
    "        # Test training mode\n",
    "        logits_train = model([token_ids, attention_mask], training=True)\n",
    "        print(f\"✅ Training mode successful! Output shape: {logits_train.shape}\")\n",
    "        \n",
    "        return model, logits\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Full model test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_specific_embedding_issue():\n",
    "    \"\"\"Test the specific embedding issue you encountered\"\"\"\n",
    "    print(\"\\n🔍 Testing the specific embedding issue from your original code...\")\n",
    "    \n",
    "    try:\n",
    "        # Create model exactly as you did\n",
    "        sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL, CONTEXT_LEN)\n",
    "        dum_model = GPT(D_MODEL, VOCAB_SIZE, CONTEXT_LEN, 8, 0.00001, 4, 0.1, sinusoidal_lookup_table)\n",
    "        \n",
    "        # Test exactly as you did\n",
    "        dummy_input = tf.constant([[0] * CONTEXT_LEN], dtype=tf.int32)\n",
    "        \n",
    "        # Get the embeddings layer\n",
    "        pos_layer = dum_model.get_layer('init_embeddings')\n",
    "        \n",
    "        # Run the embeddings layer\n",
    "        pos_emb = pos_layer(dummy_input)\n",
    "        print(f\"✅ Your original embedding test now works! Shape: {pos_emb.shape}\")\n",
    "        print(f\"   Input was all zeros: {dummy_input[0, :5].numpy()}\")\n",
    "        print(f\"   Output range: [{tf.reduce_min(pos_emb):.4f}, {tf.reduce_max(pos_emb):.4f}]\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Original embedding test still fails: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def test_model_compilation_and_training(model):\n",
    "    \"\"\"Test model compilation and training capability\"\"\"\n",
    "    print(\"\\n🔍 Testing model compilation and training...\")\n",
    "    \n",
    "    try:\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.AdamW(learning_rate=1e-4),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(\"✅ Model compilation successful!\")\n",
    "        \n",
    "        # Create dummy training data\n",
    "        batch_size = 4\n",
    "        dummy_x = tf.random.uniform((batch_size, CONTEXT_LEN), maxval=VOCAB_SIZE, dtype=tf.int32)\n",
    "        dummy_mask = tf.ones((batch_size, CONTEXT_LEN), dtype=tf.float32)\n",
    "        # Create some realistic masking\n",
    "        for i in range(batch_size):\n",
    "            seq_len = tf.random.uniform([], minval=10, maxval=CONTEXT_LEN, dtype=tf.int32)\n",
    "            dummy_mask = dummy_mask.numpy()\n",
    "            dummy_mask[i, seq_len:] = 0\n",
    "            dummy_mask = tf.constant(dummy_mask)\n",
    "        \n",
    "        dummy_y = tf.random.uniform((batch_size, CONTEXT_LEN), maxval=VOCAB_SIZE, dtype=tf.int32)\n",
    "        \n",
    "        print(f\"   Training data shapes: X={dummy_x.shape}, mask={dummy_mask.shape}, Y={dummy_y.shape}\")\n",
    "        \n",
    "        # Test prediction\n",
    "        predictions = model.predict([dummy_x, dummy_mask], verbose=0)\n",
    "        print(f\"✅ Model prediction successful! Predictions shape: {predictions.shape}\")\n",
    "        \n",
    "        # Test training step\n",
    "        loss = model.train_on_batch([dummy_x, dummy_mask], dummy_y)\n",
    "        print(f\"✅ Training step successful! Loss: {loss}\")\n",
    "        \n",
    "        # Test model summary\n",
    "        print(f\"\\n📊 Model has {model.count_params():,} parameters\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Model compilation/training test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def run_all_tests_for_your_model():\n",
    "    \"\"\"Run all tests specifically for your model implementation\"\"\"\n",
    "    print(\"🚀 Starting comprehensive testing for YOUR custom model implementation...\\n\")\n",
    "    \n",
    "    # Test 1: Sinusoidal lookup table\n",
    "    sinusoidal_lookup_table = test_sinusoidal_lookup_table()\n",
    "    if sinusoidal_lookup_table is None:\n",
    "        print(\"❌ Cannot proceed without sinusoidal lookup table\")\n",
    "        return\n",
    "    \n",
    "    # Test 2: Positional embeddings\n",
    "    pos_layer, pos_emb = test_positional_embeddings(sinusoidal_lookup_table)\n",
    "    \n",
    "    # Test 3: Layer normalization\n",
    "    ln_layer, ln_output = test_layer_normalization()\n",
    "    \n",
    "    # Test 4: Your self attention\n",
    "    attn_layer, attn_output = test_your_self_attention()\n",
    "    \n",
    "    # Test 5: Your decoder block\n",
    "    decoder_layer, decoder_output = test_your_decoder_block()\n",
    "    \n",
    "    # Test 6: Your full model\n",
    "    model, logits = test_your_full_model(sinusoidal_lookup_table)\n",
    "    \n",
    "    # Test 7: Your specific embedding issue\n",
    "    embedding_issue_fixed = test_specific_embedding_issue()\n",
    "    \n",
    "    # Test 8: Model compilation and training\n",
    "    compilation_success = False\n",
    "    if model is not None:\n",
    "        compilation_success = test_model_compilation_and_training(model)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🎯 TESTING SUMMARY FOR YOUR CUSTOM MODEL:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    tests = [\n",
    "        (\"Sinusoidal Lookup Table\", sinusoidal_lookup_table is not None),\n",
    "        (\"Positional Embeddings\", pos_emb is not None),\n",
    "        (\"Layer Normalization\", ln_output is not None),\n",
    "        (\"YOUR Self Attention Layer\", attn_output is not None),\n",
    "        (\"YOUR Decoder Block\", decoder_output is not None),\n",
    "        (\"YOUR Full Model Forward Pass\", logits is not None),\n",
    "        (\"YOUR Original Embedding Issue\", embedding_issue_fixed),\n",
    "        (\"Model Compilation & Training\", compilation_success)\n",
    "    ]\n",
    "    \n",
    "    passed = sum(1 for _, result in tests if result)\n",
    "    total = len(tests)\n",
    "    \n",
    "    for test_name, result in tests:\n",
    "        status = \"✅ PASSED\" if result else \"❌ FAILED\"\n",
    "        print(f\"{test_name:.<50} {status}\")\n",
    "    \n",
    "    print(f\"\\n🏆 Overall: {passed}/{total} tests passed\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"🎉 All tests passed! Your model is working perfectly!\")\n",
    "        print(\"🚀 Your model is ready for training and inference!\")\n",
    "    elif passed >= total - 2:\n",
    "        print(\"🎊 Almost all tests passed! Your model is mostly working correctly!\")\n",
    "        print(\"🔧 Check the failed tests above for minor issues.\")\n",
    "    else:\n",
    "        print(\"⚠️  Some tests failed. Please fix the issues before training.\")\n",
    "    \n",
    "    return model if logits is not None else None\n",
    "\n",
    "# Run the tests\n",
    "if __name__ == \"__main__\":\n",
    "    final_model = run_all_tests_for_your_model()\n",
    "    \n",
    "    if final_model is not None:\n",
    "        print(f\"\\n🎁 Model returned successfully!\")\n",
    "        print(f\"   Total parameters: {final_model.count_params():,}\")\n",
    "        print(f\"   Ready for: training, inference, and saving!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39917dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_from_bot(model, token_to_id_dict, prompt, max_length=100, temperature=0.7, context_len=128):\n",
    "    \"\"\"Generate text response from your GPT model\"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    input_tokens = [token_to_id_dict.get(char, 0) for char in prompt]\n",
    "    \n",
    "    # Handle context length\n",
    "    if len(input_tokens) > context_len:\n",
    "        input_tokens = input_tokens[-context_len:]\n",
    "    \n",
    "    # Pad to context length\n",
    "    input_ids = np.zeros(context_len, dtype=np.int32)\n",
    "    if len(input_tokens) > 0:\n",
    "        input_ids[-len(input_tokens):] = input_tokens\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = np.zeros(context_len, dtype=np.int32)\n",
    "    if len(input_tokens) > 0:\n",
    "        attention_mask[-len(input_tokens):] = 1\n",
    "    \n",
    "    # Prepare for model\n",
    "    input_ids = np.expand_dims(input_ids, axis=0)\n",
    "    attention_mask = np.expand_dims(attention_mask, axis=0)\n",
    "    \n",
    "    # Generate response token by token\n",
    "    generated_tokens = input_tokens.copy()\n",
    "    id_to_token = {v: k for k, v in token_to_id_dict.items()}\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Get model predictions\n",
    "        predictions = model.predict([input_ids, attention_mask], verbose=0)\n",
    "        \n",
    "        # Get last token logits (find the last non-zero position in attention mask)\n",
    "        last_pos = np.sum(attention_mask[0]) - 1\n",
    "        if last_pos < 0:\n",
    "            last_pos = 0\n",
    "        next_token_logits = predictions[0, last_pos, :] / temperature\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        probabilities = tf.nn.softmax(next_token_logits).numpy()\n",
    "        \n",
    "        # Sample next token\n",
    "        next_token = np.random.choice(len(probabilities), p=probabilities)\n",
    "        \n",
    "        # Stop if we hit a stop token or newline\n",
    "        if next_token == 0 or (next_token in token_to_id_dict.values() and id_to_token[next_token] == '\\n'):\n",
    "            break\n",
    "            \n",
    "        generated_tokens.append(next_token)\n",
    "        \n",
    "        # Update input for next iteration\n",
    "        if len(generated_tokens) > context_len:\n",
    "            generated_tokens = generated_tokens[-context_len:]\n",
    "        \n",
    "        # Create new input\n",
    "        new_input_ids = np.zeros((1, context_len), dtype=np.int32)\n",
    "        if len(generated_tokens) > 0:\n",
    "            new_input_ids[0, -len(generated_tokens):] = generated_tokens\n",
    "        \n",
    "        new_attention_mask = np.zeros((1, context_len), dtype=np.int32)\n",
    "        if len(generated_tokens) > 0:\n",
    "            new_attention_mask[0, -len(generated_tokens):] = 1\n",
    "        \n",
    "        input_ids = new_input_ids\n",
    "        attention_mask = new_attention_mask\n",
    "    \n",
    "    # Convert tokens back to text\n",
    "    response_tokens = generated_tokens[len(input_tokens):]  # Only the new tokens\n",
    "    response = ''.join([id_to_token.get(token, '') for token in response_tokens])\n",
    "    \n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b200e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"]8'Vi3A;#sFöXöxr3ö][xöM6!dlwx—$pb:Orxx1JkW0:pöyyö;94œ!ööGHQöG:‘::$fwrg3Rg!R!/gxrgg/PöJIYPlö6öJ%6RpLp\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response_from_bot(model,token_to_id_dict,prompt = 'yoyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770fbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ada879",
   "metadata": {},
   "source": [
    "## 7. Notes & Next Steps\n",
    "Document any observations, issues, or future plans here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
