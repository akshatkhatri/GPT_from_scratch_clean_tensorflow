{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d92101e",
   "metadata": {},
   "source": [
    "# GPT Model Development Notebook\n",
    "This notebook is organized into the following sections:\n",
    "1. **Imports & Setup**\n",
    "2. **Data Loading & Preprocessing**\n",
    "3. **Model Architecture**\n",
    "4. **Training**\n",
    "5. **Evaluation & Results**\n",
    "6. **Saving & Exporting Model**\n",
    "7. **Notes & Next Steps**\n",
    "---\n",
    "Please follow the section headers and keep code and explanations grouped for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fad05",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup\n",
    "Import all required libraries and set up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d2d7a",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing\n",
    "Load your dataset and perform any necessary preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03cf42",
   "metadata": {},
   "source": [
    "## 6. Saving & Exporting Model\n",
    "Save your trained model and export as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133d2a4",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Results\n",
    "Evaluate your model and display results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b3f63",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "Train your model and monitor metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43169b8",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "Define your GPT model architecture here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62adc19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26b8fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "007f70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from typing import List, Dict, Tuple\n",
    "\n",
    "# def tokenize_and_build_vocabulary_tf(\n",
    "#     file_path_list: List[str] = [r\"/home/akshat/GPT_from_scratch/text_data/pg76702.txt\"],\n",
    "#     existing_vocab: Dict[str, int] = None # type: ignore\n",
    "# ) -> Tuple[tf.lookup.StaticHashTable, tf.lookup.StaticHashTable]:\n",
    "#     \"\"\"\n",
    "#     Build a character-level vocabulary from text files and return TensorFlow lookup tables.\n",
    "    \n",
    "#     Returns:\n",
    "#         token_to_id_table: tf.lookup.StaticHashTable mapping char -> int\n",
    "#         id_to_token_table: tf.lookup.StaticHashTable mapping int -> char\n",
    "#     \"\"\"\n",
    "#     if existing_vocab is None:\n",
    "#         existing_vocab = {}\n",
    "\n",
    "#     vocab_set = set(existing_vocab.keys())\n",
    "\n",
    "#     # Collect characters from all files\n",
    "#     for file_name in file_path_list:\n",
    "#         with open(file_name, encoding=\"utf-8\") as f:\n",
    "#             text = f.read()\n",
    "#             vocab_set.update(text)\n",
    "\n",
    "#     # Sort for consistency\n",
    "#     sorted_tokens = sorted(vocab_set)\n",
    "\n",
    "#     # Assign IDs (keep existing IDs if possible)\n",
    "#     token_to_id = {token: i for i, token in enumerate(sorted_tokens)}\n",
    "#     id_to_token = {i: token for token, i in token_to_id.items()}\n",
    "\n",
    "#     # Convert dicts to tensors\n",
    "#     token_keys = tf.constant(list(token_to_id.keys()))\n",
    "#     token_values = tf.constant(list(token_to_id.values()), dtype=tf.int32)\n",
    "\n",
    "#     id_keys = tf.constant(list(id_to_token.keys()), dtype=tf.int32)\n",
    "#     id_values = tf.constant(list(id_to_token.values()))\n",
    "\n",
    "#     # Create TensorFlow lookup tables\n",
    "#     token_to_id_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(token_keys, token_values),\n",
    "#         default_value=-1  # unknown token\n",
    "#     )\n",
    "#     id_to_token_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(id_keys, id_values),\n",
    "#         default_value=\"\"  # unknown ID\n",
    "#     )\n",
    "\n",
    "#     return token_to_id_table, id_to_token_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9856e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from typing import List, Dict, Tuple\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def tokenize_and_build_vocabulary_tf(\n",
    "#     file_path_list: List[str],\n",
    "#     existing_vocab: Dict[str, int] | None = None\n",
    "# ) -> Tuple[tf.lookup.StaticHashTable, tf.lookup.StaticHashTable]:\n",
    "#     \"\"\"\n",
    "#     Build a character-level vocabulary from text files and return TF lookup tables:\n",
    "#       token_to_id: char -> int\n",
    "#       id_to_token: int -> char\n",
    "#     \"\"\"\n",
    "#     if isinstance(file_path_list, (str, bytes)):\n",
    "#         file_path_list = [file_path_list] # type: ignore\n",
    "#     if existing_vocab is None:\n",
    "#         existing_vocab = {}\n",
    "\n",
    "#     vocab_set = set(existing_vocab.keys())\n",
    "#     for file_name in file_path_list:\n",
    "#         if os.path.isdir(file_name):\n",
    "#             raise IsADirectoryError(f\"Expected file path, got directory: {file_name}\")\n",
    "#         if not os.path.isfile(file_name):\n",
    "#             raise FileNotFoundError(f\"File not found: {file_name}\")\n",
    "#         with open(file_name, encoding=\"utf-8\") as f:\n",
    "#             text = f.read()\n",
    "#             vocab_set.update(text)\n",
    "\n",
    "#     sorted_tokens = sorted(vocab_set)\n",
    "#     token_to_id = {tok: i for i, tok in enumerate(sorted_tokens)}\n",
    "#     id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
    "\n",
    "#     token_keys = tf.constant(list(token_to_id.keys()), dtype=tf.string)\n",
    "#     token_vals = tf.constant(list(token_to_id.values()), dtype=tf.int32)\n",
    "\n",
    "#     id_keys = tf.constant(list(id_to_token.keys()), dtype=tf.int32)\n",
    "#     id_vals = tf.constant(list(id_to_token.values()), dtype=tf.string)\n",
    "\n",
    "#     token_to_id_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(token_keys, token_vals),\n",
    "#         default_value=-1\n",
    "#     )\n",
    "#     id_to_token_table = tf.lookup.StaticHashTable(\n",
    "#         initializer=tf.lookup.KeyValueTensorInitializer(id_keys, id_vals),\n",
    "#         default_value=tf.constant(\"\", dtype=tf.string)\n",
    "#     )\n",
    "#     return token_to_id_table, id_to_token_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b18d7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "@keras.saving.register_keras_serializable()\n",
    "def prepare_sinusoidal_lookup_table(EMBEDDING_SIZE: int = 128, max_seq_len: int = 512):\n",
    "    \"\"\"\n",
    "    Builds a sinusoidal positional encoding lookup table.\n",
    "    \n",
    "    Args:\n",
    "      EMBEDDING_SIZE: dimensionality of each position encoding vector (must be even).\n",
    "      max_seq_len: maximum sequence length (number of positions).\n",
    "    \n",
    "    Returns:\n",
    "      lookup_table: a tf array of shape (max_seq_len, EMBEDDING_SIZE)\n",
    "                    where row p gives the positional encoding for position p.\n",
    "    \"\"\"\n",
    "    # Initialize the table\n",
    "    lookup_table = np.zeros((max_seq_len, EMBEDDING_SIZE), dtype=np.float32)\n",
    "    \n",
    "    # Compute the angle rates for each dimension\n",
    "    # angle_rates[k] = 1 / (10000^(2*(k//2) / EMBEDDING_SIZE))\n",
    "    dims = np.arange(EMBEDDING_SIZE)[np.newaxis, :]   # shape (1, EMBEDDING_SIZE)\n",
    "    positions = np.arange(max_seq_len)[:, np.newaxis] # shape (max_seq_len, 1)\n",
    "    angle_rates = 1 / np.power(10000, (2 * (dims // 2)) / EMBEDDING_SIZE)\n",
    "    \n",
    "    # Compute the angle for each position and dimension: position * angle_rate\n",
    "    angle_rads = positions * angle_rates  # shape (max_seq_len, EMBEDDING_SIZE)\n",
    "    \n",
    "    # Apply sin to even indices (0,2,4,...) and cos to odd indices (1,3,5,...)\n",
    "    lookup_table[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    lookup_table[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    return tf.constant(lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "741514bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def tokenize_and_build_token_id(token_to_id_table: tf.lookup.StaticHashTable,\n",
    "#                                 text_batch: tf.Tensor,\n",
    "#                                 pad_value: int = 0):\n",
    "#     \"\"\"\n",
    "#     Tokenize a batch of strings character by character, pad sequences,\n",
    "#     and return attention masks.\n",
    "\n",
    "#     Args:\n",
    "#         token_to_id_table: TF lookup table mapping char -> int\n",
    "#         text_batch: tf.Tensor of shape [batch_size], dtype=tf.string\n",
    "#         pad_value: int, ID to use for padding\n",
    "\n",
    "#     Returns:\n",
    "#         token_ids: tf.Tensor [batch_size, max_seq_len]\n",
    "#         attention_mask: tf.Tensor [batch_size, max_seq_len]\n",
    "#     \"\"\"\n",
    "#     token_ids_list = []\n",
    "\n",
    "#     for text in text_batch.numpy():  # type: ignore\n",
    "#         # Convert bytes to TF string\n",
    "\n",
    "#         # Split into characters\n",
    "#         char_tensor = tf.strings.bytes_split(text)\n",
    "\n",
    "#         # Lookup token IDs\n",
    "#         token_ids = token_to_id_table.lookup(char_tensor)\n",
    "\n",
    "#         token_ids_list.append(token_ids)\n",
    "\n",
    "#     # Pad all sequences to the same length\n",
    "#     token_ids_padded = tf.ragged.stack(token_ids_list).to_tensor(default_value=pad_value) # type: ignore\n",
    "#     # Create attention mask: 1 for real tokens, 0 for padding\n",
    "#     attention_mask = tf.cast(token_ids_padded != pad_value, tf.int32)\n",
    "\n",
    "#     return token_ids_padded, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c66c28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from typing import Tuple\n",
    "\n",
    "\n",
    "# def tokenize_and_build_token_id(\n",
    "#     token_to_id_dict: dict,\n",
    "#     text_batch: list[str],\n",
    "#     max_seq_len: int,\n",
    "#     pad_value: int = 0,\n",
    "#     unk_value: int = None\n",
    "# ) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "#     \"\"\"\n",
    "#     TensorFlow-compatible tokenization converting batch of strings to char token IDs,\n",
    "#     padded/truncated to max_seq_len, along with attention mask.\n",
    "\n",
    "#     Args:\n",
    "#         token_to_id_dict: dict mapping character str -> int ID\n",
    "#         text_batch: list of strings to tokenize\n",
    "#         max_seq_len: max length to pad/truncate sequences\n",
    "#         pad_value: int ID for padding tokens\n",
    "#         unk_value: int ID for unknown tokens; if None, uses pad_value\n",
    "\n",
    "#     Returns:\n",
    "#         token_ids: (batch_size, max_seq_len) tf.int32 tensor of token IDs\n",
    "#         attention_mask: (batch_size, max_seq_len) tf.int32 tensor (1 for tokens, 0 for padding)\n",
    "#     \"\"\"\n",
    "\n",
    "#     if unk_value is None:\n",
    "#         unk_value = pad_value\n",
    "\n",
    "#     # Create lookup table from token_to_id_dict\n",
    "#     keys = tf.constant(list(token_to_id_dict.keys()))\n",
    "#     values = tf.constant(list(token_to_id_dict.values()), dtype=tf.int32)\n",
    "#     table = tf.lookup.StaticHashTable(\n",
    "#         tf.lookup.KeyValueTensorInitializer(keys, values),\n",
    "#         default_value=unk_value\n",
    "#     )\n",
    "\n",
    "#     # Convert text batch to a RaggedTensor of chars\n",
    "#     rt_chars = tf.strings.unicode_split(text_batch, 'UTF-8')  # shape: [batch_size, (seq_len)]\n",
    "\n",
    "#     # Lookup token IDs for each char\n",
    "#     token_ids = table.lookup(rt_chars)\n",
    "\n",
    "#     # Pad or truncate sequences to max_seq_len\n",
    "#     token_ids = token_ids.to_tensor(default_value=pad_value, shape=[None, max_seq_len])\n",
    "#     token_ids = token_ids[:, :max_seq_len]  # truncate if longer\n",
    "\n",
    "#     # Construct attention mask: 1 where not pad_value, else 0\n",
    "#     attention_mask = tf.cast(token_ids != pad_value, tf.int32)\n",
    "\n",
    "#     return token_ids, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21e3a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def tokenize_and_build_vocabulary_tf(file_path_list: List[str], existing_vocab: Dict[str, int] | None = None) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a character-level vocabulary dictionary from text files.\n",
    "    \n",
    "    Args:\n",
    "        file_path_list: List of file paths containing the text corpus.\n",
    "        existing_vocab: Optional existing vocabulary to extend.\n",
    "\n",
    "    Returns:\n",
    "        token_to_id: dict mapping character to unique integer token ID.\n",
    "    \"\"\"\n",
    "    if isinstance(file_path_list, (str, bytes)):\n",
    "        file_path_list = [file_path_list] # type: ignore\n",
    "    if existing_vocab is None:\n",
    "        existing_vocab = {}\n",
    "    vocab_set = set(existing_vocab.keys())\n",
    "    \n",
    "    for file_name in file_path_list:\n",
    "        if os.path.isdir(file_name):\n",
    "            raise IsADirectoryError(f\"Expected file path, got directory: {file_name}\")\n",
    "        if not os.path.isfile(file_name):\n",
    "            raise FileNotFoundError(f\"File not found: {file_name}\")\n",
    "        with open(file_name, encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            vocab_set.update(text)\n",
    "    \n",
    "    sorted_tokens = sorted(vocab_set)\n",
    "    token_to_id = {char: idx for idx, char in enumerate(sorted_tokens)}\n",
    "    return token_to_id\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def tokenize_and_build_token_id(token_to_id_dict: Dict[str, int], text_batch: List[str], max_seq_len: int, pad_value: int = 0) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Tokenize a batch of text strings into character token IDs using a token dictionary,\n",
    "    then pad/truncate to max_seq_len and create attention masks.\n",
    "\n",
    "    Args:\n",
    "        token_to_id_dict: dict mapping character to integer token ID.\n",
    "        text_batch: list of text strings to tokenize.\n",
    "        max_seq_len: maximum sequence length after padding/truncation.\n",
    "        pad_value: integer ID used for padding tokens.\n",
    "\n",
    "    Returns:\n",
    "        token_ids: tf.Tensor of shape (batch_size, max_seq_len), dtype tf.int32.\n",
    "        attention_mask: tf.Tensor of shape (batch_size, max_seq_len), dtype tf.int32 (1 for real tokens, 0 for padding).\n",
    "    \"\"\"\n",
    "    batch_token_ids = []\n",
    "    for text in text_batch:\n",
    "        ids = [token_to_id_dict.get(c, pad_value) for c in text]\n",
    "        if len(ids) > max_seq_len:\n",
    "            ids = ids[:max_seq_len]\n",
    "        else:\n",
    "            ids += [pad_value] * (max_seq_len - len(ids))\n",
    "        batch_token_ids.append(ids)\n",
    "    \n",
    "    token_ids = np.array(batch_token_ids, dtype=np.int32)\n",
    "    attention_mask = (token_ids != pad_value).astype(np.int32)\n",
    "    \n",
    "    return tf.constant(token_ids), tf.constant(attention_mask) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4965754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Letters, digits, punctuation, space, newline\n",
    "ALLOWED = set(\n",
    "    list(string.ascii_lowercase) +\n",
    "    list(\" .,!?;\\\"\\n\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5158d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt') as f:\n",
    "    text = f.read()\n",
    "    text = \"\".join(ch if ch in ALLOWED else \" \" for ch in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "153f850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "token_to_id_dict = tokenize_and_build_vocabulary_tf([r'/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt'])\n",
    "# Lookup with plain Python dict\n",
    "token_id_for_a = token_to_id_dict.get('a', None)\n",
    "print(token_id_for_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca4c6824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " \"'\": 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " ':': 9,\n",
       " ';': 10,\n",
       " '?': 11,\n",
       " 'a': 12,\n",
       " 'b': 13,\n",
       " 'c': 14,\n",
       " 'd': 15,\n",
       " 'e': 16,\n",
       " 'f': 17,\n",
       " 'g': 18,\n",
       " 'h': 19,\n",
       " 'i': 20,\n",
       " 'j': 21,\n",
       " 'k': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'q': 28,\n",
       " 'r': 29,\n",
       " 's': 30,\n",
       " 't': 31,\n",
       " 'u': 32,\n",
       " 'v': 33,\n",
       " 'w': 34,\n",
       " 'x': 35,\n",
       " 'y': 36,\n",
       " 'z': 37}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec9075b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(13,), dtype=string, numpy=\n",
       "array([b'A', b'k', b's', b'h', b'a', b't', b' ', b'K', b'h', b'a', b't',\n",
       "       b'r', b'i'], dtype=object)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = tf.constant('Akshat Khatri')\n",
    "tf.strings.bytes_split(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45984209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello'\n",
      "b'Worlds '\n"
     ]
    }
   ],
   "source": [
    "name = tf.constant(['Hello','Worlds '])\n",
    "for name in name.numpy():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33ba567a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1.,2.,3.])\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "046629d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
       " array([[ 0, 22, 30, ...,  0,  0,  0],\n",
       "        [19, 16, 23, ...,  0,  0,  0],\n",
       "        [24, 16,  0, ...,  0,  0,  0]], shape=(3, 512), dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
       " array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0]], shape=(3, 512), dtype=int32)>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['Akshat Khatri','hello ','me']\n",
    "tokenize_and_build_token_id(token_to_id_dict,name,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74d1a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "caa293c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Callable\n",
    "\n",
    "# class InitializePositionalEmbeddings(keras.layers.Layer): # Receives input of sequence of text\n",
    "#     def __init__(self,d_model: int = 128,sinusoidal_lookup_table = [],token_to_id_dict : tf.lookup.StaticHashTable = {} ,max_seq_len : int = 512,**kwargs): # type: ignore\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.d_model = d_model # d_model\n",
    "#         self.max_seq_len = max_seq_len\n",
    "        \n",
    "#         assert len(sinusoidal_lookup_table) > 0\n",
    "#         assert token_to_id_dict.size().numpy() > 0\n",
    "#         self.VOCAB_SIZE = token_to_id_dict.size().numpy()\n",
    "\n",
    "#         self.pos_table = sinusoidal_lookup_table\n",
    "#         self._embedding_dim = [self.VOCAB_SIZE,d_model]\n",
    "#         self.token_to_id_dict = token_to_id_dict\n",
    "    \n",
    "#     def build(self, input_shape): # this is batch input shape\n",
    "#         print(input_shape)\n",
    "#         self.embedding_matrix = self.add_weight(\n",
    "#             name=\"embedding_matrix\",\n",
    "#             shape=(self.VOCAB_SIZE, self.d_model),\n",
    "#             initializer=\"random_normal\",\n",
    "#             trainable=True   # important\n",
    "#         )\n",
    "#         self.input_seq_list = input_shape[-1]\n",
    "\n",
    "#     def call(self,inputs):\n",
    "#         # print(inputs)\n",
    "#         tokens_in_id,non_padded_tokens_mask = tokenize_and_build_token_id(self.token_to_id_dict,inputs)\n",
    "#         # print(tokens_in_id,non_padded_tokens_mask,sep = '\\n')\n",
    "#         token_embeddings = tf.nn.embedding_lookup(self.embedding_matrix, tokens_in_id)\n",
    "#         # Positional embeddings\n",
    "#         seq_len = tf.shape(tokens_in_id)[1] # type: ignore\n",
    "#         pos_embeddings = self.pos_table[:seq_len, :]\n",
    "#         pos_embeddings = tf.expand_dims(pos_embeddings, 0)  # broadcast along batch\n",
    "#         # Add token + position embeddings\n",
    "#         embeddings = token_embeddings + pos_embeddings\n",
    "#         return embeddings,non_padded_tokens_mask\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         base_config = super().get_config()\n",
    "#         return {**base_config,'EMBEDDING_SIZE' : self.EMBEDDING_SIZE,'VOCAB_SIZE' : self.VOCAB_SIZE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d037241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class InitializePositionalEmbeddings(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        vocab_size : int,\n",
    "        CONTEXT_LEN: int = 128,\n",
    "        pad_value: int = 0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_model = int(d_model)\n",
    "        self.pad_value = int(pad_value)\n",
    "        self.vocab_size = vocab_size\n",
    "        self._pos_table = prepare_sinusoidal_lookup_table(d_model, CONTEXT_LEN)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding_matrix = self.add_weight(\n",
    "            name=\"embedding_matrix\",\n",
    "            shape=(self.vocab_size, self.d_model),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, text_batch):\n",
    "\n",
    "        token_ids= text_batch # Unpacking Data Pre-processing inputs Embeddings\n",
    "        \n",
    "        # Embeddings lookup: (B, T, D)\n",
    "        token_emb = tf.nn.embedding_lookup(self.embedding_matrix, token_ids)\n",
    "        # Positional embeddings: slice and broadcast\n",
    "        seq_len = tf.shape(token_ids)[1] # type: ignore\n",
    "        pos_emb = self._pos_table[:seq_len, :]    # type: ignore # (T, D)\n",
    "        pos_emb = tf.expand_dims(pos_emb, 0)     # (1, T, D)\n",
    "        embeddings = token_emb + pos_emb         # (B, T, D)\n",
    "        return embeddings\n",
    "\n",
    "    # def compute_output_shape(self, input_shape):\n",
    "    #     # input_shape: (batch_size,)\n",
    "    #     batch = input_shape\n",
    "    #     # Sequence length is dynamic: None\n",
    "    #     return (batch, None, self.d_model), (batch, None)\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\n",
    "            \"d_model\": self.d_model,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'max_seq_len': self.max_seq_len,\n",
    "            \"pad_value\": self.pad_value,\n",
    "        })\n",
    "        return cfg\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape: (batch_size, seq_len)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        return (batch_size, seq_len, self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64c431a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(token_to_id_dict)\n",
    "D_MODEL = 64\n",
    "MAX_SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd66a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL)\n",
    "batch_text = ['yo','Akshat Khatri', 'Hello World','Me']\n",
    "batch_text = tokenize_and_build_token_id(token_to_id_dict,batch_text,MAX_SEQ_LEN) # type: ignore\n",
    "token_ids,attention_mask = batch_text\n",
    "\n",
    "layer = InitializePositionalEmbeddings(D_MODEL,VOCAB_SIZE)\n",
    "\n",
    "# @tf.function\n",
    "# def call_some(batch_text):\n",
    "#     embeddings = layer(batch_text)\n",
    "#     return embeddings\n",
    "\n",
    "# call_some(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bb6e1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class SelfAttentionLayer(keras.layers.Layer):\n",
    "    def __init__(self, attention_heads=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention_heads = attention_heads\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[0][-1]\n",
    "        \n",
    "        self.Query_projection = self.add_weight(\n",
    "            name='Query_Vector_for_projection',\n",
    "            initializer='random_normal',\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True \n",
    "        )\n",
    "        self.Key_projection = self.add_weight(\n",
    "            name='Key_Vector_for_projection',\n",
    "            initializer='random_normal',\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True \n",
    "        )\n",
    "        self.Value_projection = self.add_weight(\n",
    "            name='Value_Vector_for_projection',\n",
    "            initializer='random_normal',\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True \n",
    "        )\n",
    "        self.output_projection = self.add_weight(\n",
    "            name=\"Output_projection\",\n",
    "            initializer=\"random_normal\",\n",
    "            shape=(self.d_model, self.d_model),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.d_head = self.d_model // self.attention_heads\n",
    "        assert self.d_model % self.attention_heads == 0, \"d_model must be divisible by attention_heads\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embeddings = inputs[0]\n",
    "        token_masks = inputs[1]\n",
    "\n",
    "        batch_size = tf.shape(embeddings)[0]\n",
    "        seq_len = tf.shape(embeddings)[1]\n",
    "\n",
    "        # 1. Project to Q, K, V\n",
    "        Q = embeddings @ self.Query_projection\n",
    "        K = embeddings @ self.Key_projection\n",
    "        V = embeddings @ self.Value_projection\n",
    "\n",
    "        # 2. Reshape for multi-head attention\n",
    "        Q = tf.reshape(Q, (batch_size, seq_len, self.attention_heads, self.d_head))\n",
    "        K = tf.reshape(K, (batch_size, seq_len, self.attention_heads, self.d_head))\n",
    "        V = tf.reshape(V, (batch_size, seq_len, self.attention_heads, self.d_head))\n",
    "\n",
    "        Q = tf.transpose(Q, (0, 2, 1, 3))  # (batch, heads, seq_len, d_head)\n",
    "        K = tf.transpose(K, (0, 2, 1, 3))\n",
    "        V = tf.transpose(V, (0, 2, 1, 3))\n",
    "\n",
    "        # 3. Compute attention scores\n",
    "        scores = tf.matmul(Q, K, transpose_b=True)  # (batch, heads, seq_len, seq_len)\n",
    "        scores = scores / tf.sqrt(tf.cast(self.d_head, tf.float32))\n",
    "        \n",
    "        # 4. FIXED MASKING - This was your main bug\n",
    "        # 4a. Causal mask (L,L) lower triangular\n",
    "        causal_mask = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        \n",
    "        # 4b. Token mask - FIXED: proper broadcasting to all heads\n",
    "        token_mask = tf.cast(token_masks, tf.float32)  # (B, L)\n",
    "        \n",
    "        # Create proper attention mask shape (B, H, L, L)\n",
    "        # Each head gets the same mask pattern\n",
    "        attention_mask = causal_mask[tf.newaxis, tf.newaxis, :, :]  # (1, 1, L, L)\n",
    "        attention_mask = attention_mask * token_mask[:, tf.newaxis, tf.newaxis, :]  # (B, 1, 1, L)\n",
    "        attention_mask = attention_mask * token_mask[:, tf.newaxis, :, tf.newaxis]  # (B, 1, L, 1)\n",
    "        \n",
    "        # Broadcast to all heads\n",
    "        attention_mask = tf.broadcast_to(attention_mask, (batch_size, self.attention_heads, seq_len, seq_len))\n",
    "        \n",
    "        # 5. Apply mask with stronger negative value\n",
    "        scores = tf.where(\n",
    "            attention_mask > 0, \n",
    "            scores, \n",
    "            tf.constant(-1e30, dtype=scores.dtype)  # FIXED: Much more negative\n",
    "        )\n",
    "\n",
    "        # 6. Softmax and apply to values\n",
    "        attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "        \n",
    "        # Add attention dropout (missing in your original)\n",
    "        attention_weights = tf.nn.dropout(attention_weights, rate=0.1)\n",
    "        \n",
    "        context = attention_weights @ V   # (batch, heads, seq_len, d_head)\n",
    "        \n",
    "        # 7. Concatenate heads\n",
    "        concat_context = tf.transpose(context, (0, 2, 1, 3))  # (batch, seq_len, heads, d_head)\n",
    "        concat_context = tf.reshape(concat_context, (batch_size, seq_len, self.d_model))\n",
    "        \n",
    "        # 8. Final projection\n",
    "        final_context = concat_context @ self.output_projection \n",
    "        return final_context\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"attention_heads\": self.attention_heads})\n",
    "        return config\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40a50e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 13, 4, 3), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]]], shape=(16, 13, 4, 3), dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "a = np.random.rand(3, 13, 64)  # batch, seq_len, d_model\n",
    "q = np.ones((64, 64))          # d_model Ã— d_model\n",
    "\n",
    "a = tf.constant(a, dtype=tf.float32)\n",
    "q = tf.constant(q, dtype=tf.float32)\n",
    "\n",
    "s = a @ q   # type: ignore # [3, 13, 64]\n",
    "d_head = 16\n",
    "num_heads = 64 // d_head # 4\n",
    "\n",
    "# split into heads\n",
    "s = tf.reshape(s, (3, num_heads, 13, d_head))  # [3, 4, 13, 16]\n",
    "f = tf.constant(np.ones_like(s))\n",
    "\n",
    "tf.transpose(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "873ee087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0.04742587, 0.04742587, 0.95257413, 0.04742587, 0.04742587],\n",
       "       [0.95257413, 0.95257413, 0.04742587, 0.95257413, 0.95257413]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = tf.constant([[1,2,9,4,5],[4,5,6,7,8]])\n",
    "keras.activations.softmax(tf.cast(arr,dtype = tf.float32),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb91875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0.04742587, 0.04742587, 0.04742587, 0.04742587, 0.04742587],\n",
       "       [0.95257413, 0.95257413, 0.95257413, 0.95257413, 0.95257413]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = tf.constant([[1,2,3,4,5],[4,5,6,7,8]])\n",
    "arr = tf.cast(arr,dtype = tf.float32)\n",
    "\n",
    "tf.nn.softmax(arr,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac7cc3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000000000.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0da4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self,eps=1e-5,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def build(self,input_shape): # Near Attention (batch, seq_len, d_model)\n",
    "        self.alpha = self.add_weight(\n",
    "            name = 'alpha',\n",
    "            shape = input_shape[-1:],\n",
    "            initializer = 'ones',\n",
    "            dtype = tf.float32,\n",
    "            trainable = True\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            name = 'beta',\n",
    "            shape = input_shape[-1:],\n",
    "            initializer = 'zeros',\n",
    "            dtype = tf.float32,\n",
    "            trainable = True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mean, var = tf.nn.moments(inputs, axes=[-1], keepdims=True)\n",
    "        normed = (inputs - mean) / tf.sqrt(var + self.eps) # type: ignore\n",
    "        return self.alpha * normed + self.beta\n",
    "\n",
    "    def get_config(self):\n",
    "        base = super().get_config()\n",
    "        return {**base, \"eps\": self.eps}\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7a994b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense(keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"he_normal\",\n",
    "            trainable=True,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=\"bias\",\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs shape: (batch, seq_len, input_dim)\n",
    "        output = tf.matmul(inputs, self.kernel) + self.bias  # shape: (batch, seq_len, units))  # shape: (batch, seq_len, units)\n",
    "        return output + self.bias\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape: (batch, seq_len, input_dim)\n",
    "        return (input_shape, input_shape[1], self.units)\n",
    "\n",
    "    def get_config(self):\n",
    "        base = super().get_config()\n",
    "        return {**base, \"units\": self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cb7c629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (2,3,4,5,6)\n",
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea053e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class DecoderBlock(keras.Model):\n",
    "    '''A single Decoder Block'''\n",
    "    def __init__(self, d_model, n_heads, dropout_rate=0.1, epsilon=1e-5, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.epsilon = epsilon\n",
    "        # norms\n",
    "        self.ln1 = LayerNormalization(epsilon)   # pre-attn\n",
    "        self.ln2 = LayerNormalization(epsilon)   # pre-ffn\n",
    "        # attention (assumes your SelfAttentionLayer accepts (x, attention_mask))\n",
    "        self.attn = SelfAttentionLayer(n_heads)\n",
    "        self.dropout1 = keras.layers.Dropout(dropout_rate)\n",
    "        # FFN\n",
    "        self.ffn1 = keras.layers.Dense(4 * d_model, activation=\"gelu\")\n",
    "        self.ffn2 = keras.layers.Dense(d_model)\n",
    "        self.dropout2 = keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, attention_mask, training=False):\n",
    "        # Self-attention sublayer\n",
    "        y = self.ln1(x)\n",
    "        y = self.attn((y, attention_mask))          # shape: (B, T, d_model)\n",
    "        y = self.dropout1(y, training=training)\n",
    "        x = x + y                                    # residual\n",
    "\n",
    "        # FFN sublayer\n",
    "        y = self.ln2(x)\n",
    "        y = self.ffn1(y)\n",
    "        y = self.ffn2(y)\n",
    "        y = self.dropout2(y, training=training)\n",
    "        x = x + y                                    # residual\n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape is typically (batch_size, seq_len, d_model)\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"d_model\": self.d_model,\n",
    "            \"n_heads\": self.n_heads,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "            \"epsilon\": self.epsilon,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class GPT(keras.Model):\n",
    "    '''\n",
    "    GPT model with N distinct blocks\n",
    "      -----------------------------------'''\n",
    "    def __init__(self,\n",
    "                 d_model: int = 128,\n",
    "                 vocab_size: int = 94,\n",
    "                 context_length: int = 512,\n",
    "                 attention_heads: int = 8,\n",
    "                 epsilon: float = 1e-5,\n",
    "                 decoder_blocks: int = 3,\n",
    "                 dropout_rate: float = 0.1,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._d_model = d_model\n",
    "        self._vocab_size = vocab_size\n",
    "        self._context_length = context_length\n",
    "        self._attention_heads = attention_heads\n",
    "        self._epsilon = epsilon\n",
    "        self._decoder_blocks = decoder_blocks\n",
    "        self._dropout_rate = dropout_rate\n",
    "\n",
    "        # embeddings (yours)\n",
    "        self.emb = InitializePositionalEmbeddings(\n",
    "            d_model, vocab_size,context_length,name=\"init_embeddings\"\n",
    "        )\n",
    "\n",
    "        # stack of distinct decoder blocks\n",
    "        self.blocks = [\n",
    "            DecoderBlock(d_model, attention_heads, dropout_rate, epsilon, name=f\"decoder_block_{i}\")\n",
    "            for i in range(decoder_blocks)\n",
    "        ]\n",
    "\n",
    "        # final norm (GPT-2 style) and LM head\n",
    "        self.final_ln = LayerNormalization(epsilon)\n",
    "        self.lm_head = keras.layers.Dense(vocab_size, name=\"Model_head\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        inputs: (token_ids, attention_mask)\n",
    "          - token_ids: int32 (B, T)\n",
    "          - attention_mask: int32/float32 mask broadcasting to attention logits.\n",
    "            Common shapes: (B, 1, 1, T) or (B, T) if your SelfAttentionLayer handles expansion.\n",
    "        \"\"\"\n",
    "        token_ids, attention_mask = inputs\n",
    "        x = self.emb(token_ids)                         # (B, T, d_model)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attention_mask, training=training)\n",
    "\n",
    "        x = self.final_ln(x)\n",
    "        logits = self.lm_head(x)                        # (B, T, vocab_size)\n",
    "        return logits                                   # keep softmax outside\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\n",
    "            \"d_model\": self._d_model,\n",
    "            \"vocab_size\": self._vocab_size,\n",
    "            \"context_length\": self._context_length,\n",
    "            \"attention_heads\": self._attention_heads,\n",
    "            \"epsilon\": self._epsilon,\n",
    "            \"decoder_blocks\": self._decoder_blocks,\n",
    "            \"dropout_rate\": self._dropout_rate,\n",
    "        })\n",
    "        return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd143548",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LEN = 128\n",
    "VOCAB_SIZE = len(token_to_id_dict) # 94 currently char level\n",
    "\n",
    "batch_text = ['yo','Akshat Khatri', 'Hello World','Me']\n",
    "token_ids,attention_mask = tokenize_and_build_token_id(token_to_id_dict,batch_text,CONTEXT_LEN) # type: ignore # Unpacking Values\n",
    "sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL,CONTEXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3d639c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(4, 128), dtype=int32, numpy=\n",
       " array([[36, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 22, 30, 19, 12, 31,  1,  0, 19, 12, 31, 29, 20,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 16, 23, 23, 26,  1,  0, 26, 29, 23, 15,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "       dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=int32)>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token_ids,attention_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f0db5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class CosineDecayWithWarmup(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, \n",
    "                 warmup_steps: int,\n",
    "                 total_steps: int,\n",
    "                 peak_learning_rate: float = 1e-4,\n",
    "                 min_learning_rate: float = 1e-6,\n",
    "                 name: str = \"cosine_decay_with_warmup\"):\n",
    "        super().__init__()\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.peak_learning_rate = peak_learning_rate\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.name = name\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        total_steps = tf.cast(self.total_steps, tf.float32)\n",
    "        \n",
    "        # Warmup phase: linear increase from 0 to peak_learning_rate\n",
    "        warmup_lr = self.peak_learning_rate * step / warmup_steps\n",
    "        \n",
    "        # Cosine decay phase\n",
    "        decay_steps = total_steps - warmup_steps\n",
    "        cosine_decay_lr = self.min_learning_rate + 0.5 * (\n",
    "            self.peak_learning_rate - self.min_learning_rate\n",
    "        ) * (1 + tf.cos(np.pi * (step - warmup_steps) / decay_steps))\n",
    "        \n",
    "        return tf.where(step < warmup_steps, warmup_lr, cosine_decay_lr)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"peak_learning_rate\": self.peak_learning_rate,\n",
    "            \"min_learning_rate\": self.min_learning_rate,\n",
    "            \"name\": self.name,\n",
    "        }\n",
    "\n",
    "# Example usage for your model\n",
    "# Estimate your training parameters\n",
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCH = 1000  # Adjust based on your dataset size and batch size\n",
    "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "WARMUP_STEPS = int(0.1 * TOTAL_STEPS)  # 10% warmup\n",
    "\n",
    "# Create the learning rate schedule\n",
    "lr_schedule = CosineDecayWithWarmup(\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    total_steps=TOTAL_STEPS,\n",
    "    peak_learning_rate=1e-4,  # Your desired peak learning rate\n",
    "    min_learning_rate=1e-6    # Minimum learning rate at the end\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d45b6a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ init_embeddings                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InitializePositionalEmbeddingâ€¦</span> â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,728</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” layer_normalization_9      â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” layer_normalization_10     â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” self_attention_layer_3     â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionLayer</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_11          â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Model_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,470</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ init_embeddings                 â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚         \u001b[38;5;34m2,432\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mInitializePositionalEmbeddingâ€¦\u001b[0m â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_0 (\u001b[38;5;33mDecoderBlock\u001b[0m)  â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚        \u001b[38;5;34m49,728\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” layer_normalization_9      â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” layer_normalization_10     â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” self_attention_layer_3     â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚        \u001b[38;5;34m16,384\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mSelfAttentionLayer\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dropout_6 (\u001b[38;5;33mDropout\u001b[0m)        â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dense_6 (\u001b[38;5;33mDense\u001b[0m)            â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          â”‚        \u001b[38;5;34m16,640\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dense_7 (\u001b[38;5;33mDense\u001b[0m)            â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚        \u001b[38;5;34m16,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â”” dropout_7 (\u001b[38;5;33mDropout\u001b[0m)        â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_11          â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Model_head (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m38\u001b[0m)           â”‚         \u001b[38;5;34m2,470\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build once to get .summary()\n",
    "DECODER_BLOCKS = 1\n",
    "ATTENTION_HEADS = 2\n",
    "\n",
    "GPT_model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,ATTENTION_HEADS,0.00001,DECODER_BLOCKS,0.3)\n",
    "_ = GPT_model((token_ids, attention_mask))\n",
    "GPT_model.summary(expand_nested=True)\n",
    "\n",
    "# training (stable): use logits\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-4, clipnorm=1.0)\n",
    "GPT_model.compile(optimizer=opt, loss=loss) # type: ignore\n",
    "\n",
    "# inference probs (when you actually need them)\n",
    "logits = GPT_model((token_ids, attention_mask), training=False)\n",
    "probs = keras.ops.softmax(logits, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc4eb0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 128, 38), dtype=float32, numpy=\n",
       "array([[[0.02427419, 0.00844106, 0.00674337, ..., 0.00477125,\n",
       "         0.02076543, 0.00828871],\n",
       "        [0.01316042, 0.0116842 , 0.00589607, ..., 0.00569568,\n",
       "         0.04424641, 0.01368236],\n",
       "        [0.01662502, 0.01813557, 0.00597432, ..., 0.01042927,\n",
       "         0.053636  , 0.01544004],\n",
       "        ...,\n",
       "        [0.01592959, 0.00297815, 0.00141975, ..., 0.00922529,\n",
       "         0.01749071, 0.00075334],\n",
       "        [0.00800081, 0.00451244, 0.00180551, ..., 0.01019324,\n",
       "         0.03020593, 0.00132201],\n",
       "        [0.00445642, 0.00955095, 0.00237412, ..., 0.00923473,\n",
       "         0.02976992, 0.00165074]],\n",
       "\n",
       "       [[0.02280555, 0.00861939, 0.00657079, ..., 0.00410576,\n",
       "         0.0271038 , 0.00749166],\n",
       "        [0.02359629, 0.01746042, 0.00732253, ..., 0.00576877,\n",
       "         0.03419791, 0.01191207],\n",
       "        [0.0168638 , 0.01274324, 0.00576653, ..., 0.00823772,\n",
       "         0.03976739, 0.01743495],\n",
       "        ...,\n",
       "        [0.01608564, 0.00302242, 0.00141322, ..., 0.00919705,\n",
       "         0.01782246, 0.00076548],\n",
       "        [0.00800666, 0.00457291, 0.00182889, ..., 0.01020666,\n",
       "         0.03018394, 0.00133081],\n",
       "        [0.00441568, 0.00954782, 0.00238026, ..., 0.00927593,\n",
       "         0.02962051, 0.00164141]],\n",
       "\n",
       "       [[0.02244888, 0.00876269, 0.0064248 , ..., 0.00408475,\n",
       "         0.02727075, 0.00747057],\n",
       "        [0.01679682, 0.01457764, 0.00592453, ..., 0.00658551,\n",
       "         0.03336759, 0.01314574],\n",
       "        [0.02148086, 0.01747933, 0.00662308, ..., 0.01212373,\n",
       "         0.02792542, 0.0178262 ],\n",
       "        ...,\n",
       "        [0.01599921, 0.0030007 , 0.0014198 , ..., 0.00928531,\n",
       "         0.01760137, 0.00076697],\n",
       "        [0.00811842, 0.00446541, 0.00184778, ..., 0.01016731,\n",
       "         0.02988618, 0.0013086 ],\n",
       "        [0.00440186, 0.00954029, 0.00236804, ..., 0.00920528,\n",
       "         0.03001476, 0.00167873]],\n",
       "\n",
       "       [[0.02265203, 0.00860163, 0.00646129, ..., 0.0040876 ,\n",
       "         0.02726906, 0.00754818],\n",
       "        [0.01679682, 0.01457764, 0.00592453, ..., 0.00658551,\n",
       "         0.03336759, 0.01314574],\n",
       "        [0.01671545, 0.01821531, 0.0059901 , ..., 0.01025133,\n",
       "         0.05400727, 0.0154018 ],\n",
       "        ...,\n",
       "        [0.01602126, 0.00302611, 0.00142294, ..., 0.00929061,\n",
       "         0.01758417, 0.00076612],\n",
       "        [0.00802423, 0.00452438, 0.00182878, ..., 0.01009993,\n",
       "         0.03004754, 0.00133522],\n",
       "        [0.00449873, 0.00954755, 0.00242224, ..., 0.00919302,\n",
       "         0.03017655, 0.00166743]]], shape=(4, 128, 38), dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81260874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 128, 38), dtype=float32, numpy=\n",
       "array([[[0.02427419, 0.00844106, 0.00674337, ..., 0.00477125,\n",
       "         0.02076543, 0.00828871],\n",
       "        [0.01441236, 0.01237122, 0.00629917, ..., 0.00738545,\n",
       "         0.03824622, 0.01349361],\n",
       "        [0.01685621, 0.01774202, 0.00600358, ..., 0.01018341,\n",
       "         0.05421719, 0.01545428],\n",
       "        ...,\n",
       "        [0.01615363, 0.00298077, 0.00143518, ..., 0.00926499,\n",
       "         0.01752654, 0.00076801],\n",
       "        [0.00801641, 0.00454536, 0.0018517 , ..., 0.01021357,\n",
       "         0.03007269, 0.00131147],\n",
       "        [0.00438085, 0.00967935, 0.00237462, ..., 0.0092137 ,\n",
       "         0.02995286, 0.00165967]],\n",
       "\n",
       "       [[0.02249563, 0.00874352, 0.00658948, ..., 0.00411398,\n",
       "         0.02734506, 0.00754081],\n",
       "        [0.01726262, 0.01583331, 0.00718337, ..., 0.00666552,\n",
       "         0.03666238, 0.01243987],\n",
       "        [0.01815676, 0.01363678, 0.00625158, ..., 0.01019126,\n",
       "         0.03491739, 0.01655457],\n",
       "        ...,\n",
       "        [0.01618759, 0.0029579 , 0.00143069, ..., 0.00914862,\n",
       "         0.01738329, 0.00076457],\n",
       "        [0.00802889, 0.00449368, 0.00183823, ..., 0.01016657,\n",
       "         0.02956688, 0.00129277],\n",
       "        [0.00436429, 0.00966537, 0.00236888, ..., 0.00926637,\n",
       "         0.02995704, 0.00165211]],\n",
       "\n",
       "       [[0.02248992, 0.00874272, 0.00649097, ..., 0.00407364,\n",
       "         0.02750942, 0.00746216],\n",
       "        [0.01449085, 0.01297158, 0.00482352, ..., 0.00382547,\n",
       "         0.04856883, 0.01308829],\n",
       "        [0.02148086, 0.01747933, 0.00662308, ..., 0.01212373,\n",
       "         0.02792542, 0.0178262 ],\n",
       "        ...,\n",
       "        [0.01618705, 0.00294865, 0.00140628, ..., 0.0091581 ,\n",
       "         0.01751784, 0.00076448],\n",
       "        [0.00804455, 0.00453536, 0.00184362, ..., 0.01015037,\n",
       "         0.03003075, 0.00131762],\n",
       "        [0.00439142, 0.00969619, 0.00235233, ..., 0.00928757,\n",
       "         0.02999088, 0.00165266]],\n",
       "\n",
       "       [[0.02244378, 0.00881029, 0.00636801, ..., 0.00403745,\n",
       "         0.02753555, 0.00751321],\n",
       "        [0.02114603, 0.01512023, 0.00596836, ..., 0.00572949,\n",
       "         0.03189167, 0.01263926],\n",
       "        [0.01672052, 0.01809613, 0.00595886, ..., 0.01037397,\n",
       "         0.0548842 , 0.01535218],\n",
       "        ...,\n",
       "        [0.01618698, 0.00301383, 0.00140994, ..., 0.00920277,\n",
       "         0.01754086, 0.00076201],\n",
       "        [0.00790861, 0.00458742, 0.00182   , ..., 0.01020947,\n",
       "         0.03027489, 0.00132108],\n",
       "        [0.00439696, 0.00955593, 0.0023744 , ..., 0.00929537,\n",
       "         0.03006582, 0.00166343]]], shape=(4, 128, 38), dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = GPT_model((token_ids, attention_mask))\n",
    "probs = tf.nn.softmax(outputs, axis=-1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72ebf9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ init_embeddings                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InitializePositionalEmbeddingâ€¦</span> â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,728</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_11          â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Model_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,470</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ init_embeddings                 â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚         \u001b[38;5;34m2,432\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mInitializePositionalEmbeddingâ€¦\u001b[0m â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_0 (\u001b[38;5;33mDecoderBlock\u001b[0m)  â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚        \u001b[38;5;34m49,728\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_11          â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)           â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Model_head (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m38\u001b[0m)           â”‚         \u001b[38;5;34m2,470\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,758</span> (213.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,758\u001b[0m (213.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80e575a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved diagram to gpt_model.png\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "try:\n",
    "    plot_model(\n",
    "        GPT_model,\n",
    "        to_file=\"gpt_model.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        expand_nested=True,\n",
    "        dpi=160\n",
    "    )\n",
    "    print(\"Saved diagram to gpt_model.png\")\n",
    "except Exception as e:\n",
    "    print(\"plot_model failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fdd9c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InitializePositionalEmbeddings name=init_embeddings, built=True>,\n",
       " <DecoderBlock name=decoder_block_0, built=True>,\n",
       " <LayerNormalization name=layer_normalization_11, built=True>,\n",
       " <Dense name=Model_head, built=True>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe5fecf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54758"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7809a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                               GPT MODEL SUMMARY                                \n",
      "================================================================================\n",
      "Total parameters:      54,758\n",
      "Total layers:          4\n",
      "Trainable weights:     17\n",
      "Final output shape(s): ['(unavailable)']\n",
      "--------------------------------------------------------------------------------\n",
      "Idx | Layer Type               | Layer Name              | Weight Name                  | Shape           |   Params\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "000 | InitializePositionalEmbeddings | init_embeddings         | embedding_matrix             | (38, 64)        |    2,432\n",
      "001 | DecoderBlock             | decoder_block_0         | alpha                        | (64,)           |       64\n",
      "    |                          |                         | beta                         | (64,)           |       64\n",
      "    |                          |                         | alpha                        | (64,)           |       64\n",
      "    |                          |                         | beta                         | (64,)           |       64\n",
      "    |                          |                         | Query_Vector_for_projection  | (64, 64)        |    4,096\n",
      "    |                          |                         | Key_Vector_for_projection    | (64, 64)        |    4,096\n",
      "    |                          |                         | Value_Vector_for_projection  | (64, 64)        |    4,096\n",
      "    |                          |                         | Output_projection            | (64, 64)        |    4,096\n",
      "    |                          |                         | kernel                       | (64, 256)       |   16,384\n",
      "    |                          |                         | bias                         | (256,)          |      256\n",
      "    |                          |                         | kernel                       | (256, 64)       |   16,384\n",
      "    |                          |                         | bias                         | (64,)           |       64\n",
      "    |                          |                         |                              |                 |         \n",
      "002 | LayerNormalization       | layer_normalization_11  | alpha                        | (64,)           |       64\n",
      "    |                          |                         | beta                         | (64,)           |       64\n",
      "    |                          |                         |                              |                 |         \n",
      "003 | Dense                    | Model_head              | kernel                       | (64, 38)        |    2,432\n",
      "    |                          |                         | bias                         | (38,)           |       38\n",
      "    |                          |                         |                              |                 |         \n",
      "================================================================================\n",
      "Note: Only trainable weights are listed above. Output shapes may be unavailable\n",
      "for subclassed models or models not built symbolically.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def format_model_summary(model):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'GPT MODEL SUMMARY':^80}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_params = model.count_params()\n",
    "    total_layers = len(model.layers)\n",
    "    total_weights = sum(len(layer.trainable_weights) for layer in model.layers)\n",
    "    try:\n",
    "        output_shapes = [tuple(out.shape) for out in model.outputs]\n",
    "    except Exception:\n",
    "        output_shapes = [\"(unavailable)\"]\n",
    "    \n",
    "    print(f\"{'Total parameters:':<22} {total_params:,}\")\n",
    "    print(f\"{'Total layers:':<22} {total_layers}\")\n",
    "    print(f\"{'Trainable weights:':<22} {total_weights}\")\n",
    "    print(f\"{'Final output shape(s):':<22} {output_shapes if output_shapes else '(N/A)'}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    header = f\"{'Idx':>3} | {'Layer Type':<24} | {'Layer Name':<23} | {'Weight Name':<28} | {'Shape':<15} | {'Params':>8}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    \n",
    "    for i, layer in enumerate(model.layers):\n",
    "        layer_type = layer.__class__.__name__\n",
    "        layer_name = layer.name\n",
    "        weights = layer.trainable_weights\n",
    "        layer_weight_count = len(weights)\n",
    "\n",
    "        if layer_weight_count == 0:\n",
    "            print(f\"{i:03} | {layer_type:<24} | {layer_name:<23} | {'-':<28} | {'-':<15} | {'0':>8}\")\n",
    "        else:\n",
    "            for j, w in enumerate(weights):\n",
    "                n = int(np.prod(w.shape)) if hasattr(w, \"shape\") else \"?\"\n",
    "                shape_str = str(tuple(w.shape))\n",
    "                weight_name = w.name\n",
    "                if j == 0:\n",
    "                    print(f\"{i:03} | {layer_type:<24} | {layer_name:<23} | {weight_name:<28} | {shape_str:<15} | {n:>8,}\")\n",
    "                else:\n",
    "                    print(f\"    | {'':<24} | {'':<23} | {weight_name:<28} | {shape_str:<15} | {n:>8,}\")\n",
    "        if layer_weight_count > 1:\n",
    "            print(f\"    | {'':<24} | {'':<23} | {'':<28} | {'':<15} | {'':>8}\")\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"Note: Only trainable weights are listed above. Output shapes may be unavailable\\n\"\n",
    "          \"for subclassed models or models not built symbolically.\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Usage:\n",
    "format_model_summary(GPT_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2ab03dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_book_training_data(book_text: str, \n",
    "#                              token_to_id_dict: Dict[str, int], \n",
    "#                              context_length: int = 512,\n",
    "#                              pad_value: int = 0):\n",
    "#     \"\"\"\n",
    "#     Prepare training data from a Gutenberg book\n",
    "#     \"\"\"\n",
    "#     # 1. Tokenize the entire book\n",
    "#     token_ids = [token_to_id_dict.get(c, pad_value) for c in book_text]\n",
    "    \n",
    "#     # 2. Create sliding windows\n",
    "#     inputs = []\n",
    "#     targets = []\n",
    "    \n",
    "#     # Slide window across the entire book\n",
    "#     for i in range(0, len(token_ids) - context_length, context_length):\n",
    "#         # Extract window of context_length + 1 tokens\n",
    "#         window = token_ids[i:i + context_length + 1]\n",
    "        \n",
    "#         if len(window) < context_length + 1:\n",
    "#             break  # Skip incomplete windows at the end\n",
    "        \n",
    "#         # Create input-target pair\n",
    "#         input_seq = window[:-1]   # [t1, t2, ..., t512]\n",
    "#         target_seq = window[1:]   # [t2, t3, ..., t513]\n",
    "        \n",
    "#         inputs.append(input_seq)\n",
    "#         targets.append(target_seq)\n",
    "    \n",
    "#     # 3. Convert to numpy arrays\n",
    "#     inputs = np.array(inputs, dtype=np.int32)\n",
    "#     targets = np.array(targets, dtype=np.int32)\n",
    "    \n",
    "#     # 4. Create padding masks (all 1s since we're using full context)\n",
    "#     masks = np.ones_like(inputs, dtype=np.int32)\n",
    "    \n",
    "#     return inputs, targets, masks\n",
    "\n",
    "# # Usage:\n",
    "# with open(r'/home/akshat/GPT_from_scratch/text_data/pg76702.txt', 'r', encoding='utf-8') as f:\n",
    "#     book_text = f.read()\n",
    "\n",
    "# inputs, targets, masks = prepare_book_training_data(\n",
    "#     book_text, \n",
    "#     token_to_id_dict, \n",
    "#     context_length=512\n",
    "# )\n",
    "\n",
    "# print(f\"Created {len(inputs)} training examples\")\n",
    "# print(f\"Input shape: {inputs.shape}\")\n",
    "# print(f\"Target shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ea8b1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'/home/akshat/GPT_from_scratch/text_data/pg76702.txt', 'r') as f:\n",
    "#     book_text = f.read()\n",
    "\n",
    "# print(f\"Total characters: {len(book_text)}\")\n",
    "# print(f\"Expected examples (rough): {len(book_text) // 512}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fc7c7",
   "metadata": {},
   "source": [
    "''' Stop '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "649d5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to TensorFlow tensors\n",
    "# input_ids = tf.constant(inputs, dtype=tf.int32)\n",
    "# target_ids = tf.constant(targets, dtype=tf.int32)\n",
    "# attention_masks = tf.constant(masks, dtype=tf.int32)\n",
    "\n",
    "# model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,8,0.00001,4,0.1,sinusoidal_lookup_table)\n",
    "\n",
    "# # Compile your model\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.AdamW(learning_rate=1e-4), # type: ignore\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # Train with .fit()\n",
    "# history = model.fit(\n",
    "#     x=[input_ids, ,  # Your model expects (token_ids, attention_mask)\n",
    "#     y=target_ids,\n",
    "#     batch_size=16,  # Start small since 677 examples isn't huge\n",
    "#     epochs=50,\n",
    "#     validation_split=0.1,  # Use 10% for validation\n",
    "#     callbacks=[\n",
    "#         keras.callbacks.ModelCheckpoint('best_model.keras', save_best_only=True),\n",
    "#         keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "#         keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e775cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text(model, start_text, token_to_id, id_to_token, max_len=100, temperature=1.0):\n",
    "#     # Encode start text\n",
    "#     token_ids, attention_mask = tokenize_and_build_token_id(\n",
    "#         token_to_id, [start_text], max_seq_len=512\n",
    "#     )\n",
    "    \n",
    "#     generated = list(token_ids[0].numpy())  # flatten out\n",
    "#     mask = list(attention_mask[0].numpy())\n",
    "    \n",
    "#     for _ in range(max_len):\n",
    "#         # Trim to last 512 tokens\n",
    "#         x_tokens = np.array([generated[-512:]])\n",
    "#         x_mask   = np.array([mask[-512:]])\n",
    "\n",
    "#         # Forward pass with both inputs\n",
    "#         logits = model((x_tokens, x_mask), training=False)\n",
    "\n",
    "#         # Take last position logits\n",
    "#         next_logits = logits[0, -1] / temperature\n",
    "#         probs = tf.nn.softmax(next_logits).numpy()\n",
    "\n",
    "#         # Sample next token\n",
    "#         next_id = np.random.choice(len(probs), p=probs)\n",
    "\n",
    "#         # Append\n",
    "#         generated.append(next_id)\n",
    "#         mask.append(1)  # mark as valid token\n",
    "\n",
    "#     # Decode\n",
    "#     return ''.join(id_to_token[i] for i in generated if i in id_to_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d50c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_token_dict = {v: k for k, v in token_to_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "43978b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = \"Akshat Khatri\"\n",
    "# result = generate_text(model, start, token_to_id_dict, id_to_token_dict, max_len=100, temperature=0.8)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94cf8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset('wikitext', 'wikitext-103-v1')# Concatenate train + validation + test\n",
    "# all_texts = []\n",
    "# for split in [\"train\", \"validation\", \"test\"]:\n",
    "#     all_texts.extend(dataset[split][\"text\"])\n",
    "\n",
    "# # Remove empty lines\n",
    "# all_texts = [t.strip() for t in all_texts if t.strip() != \"\"]\n",
    "\n",
    "# # Join into one giant string\n",
    "# big_text = \"\\n\".join(all_texts)\n",
    "\n",
    "# # Write to file\n",
    "# with open(\"wikitext_full.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(big_text)\n",
    "\n",
    "# print(\"Saved dataset to wikitext_full.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c759f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, targets, masks = prepare_book_training_data(\n",
    "#     book_text, \n",
    "#     token_to_id_dict, \n",
    "#     context_length=512\n",
    "# )\n",
    "\n",
    "# print(f\"Created {len(inputs)} training examples\")\n",
    "# print(f\"Input shape: {inputs.shape}\")\n",
    "# print(f\"Target shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d5f51f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Assuming you already have:\n",
    "# # - prepare_book_training_data()\n",
    "# # - token_to_id_dict\n",
    "\n",
    "# file_path = r\"/home/akshat/GPT_from_scratch/text_data/wikitext_full.txt\"\n",
    "\n",
    "# inputs_list, targets_list, masks_list = [], [], []\n",
    "\n",
    "# buffer = \"\"\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     for line in f:\n",
    "#         buffer += line.strip() + \" \"\n",
    "#         # Process every ~5000 chars to avoid memory spike\n",
    "#         if len(buffer) > 5000:\n",
    "#             inp, tgt, msk = prepare_book_training_data(\n",
    "#                 buffer, token_to_id_dict, context_length=512\n",
    "#             )\n",
    "#             inputs_list.append(inp)\n",
    "#             targets_list.append(tgt)\n",
    "#             masks_list.append(msk)\n",
    "#             buffer = \"\"  # reset buffer\n",
    "\n",
    "# # Process any leftover buffer\n",
    "# if buffer.strip():\n",
    "#     inp, tgt, msk = prepare_book_training_data(\n",
    "#         buffer, token_to_id_dict, context_length=512\n",
    "#     )\n",
    "#     inputs_list.append(inp)\n",
    "#     targets_list.append(tgt)\n",
    "#     masks_list.append(msk)\n",
    "\n",
    "# # Concatenate all batches into final arrays\n",
    "# inputs = np.concatenate(inputs_list, axis=0)\n",
    "# targets = np.concatenate(targets_list, axis=0)\n",
    "# masks = np.concatenate(masks_list, axis=0)\n",
    "\n",
    "# print(f\"Created {len(inputs)} training examples\")\n",
    "# print(f\"Input shape: {inputs.shape}\")\n",
    "# print(f\"Target shape: {targets.shape}\")\n",
    "# print(f\"Masks shape: {masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "20b06fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_tf_example(input_ids: List[int], target_ids: List[int], attention_mask: List[int]) -> bytes:\n",
    "    \"\"\"\n",
    "    Create a serialized TFRecord example from input-target pair.\n",
    "    \n",
    "    Args:\n",
    "        input_ids: Token sequence for model input\n",
    "        target_ids: Token sequence for model targets (shifted by 1)\n",
    "        attention_mask: Mask for valid tokens (1) vs padding (0)\n",
    "        \n",
    "    Returns:\n",
    "        Serialized TFRecord example\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        'input_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=input_ids)),\n",
    "        'target_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=target_ids)),\n",
    "        'attention_mask': tf.train.Feature(int64_list=tf.train.Int64List(value=attention_mask))\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example.SerializeToString()\n",
    "\n",
    "\n",
    "def convert_text_to_tfrecord(\n",
    "    text_file_path: str,\n",
    "    token_to_id_dict: Dict[str, int],\n",
    "    output_dir: str,\n",
    "    context_length: int = 512,\n",
    "    records_per_file: int = 1000,\n",
    "    pad_value: int = 0\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert text file to TFRecord files for GPT training.\n",
    "    \n",
    "    Process:\n",
    "    1. Read and tokenize entire text file\n",
    "    2. Create sliding windows of context_length + 1 tokens\n",
    "    3. Split each window into input/target pairs (shifted by 1)\n",
    "    4. Save as TFRecord files with specified number of records per file\n",
    "    \n",
    "    Args:\n",
    "        text_file_path: Path to your text file (e.g., WikiText-103)\n",
    "        token_to_id_dict: Character-to-ID mapping dictionary\n",
    "        output_dir: Directory to save TFRecord files\n",
    "        context_length: Sequence length for training\n",
    "        records_per_file: Number of examples per TFRecord file\n",
    "        pad_value: Token ID used for unknown characters\n",
    "        \n",
    "    Returns:\n",
    "        Path to output directory containing TFRecord files\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Reading text file: {text_file_path}\")\n",
    "    \n",
    "    # Step 1: Load and tokenize text\n",
    "    with open(text_file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    print(f\"Text length: {len(text):,} characters\")\n",
    "    \n",
    "    # Convert each character to token ID\n",
    "    print(\"Tokenizing text...\")\n",
    "    token_ids = [token_to_id_dict.get(char, pad_value) for char in text]\n",
    "    print(f\"Token length: {len(token_ids):,} tokens\")\n",
    "    \n",
    "    # Step 2: Calculate output size\n",
    "    num_examples = (len(token_ids) - context_length) // context_length\n",
    "    print(f\"Will create {num_examples:,} training examples\")\n",
    "    \n",
    "    # Step 3: Process sliding windows and write TFRecord files\n",
    "    file_count = 0\n",
    "    examples_in_current_file = 0\n",
    "    writer = None\n",
    "    \n",
    "    print(\"Creating TFRecord files...\")\n",
    "    \n",
    "    # Slide window across token sequence\n",
    "    for i in tqdm(range(0, len(token_ids) - context_length, context_length)):\n",
    "        \n",
    "        # Extract window of tokens\n",
    "        window = token_ids[i:i + context_length + 1]\n",
    "        if len(window) < context_length + 1:\n",
    "            break\n",
    "            \n",
    "        # Create input-target pair (GPT training format)\n",
    "        input_ids = window[:-1]    # First 512 tokens: [t1, t2, ..., t512]\n",
    "        target_ids = window[1:]    # Shifted by 1: [t2, t3, ..., t513]\n",
    "        attention_mask = [1] * context_length  # All valid tokens (no padding)\n",
    "        \n",
    "        # Start new TFRecord file if needed\n",
    "        if writer is None or examples_in_current_file >= records_per_file:\n",
    "            if writer is not None:\n",
    "                writer.close()\n",
    "            \n",
    "            tfrecord_filename = os.path.join(output_dir, f'train_{file_count:04d}.tfrecord')\n",
    "            writer = tf.io.TFRecordWriter(tfrecord_filename)\n",
    "            file_count += 1\n",
    "            examples_in_current_file = 0\n",
    "        \n",
    "        # Write training example to current TFRecord file\n",
    "        tf_example = create_tf_example(input_ids, target_ids, attention_mask)\n",
    "        writer.write(tf_example)\n",
    "        examples_in_current_file += 1\n",
    "    \n",
    "    # Cleanup\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "    \n",
    "    # Step 4: Save summary information\n",
    "    print(f\"\\nConversion complete!\")\n",
    "    print(f\"Created {file_count} TFRecord files in: {output_dir}\")\n",
    "    print(f\"Total examples: {num_examples:,}\")\n",
    "    \n",
    "    # Write metadata file\n",
    "    metadata = {\n",
    "        'context_length': context_length,\n",
    "        'vocab_size': len(token_to_id_dict),\n",
    "        'num_examples': num_examples,\n",
    "        'num_files': file_count,\n",
    "        'records_per_file': records_per_file\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(output_dir, 'metadata.txt')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        for key, value in metadata.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "\n",
    "def create_tf_data_pipeline(\n",
    "    tfrecord_dir: str,\n",
    "    context_length: int = 512,\n",
    "    batch_size: int = 32,\n",
    "    shuffle_buffer: int = 1000,\n",
    "    prefetch_buffer: int = tf.data.AUTOTUNE\n",
    ") -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Create tf.data pipeline from TFRecord files for training.\n",
    "    \n",
    "    Process:\n",
    "    1. Find all TFRecord files in directory\n",
    "    2. Create dataset that reads and parses TFRecord examples\n",
    "    3. Apply shuffling, batching, and prefetching for efficient training\n",
    "    \n",
    "    Args:\n",
    "        tfrecord_dir: Directory containing TFRecord files\n",
    "        context_length: Expected sequence length in records\n",
    "        batch_size: Number of examples per training batch\n",
    "        shuffle_buffer: Size of shuffle buffer (larger = more random)\n",
    "        prefetch_buffer: Number of batches to prefetch (AUTOTUNE = automatic)\n",
    "        \n",
    "    Returns:\n",
    "        tf.data.Dataset ready for model.fit()\n",
    "    \"\"\"\n",
    "    # Step 1: Find TFRecord files\n",
    "    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "    print(f\"Found {len(tfrecord_files)} TFRecord files\")\n",
    "    \n",
    "    # Step 2: Define how to parse each TFRecord example\n",
    "    feature_description = {\n",
    "        'input_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'target_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'attention_mask': tf.io.FixedLenFeature([context_length], tf.int64)\n",
    "    }\n",
    "    \n",
    "    def parse_tfrecord_example(example_proto):\n",
    "        \"\"\"Parse a single TFRecord example into model inputs and targets.\"\"\"\n",
    "        # Parse the serialized example\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        \n",
    "        # Convert to correct data types\n",
    "        input_ids = tf.cast(parsed_features['input_ids'], tf.int32)\n",
    "        target_ids = tf.cast(parsed_features['target_ids'], tf.int32)\n",
    "        attention_mask = tf.cast(parsed_features['attention_mask'], tf.int32)\n",
    "        \n",
    "        # Return in format expected by your GPT model: ((input_ids, attention_mask), targets)\n",
    "        model_inputs = (input_ids, attention_mask)\n",
    "        model_targets = target_ids\n",
    "        \n",
    "        return model_inputs, model_targets\n",
    "    \n",
    "    # Step 3: Create and configure dataset pipeline\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    dataset = dataset.map(parse_tfrecord_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(prefetch_buffer)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Example usage (commented out)\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Example usage for WikiText-103 or similar large text files\n",
    "    \"\"\"\n",
    "    \n",
    "    # # Step 1: Define your vocabulary (replace with actual token_to_id_dict)\n",
    "    # example_vocab = your_token_to_id_dict\n",
    "    \n",
    "    # # Step 2: Convert text to TFRecord format (run once)\n",
    "    # tfrecord_dir = convert_text_to_tfrecord(\n",
    "    #     text_file_path=r'/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "    #     token_to_id_dict=example_vocab,\n",
    "    #     output_dir='./tfrecords',\n",
    "    #     context_length=512,\n",
    "    #     records_per_file=1000\n",
    "    # )\n",
    "    \n",
    "    # # Step 3: Create training pipeline (use for training)\n",
    "    # train_dataset = create_tf_data_pipeline(\n",
    "    #     tfrecord_dir=tfrecord_dir,\n",
    "    #     context_length=512,\n",
    "    #     batch_size=16\n",
    "    # )\n",
    "    \n",
    "    # print(\"TFRecord pipeline ready for training!\")\n",
    "    # # Now you can use train_dataset with your model's .fit() method\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "253d99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Define your vocabulary (replace with actual token_to_id_dict)\n",
    "# example_vocab = token_to_id_dict\n",
    "\n",
    "# # Step 2: Convert text to TFRecord format (run once)\n",
    "# tfrecord_dir = convert_text_to_tfrecord(\n",
    "#     text_file_path=r'/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=example_vocab,\n",
    "#     output_dir='./tfrecords',\n",
    "#     context_length=128,\n",
    "#     records_per_file=1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9caffa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create training and validation pipeline (use for training)\n",
    "def create_train_val_datasets(tfrecord_dir: str, \n",
    "                             context_length: int,\n",
    "                             batch_size: int = 32,\n",
    "                             val_split: float = 0.1):\n",
    "    \"\"\"\n",
    "    Create training and validation datasets from TFRecord files\n",
    "    \"\"\"\n",
    "    # Find all TFRecord files\n",
    "    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "    print(f\"Found {len(tfrecord_files)} TFRecord files\")\n",
    "    \n",
    "    # Split files for train/val\n",
    "    num_val_files = max(1, int(len(tfrecord_files) * val_split))\n",
    "    val_files = tfrecord_files[:num_val_files]\n",
    "    train_files = tfrecord_files[num_val_files:]\n",
    "    \n",
    "    print(f\"Using {len(train_files)} files for training, {len(val_files)} for validation\")\n",
    "    \n",
    "    # Feature description\n",
    "    feature_description = {\n",
    "        'input_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'target_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "        'attention_mask': tf.io.FixedLenFeature([context_length], tf.int64)\n",
    "    }\n",
    "    \n",
    "    def parse_function(example_proto):\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        \n",
    "        input_ids = tf.cast(parsed_features['input_ids'], tf.int32)\n",
    "        target_ids = tf.cast(parsed_features['target_ids'], tf.int32)\n",
    "        attention_mask = tf.cast(parsed_features['attention_mask'], tf.int32)\n",
    "        \n",
    "        # Return in format your model expects: ([input_ids, attention_mask], targets)\n",
    "        return (input_ids, attention_mask), target_ids\n",
    "    \n",
    "    # Create training dataset\n",
    "    train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "    train_dataset = train_dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.shuffle(5000)  # Shuffle buffer\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Create validation dataset\n",
    "    val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "    val_dataset = val_dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a91e6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# def create_tf_example(input_ids: List[int], target_ids: List[int], attention_mask: List[int]) -> bytes:\n",
    "#     \"\"\"\n",
    "#     Create a serialized TFRecord example from input-target pair.\n",
    "    \n",
    "#     Args:\n",
    "#         input_ids: Token sequence for model input\n",
    "#         target_ids: Token sequence for model targets (shifted by 1)\n",
    "#         attention_mask: Mask for valid tokens (1) vs padding (0)\n",
    "        \n",
    "#     Returns:\n",
    "#         Serialized TFRecord example\n",
    "#     \"\"\"\n",
    "#     feature = {\n",
    "#         'input_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=input_ids)),\n",
    "#         'target_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=target_ids)),\n",
    "#         'attention_mask': tf.train.Feature(int64_list=tf.train.Int64List(value=attention_mask))\n",
    "#     }\n",
    "    \n",
    "#     example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "#     return example.SerializeToString()\n",
    "\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def convert_text_to_tfrecord_sp(\n",
    "#     text_file_path: str,\n",
    "#     sp_model_path: str,\n",
    "#     output_dir: str,\n",
    "#     context_length: int = 512,\n",
    "#     records_per_file: int = 1000,\n",
    "#     overlap_size: int = 64,\n",
    "#     chunk_size: int = 100_000  # Number of characters read at a time\n",
    "# ) -> str:\n",
    "#     \"\"\"\n",
    "#     Streaming version of text to TFRecord conversion with SentencePiece.\n",
    "#     Reads and tokenizes file incrementally to limit memory usage.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     file_size = os.path.getsize(text_file_path)\n",
    "#     print(f\"Reading and tokenizing text in chunks from: {text_file_path}\")\n",
    "    \n",
    "#     # Load SentencePiece processor\n",
    "#     sp = spm.SentencePieceProcessor()\n",
    "#     sp.load(sp_model_path)\n",
    "    \n",
    "#     print(f\"Loaded SentencePiece model from: {sp_model_path}\")\n",
    "#     print(f\"Vocabulary size: {sp.get_piece_size()}\")\n",
    "\n",
    "#     buffer_tokens = []\n",
    "#     step_size = context_length - overlap_size\n",
    "#     file_count = 0\n",
    "#     examples_in_current_file = 0\n",
    "#     writer = None\n",
    "    \n",
    "#     with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "#         with tqdm(total=file_size, unit='B', unit_scale=True, desc='Processing text') as pbar:\n",
    "#             while True:\n",
    "#                 chunk = file.read(chunk_size)\n",
    "#                 if not chunk:\n",
    "#                     break\n",
    "#                 buffer_tokens.extend(sp.encode_as_ids(chunk))\n",
    "#                 pbar.update(len(chunk.encode('utf-8')))  # update by bytes read\n",
    "                \n",
    "#                 # Process windows to create examples\n",
    "#                 while len(buffer_tokens) >= context_length + 1:\n",
    "#                     window = buffer_tokens[:context_length + 1]\n",
    "#                     input_ids = window[:-1]\n",
    "#                     target_ids = window[1:]\n",
    "#                     attention_mask = [1] * context_length\n",
    "                    \n",
    "#                     if writer is None or examples_in_current_file >= records_per_file:\n",
    "#                         if writer:\n",
    "#                             writer.close()\n",
    "#                         tfrecord_path = os.path.join(output_dir, f'train_{file_count:04d}.tfrecord')\n",
    "#                         writer = tf.io.TFRecordWriter(tfrecord_path)\n",
    "#                         file_count += 1\n",
    "#                         examples_in_current_file = 0\n",
    "                    \n",
    "#                     tf_example = create_tf_example(input_ids, target_ids, attention_mask)\n",
    "#                     writer.write(tf_example)\n",
    "#                     examples_in_current_file += 1\n",
    "                    \n",
    "#                     # Slide window forward by step_size tokens\n",
    "#                     buffer_tokens = buffer_tokens[step_size:]\n",
    "\n",
    "#     # Process any remaining tokens\n",
    "#     while len(buffer_tokens) >= context_length + 1:\n",
    "#         window = buffer_tokens[:context_length + 1]\n",
    "#         input_ids = window[:-1]\n",
    "#         target_ids = window[1:]\n",
    "#         attention_mask = [1] * context_length\n",
    "        \n",
    "#         if writer is None or examples_in_current_file >= records_per_file:\n",
    "#             if writer:\n",
    "#                 writer.close()\n",
    "#             tfrecord_path = os.path.join(output_dir, f'train_{file_count:04d}.tfrecord')\n",
    "#             writer = tf.io.TFRecordWriter(tfrecord_path)\n",
    "#             file_count += 1\n",
    "#             examples_in_current_file = 0\n",
    "\n",
    "#         tf_example = create_tf_example(input_ids, target_ids, attention_mask)\n",
    "#         writer.write(tf_example)\n",
    "#         examples_in_current_file += 1\n",
    "#         buffer_tokens = buffer_tokens[step_size:]\n",
    "\n",
    "#     if writer:\n",
    "#         writer.close()\n",
    "\n",
    "#     num_examples = file_count * records_per_file  # Approximate count\n",
    "\n",
    "#     print(f\"\\nConversion complete!\")\n",
    "#     print(f\"Created {file_count} TFRecord files in: {output_dir}\")\n",
    "#     print(f\"Approximate total examples: {num_examples}\")\n",
    "\n",
    "#     metadata = {\n",
    "#         'context_length': context_length,\n",
    "#         'vocab_size': sp.get_piece_size(),\n",
    "#         'num_examples': num_examples,\n",
    "#         'num_files': file_count,\n",
    "#         'records_per_file': records_per_file,\n",
    "#         'overlap_size': overlap_size,\n",
    "#         'sp_model_path': sp_model_path,\n",
    "#         'tokenization': 'SentencePiece'\n",
    "#     }\n",
    "\n",
    "#     metadata_path = os.path.join(output_dir, 'metadata.txt')\n",
    "#     with open(metadata_path, 'w') as f:\n",
    "#         for key, value in metadata.items():\n",
    "#             f.write(f\"{key}: {value}\\n\")\n",
    "#     print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "#     return output_dir\n",
    "\n",
    "\n",
    "\n",
    "# def create_tf_data_pipeline_sp(\n",
    "#     tfrecord_dir: str,\n",
    "#     context_length: int = 512,\n",
    "#     batch_size: int = 32,\n",
    "#     shuffle_buffer: int = 1000,\n",
    "#     prefetch_buffer: int = tf.data.AUTOTUNE\n",
    "# ) -> tf.data.Dataset:\n",
    "#     \"\"\"\n",
    "#     Create tf.data pipeline from TFRecord files for training (SentencePiece version).\n",
    "    \n",
    "#     Process:\n",
    "#     1. Find all TFRecord files in directory\n",
    "#     2. Create dataset that reads and parses TFRecord examples\n",
    "#     3. Apply shuffling, batching, and prefetching for efficient training\n",
    "    \n",
    "#     Args:\n",
    "#         tfrecord_dir: Directory containing TFRecord files\n",
    "#         context_length: Expected sequence length in records\n",
    "#         batch_size: Number of examples per training batch\n",
    "#         shuffle_buffer: Size of shuffle buffer (larger = more random)\n",
    "#         prefetch_buffer: Number of batches to prefetch (AUTOTUNE = automatic)\n",
    "        \n",
    "#     Returns:\n",
    "#         tf.data.Dataset ready for model.fit()\n",
    "#     \"\"\"\n",
    "#     # Step 1: Find TFRecord files\n",
    "#     tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "#     print(f\"Found {len(tfrecord_files)} TFRecord files\")\n",
    "    \n",
    "#     if not tfrecord_files:\n",
    "#         raise FileNotFoundError(f\"No TFRecord files found in {tfrecord_dir}\")\n",
    "    \n",
    "#     # Step 2: Define how to parse each TFRecord example\n",
    "#     feature_description = {\n",
    "#         'input_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "#         'target_ids': tf.io.FixedLenFeature([context_length], tf.int64),\n",
    "#         'attention_mask': tf.io.FixedLenFeature([context_length], tf.int64)\n",
    "#     }\n",
    "    \n",
    "#     def parse_tfrecord_example(example_proto):\n",
    "#         \"\"\"Parse a single TFRecord example into model inputs and targets.\"\"\"\n",
    "#         # Parse the serialized example\n",
    "#         parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        \n",
    "#         # Convert to correct data types\n",
    "#         input_ids = tf.cast(parsed_features['input_ids'], tf.int32)\n",
    "#         target_ids = tf.cast(parsed_features['target_ids'], tf.int32)\n",
    "#         attention_mask = tf.cast(parsed_features['attention_mask'], tf.int32)\n",
    "        \n",
    "#         # Return in format expected by your GPT model: ((input_ids, attention_mask), targets)\n",
    "#         model_inputs = (input_ids, attention_mask)\n",
    "#         model_targets = target_ids\n",
    "        \n",
    "#         return model_inputs, model_targets\n",
    "    \n",
    "#     # Step 3: Create and configure dataset pipeline\n",
    "#     dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "#     dataset = dataset.map(parse_tfrecord_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     dataset = dataset.shuffle(shuffle_buffer)\n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     dataset = dataset.prefetch(prefetch_buffer)\n",
    "    \n",
    "#     return dataset\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     \"\"\"\n",
    "# #     Example usage assuming you have a pre-trained SentencePiece model\n",
    "# #     \"\"\"\n",
    "    \n",
    "# #     # Your pre-trained SentencePiece model path\n",
    "# #     sp_model_path = '/home/akshat/GPT_from_scratch/notebooks/spm_gpt.model'  # You provide this\n",
    "    \n",
    "# #     # Step 1: Convert text to TFRecords using your pre-trained model\n",
    "# #     tfrecord_dir = convert_text_to_tfrecord_sp(\n",
    "# #         text_file_path=r'/home/akshat/GPT_from_scratch/text_data/BookCorpus3_cleaned.txt',\n",
    "# #         sp_model_path=sp_model_path,  # Your trained model\n",
    "# #         output_dir='./tfrecords',\n",
    "# #         context_length=CONTEXT_LEN,  # Match your CONTEXT_LEN\n",
    "# #         records_per_file=1000,\n",
    "# #         overlap_size = CONTEXT_LEN // 2,\n",
    "# #         chunk_size = 150000\n",
    "# #     )\n",
    "    \n",
    "# #     # # Step 2: Create training pipeline\n",
    "# #     # train_dataset = create_tf_data_pipeline_sp(\n",
    "# #     #     tfrecord_dir=tfrecord_dir,\n",
    "# #     #     context_length=128,  # Match your CONTEXT_LEN\n",
    "# #     #     batch_size=16\n",
    "# #     # )\n",
    "    \n",
    "# #     print(\"SentencePiece TFRecord pipeline ready for training!\")\n",
    "    \n",
    "# #     # Step 3: Load your SentencePiece model for vocab size and generation\n",
    "# #     sp = spm.SentencePieceProcessor()\n",
    "# #     sp.load(sp_model_path)\n",
    "# #     VOCAB_SIZE = sp.get_piece_size()\n",
    "    \n",
    "# #     print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "    \n",
    "#     # Now you can use:\n",
    "#     # - sp for tokenization in generation\n",
    "#     # - train_dataset for model.fit()\n",
    "#     # - VOCAB_SIZE for your model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6ba0fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create DATASETS\n",
    "# train_dataset, val_dataset = create_train_val_datasets(\n",
    "#     tfrecord_dir='./tfrecords',\n",
    "#     context_length=CONTEXT_LEN,\n",
    "#     batch_size=16,\n",
    "#     val_split=0.1\n",
    "# )\n",
    "\n",
    "\n",
    "# print(\"TFRecord pipeline ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4819661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef29291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Remove existing tfrecords directory\n",
    "# if os.path.exists('./tfrecords'):\n",
    "#     shutil.rmtree('./tfrecords')\n",
    "#     print(\"Removed existing tfrecords directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd300a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9252ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SOLUTION 1: Recreate TFRecords with correct context length\n",
    "# # Delete the existing tfrecords directory and recreate with CONTEXT_LEN\n",
    "\n",
    "\n",
    "# # Recreate with correct context length\n",
    "# tfrecord_dir = convert_text_to_tfrecord(\n",
    "#     text_file_path=r'/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,  # Make sure this variable is defined\n",
    "#     output_dir='./tfrecords',\n",
    "#     context_length=CONTEXT_LEN,  # Use your actual context length (128)\n",
    "#     records_per_file=1000\n",
    "# )\n",
    "\n",
    "# # Now create datasets with matching context length\n",
    "# train_dataset, val_dataset = create_train_val_datasets(\n",
    "#     tfrecord_dir='./tfrecords',\n",
    "#     context_length=CONTEXT_LEN,  # This will now match\n",
    "#     batch_size=16,\n",
    "#     val_split=0.1\n",
    "# )\n",
    "\n",
    "# # Calculate steps per epoch\n",
    "# records_per_file = 1000  \n",
    "# tfrecord_files = tf.io.gfile.glob(os.path.join(\"./tfrecords\", \"*.tfrecord\"))\n",
    "# total_examples = len(tfrecord_files) * records_per_file\n",
    "# train_examples = int(total_examples * 0.9)\n",
    "# steps_per_epoch = train_examples // 16\n",
    "\n",
    "# print(f\"Files: {len(tfrecord_files)}\")\n",
    "# print(f\"Total examples: {total_examples}\")\n",
    "# print(f\"Steps per epoch: {steps_per_epoch}\") # When combined with batch_size sees the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5a189899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def prepare_tfrecords(\n",
    "    text_file_path: str,\n",
    "    token_to_id_dict: dict,\n",
    "    context_length: int = 128,\n",
    "    records_per_file: int = 1000,\n",
    "    output_base_dir: str = './tfrecords',\n",
    "    version_name: str = None,\n",
    "    batch_size: int = 16,\n",
    "    val_split: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Create TFRecords from text and return train/val datasets.\n",
    "    Stores TFRecords in a versioned folder to avoid overwriting previous ones.\n",
    "\n",
    "    Args:\n",
    "        text_file_path: Path to input text file.\n",
    "        token_to_id_dict: Character-to-id dictionary.\n",
    "        context_length: Sequence length for training.\n",
    "        records_per_file: Number of examples per TFRecord file.\n",
    "        output_base_dir: Base folder to store TFRecords.\n",
    "        version_name: Optional unique folder name. If None, uses context_length.\n",
    "        batch_size: Batch size for dataset.\n",
    "        val_split: Fraction of data to use as validation.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset, val_dataset, steps_per_epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine output folder\n",
    "    if version_name is None:\n",
    "        version_name = f\"context_{context_length}_bs{batch_size}\"\n",
    "    output_dir = os.path.join(output_base_dir, version_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Convert text to TFRecords\n",
    "    tfrecord_dir = convert_text_to_tfrecord(\n",
    "        text_file_path=text_file_path,\n",
    "        token_to_id_dict=token_to_id_dict,\n",
    "        output_dir=output_dir,\n",
    "        context_length=context_length,\n",
    "        records_per_file=records_per_file\n",
    "    )\n",
    "\n",
    "    # Create train/val datasets\n",
    "    train_dataset, val_dataset = create_train_val_datasets(\n",
    "        tfrecord_dir=tfrecord_dir,\n",
    "        context_length=context_length,\n",
    "        batch_size=batch_size,\n",
    "        val_split=val_split\n",
    "    )\n",
    "    def count_tfrecord_examples(tfrecord_files):\n",
    "        count = 0\n",
    "        for tfrecord_file in tfrecord_files:\n",
    "            for _ in tf.data.TFRecordDataset(tfrecord_file):\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    # inside prepare_tfrecords\n",
    "    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "    total_examples = count_tfrecord_examples(tfrecord_files)\n",
    "    train_examples = int(total_examples * (1 - val_split))\n",
    "    steps_per_epoch = train_examples // batch_size\n",
    "\n",
    "    print(f\"TFRecord folder: {tfrecord_dir}\")\n",
    "    print(f\"Total examples: {total_examples}\")\n",
    "    print(f\"Train examples: {train_examples}\")\n",
    "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "    return train_dataset, val_dataset, steps_per_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b03ad574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset,val_dataset,steps_per_epoch = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d131044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_24, val_ds_24, steps_24 = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=24\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a6f3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_32, val_ds_32, steps_32 = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9916a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_44, val_ds_44, steps_44 = prepare_tfrecords(\n",
    "#     text_file_path='/home/akshat/GPT_from_scratch/notebooks/wikitext_full.txt',\n",
    "#     token_to_id_dict=token_to_id_dict,\n",
    "#     context_length=128,\n",
    "#     batch_size=44\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e9933902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading text file: /home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt\n",
      "Text length: 4,347,531 characters\n",
      "Tokenizing text...\n",
      "Token length: 4,347,531 tokens\n",
      "Will create 33,964 training examples\n",
      "Creating TFRecord files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33965/33965 [00:01<00:00, 26769.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversion complete!\n",
      "Created 34 TFRecord files in: ./tfrecords/context_128_bs64\n",
      "Total examples: 33,964\n",
      "Metadata saved to: ./tfrecords/context_128_bs64/metadata.txt\n",
      "Found 34 TFRecord files\n",
      "Using 31 files for training, 3 for validation\n",
      "TFRecord folder: ./tfrecords/context_128_bs64\n",
      "Total examples: 33965\n",
      "Train examples: 30568\n",
      "Steps per epoch: 477\n"
     ]
    }
   ],
   "source": [
    "train_ds_64, val_ds_64, steps_64 = prepare_tfrecords(\n",
    "    text_file_path='/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt',\n",
    "    token_to_id_dict=token_to_id_dict,\n",
    "    context_length=CONTEXT_LEN,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "train_ds_64 = train_ds_64.shuffle(10000)\n",
    "val_ds_64 = val_ds_64.shuffle(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e152da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODER_BLOCKS = 5\n",
    "# ATTENTION_HEADS = 8\n",
    "\n",
    "# GPT_model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,ATTENTION_HEADS,0.00001,DECODER_BLOCKS,0.3)\n",
    "# _ = GPT_model((token_ids, attention_mask))\n",
    "# GPT_model.summary(expand_nested=True)\n",
    "\n",
    "# # training (stable): use logits\n",
    "# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# opt = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-4, clipnorm=1.0)\n",
    "# GPT_model.compile(optimizer=opt, loss=loss) # type: ignore\n",
    "\n",
    "# # inference probs (when you actually need them)\n",
    "# logits = GPT_model((token_ids, attention_mask), training=False)\n",
    "# probs = keras.ops.softmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECODER_BLOCKS = 1\n",
    "ATTENTION_HEADS = 2\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "model = GPT(D_MODEL,VOCAB_SIZE,CONTEXT_LEN,ATTENTION_HEADS,0.00001,DECODER_BLOCKS,DROPOUT_RATE)\n",
    "\n",
    "# Compile your model (same as before)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-4, clipnorm=1.0)\n",
    "model.compile(optimizer=opt, loss=loss,metrics=['accuracy']) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f699204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Total epochs: 100\n",
      "Steps per epoch: 477\n",
      "Total steps: 47700\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:47:57.025887: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:47:57.805676: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:47:58.603023: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-08-30 05:47:58.867344: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 320 bytes spill stores, 320 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0125 - loss: 4.3998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:11.561710: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:48:12.216843: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:48:12.217100: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:48:12.217368: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-30 05:48:12.950478: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 356 bytes spill stores, 356 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:13.171887: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:14.325902: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:14.346160: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4107', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-08-30 05:48:14.528715: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 320 bytes spill stores, 320 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0219 - loss: 4.2359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:26.773636: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:48:29.787357: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-08-30 05:48:30.133876: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_01_val_loss_3.2356.keras\n",
      "\n",
      "Epoch 1: val_loss improved from None to 3.23563, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:33.442291: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "2025-08-30 05:48:33.442345: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:33.442375: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.0509 - loss: 3.9237 - val_accuracy: 0.1615 - val_loss: 3.2356\n",
      "Epoch 2/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.1318 - loss: 3.3174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:34.254991: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:48:34.255101: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_02_val_loss_3.2246.keras\n",
      "\n",
      "Epoch 2: val_loss improved from 3.23563 to 3.22456, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:34.875962: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:34.876018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:34.876050: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1319 - loss: 3.3143 - val_accuracy: 0.1633 - val_loss: 3.2246\n",
      "Epoch 3/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1556 - loss: 3.1781\n",
      "Epoch 3: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_03_val_loss_2.7940.keras\n",
      "\n",
      "Epoch 3: val_loss improved from 3.22456 to 2.79397, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:39.775665: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:39.775701: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:39.775723: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1768 - loss: 3.0698 - val_accuracy: 0.2366 - val_loss: 2.7940\n",
      "Epoch 4/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2213 - loss: 2.8717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:40.047517: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:40.047553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:40.047576: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_04_val_loss_2.7887.keras\n",
      "\n",
      "Epoch 4: val_loss improved from 2.79397 to 2.78873, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:40.298954: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:40.298990: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:40.299011: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2209 - loss: 2.8740 - val_accuracy: 0.2371 - val_loss: 2.7887\n",
      "Epoch 5/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2310 - loss: 2.7915\n",
      "Epoch 5: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_05_val_loss_2.6042.keras\n",
      "\n",
      "Epoch 5: val_loss improved from 2.78873 to 2.60420, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:45.673637: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:45.673692: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2365 - loss: 2.7335 - val_accuracy: 0.2501 - val_loss: 2.6042\n",
      "Epoch 6/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2451 - loss: 2.6488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:45.949938: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:45.949974: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:45.949996: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_06_val_loss_2.6029.keras\n",
      "\n",
      "Epoch 6: val_loss improved from 2.60420 to 2.60287, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:46.180428: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:46.180463: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:46.180486: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2456 - loss: 2.6485 - val_accuracy: 0.2502 - val_loss: 2.6029\n",
      "Epoch 7/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2455 - loss: 2.6134\n",
      "Epoch 7: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_07_val_loss_2.5269.keras\n",
      "\n",
      "Epoch 7: val_loss improved from 2.60287 to 2.52689, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:51.997628: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:51.997665: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:51.997699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.2467 - loss: 2.5898 - val_accuracy: 0.2526 - val_loss: 2.5269\n",
      "Epoch 8/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2477 - loss: 2.5591\n",
      "Epoch 8: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_08_val_loss_2.5254.keras\n",
      "\n",
      "Epoch 8: val_loss improved from 2.52689 to 2.52541, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:52.534110: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:52.534147: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:52.534168: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2479 - loss: 2.5525 - val_accuracy: 0.2524 - val_loss: 2.5254\n",
      "Epoch 9/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2495 - loss: 2.5352\n",
      "Epoch 9: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_09_val_loss_2.4857.keras\n",
      "\n",
      "Epoch 9: val_loss improved from 2.52541 to 2.48573, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:57.679829: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:57.679867: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:57.679899: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2515 - loss: 2.5224 - val_accuracy: 0.2593 - val_loss: 2.4857\n",
      "Epoch 10/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2524 - loss: 2.5192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:57.961112: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:57.961152: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:57.961178: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_10_val_loss_2.4845.keras\n",
      "\n",
      "Epoch 10: val_loss improved from 2.48573 to 2.48451, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:48:58.222612: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:48:58.222661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:48:58.222687: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2591 - loss: 2.4941 - val_accuracy: 0.2589 - val_loss: 2.4845\n",
      "Epoch 11/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2595 - loss: 2.4846\n",
      "Epoch 11: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_11_val_loss_2.4221.keras\n",
      "\n",
      "Epoch 11: val_loss improved from 2.48451 to 2.42211, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:03.239920: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:03.239960: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:03.239984: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2653 - loss: 2.4672 - val_accuracy: 0.2830 - val_loss: 2.4221\n",
      "Epoch 12/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2789 - loss: 2.4432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:03.495291: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_12_val_loss_2.4216.keras\n",
      "\n",
      "Epoch 12: val_loss improved from 2.42211 to 2.42159, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:03.729935: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:03.729975: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:03.729998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.2759 - loss: 2.4277 - val_accuracy: 0.2818 - val_loss: 2.4216\n",
      "Epoch 13/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2796 - loss: 2.4208\n",
      "Epoch 13: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_13_val_loss_2.3846.keras\n",
      "\n",
      "Epoch 13: val_loss improved from 2.42159 to 2.38459, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:08.525764: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:08.525847: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:08.525897: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2826 - loss: 2.4090 - val_accuracy: 0.2929 - val_loss: 2.3846\n",
      "Epoch 14/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2876 - loss: 2.3941\n",
      "Epoch 14: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_14_val_loss_2.3832.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:08.799223: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:08.799291: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:08.993301: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:08.993343: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:08.993365: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: val_loss improved from 2.38459 to 2.38316, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.2850 - loss: 2.3937 - val_accuracy: 0.2911 - val_loss: 2.3832\n",
      "Epoch 15/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2897 - loss: 2.3822\n",
      "Epoch 15: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_15_val_loss_2.3570.keras\n",
      "\n",
      "Epoch 15: val_loss improved from 2.38316 to 2.35702, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:14.575851: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:14.575890: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:14.575911: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2915 - loss: 2.3742 - val_accuracy: 0.2980 - val_loss: 2.3570\n",
      "Epoch 16/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2958 - loss: 2.3704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:14.862239: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_16_val_loss_2.3561.keras\n",
      "\n",
      "Epoch 16: val_loss improved from 2.35702 to 2.35614, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:15.156398: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:15.156437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:15.156458: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2936 - loss: 2.3624 - val_accuracy: 0.3004 - val_loss: 2.3561\n",
      "Epoch 17/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2972 - loss: 2.3521\n",
      "Epoch 17: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_17_val_loss_2.3279.keras\n",
      "\n",
      "Epoch 17: val_loss improved from 2.35614 to 2.32791, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:19.848763: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:19.848799: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:19.848821: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2988 - loss: 2.3453 - val_accuracy: 0.3060 - val_loss: 2.3279\n",
      "Epoch 18/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3062 - loss: 2.3160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:20.130623: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_18_val_loss_2.3278.keras\n",
      "\n",
      "Epoch 18: val_loss improved from 2.32791 to 2.32778, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:20.356863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:20.356899: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:20.356920: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3041 - loss: 2.3269 - val_accuracy: 0.3057 - val_loss: 2.3278\n",
      "Epoch 19/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3043 - loss: 2.3243\n",
      "Epoch 19: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_19_val_loss_2.2985.keras\n",
      "\n",
      "Epoch 19: val_loss improved from 2.32778 to 2.29853, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:24.537849: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:24.538041: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:24.538084: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3062 - loss: 2.3168 - val_accuracy: 0.3153 - val_loss: 2.2985\n",
      "Epoch 20/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3123 - loss: 2.3105\n",
      "Epoch 20: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_20_val_loss_2.2979.keras\n",
      "\n",
      "Epoch 20: val_loss improved from 2.29853 to 2.29789, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:25.114429: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:25.114465: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:25.114486: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3117 - loss: 2.3020 - val_accuracy: 0.3158 - val_loss: 2.2979\n",
      "Epoch 21/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3130 - loss: 2.2963\n",
      "Epoch 21: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_21_val_loss_2.2681.keras\n",
      "\n",
      "Epoch 21: val_loss improved from 2.29789 to 2.26807, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:29.486793: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:29.486831: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:29.486853: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3152 - loss: 2.2896 - val_accuracy: 0.3248 - val_loss: 2.2681\n",
      "Epoch 22/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3201 - loss: 2.2594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:29.746451: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:29.746490: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:29.746512: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_22_val_loss_2.2675.keras\n",
      "\n",
      "Epoch 22: val_loss improved from 2.26807 to 2.26749, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:29.994153: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:29.994190: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:29.994215: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3207 - loss: 2.2715 - val_accuracy: 0.3254 - val_loss: 2.2675\n",
      "Epoch 23/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3216 - loss: 2.2696\n",
      "Epoch 23: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_23_val_loss_2.2404.keras\n",
      "\n",
      "Epoch 23: val_loss improved from 2.26749 to 2.24037, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:34.340750: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:34.340788: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:34.340811: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3238 - loss: 2.2634 - val_accuracy: 0.3331 - val_loss: 2.2404\n",
      "Epoch 24/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3308 - loss: 2.2316\n",
      "Epoch 24: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_24_val_loss_2.2403.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:34.609260: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:34.805869: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: val_loss improved from 2.24037 to 2.24032, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.3265 - loss: 2.2461 - val_accuracy: 0.3342 - val_loss: 2.2403\n",
      "Epoch 25/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3294 - loss: 2.2455\n",
      "Epoch 25: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_25_val_loss_2.2152.keras\n",
      "\n",
      "Epoch 25: val_loss improved from 2.24032 to 2.21518, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:39.082269: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:39.082307: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:39.082329: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3316 - loss: 2.2388 - val_accuracy: 0.3428 - val_loss: 2.2152\n",
      "Epoch 26/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3446 - loss: 2.2045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:39.346857: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_26_val_loss_2.2147.keras\n",
      "\n",
      "Epoch 26: val_loss improved from 2.21518 to 2.21469, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:39.569906: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:39.569944: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:39.569966: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3350 - loss: 2.2299 - val_accuracy: 0.3429 - val_loss: 2.2147\n",
      "Epoch 27/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3372 - loss: 2.2211\n",
      "Epoch 27: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_27_val_loss_2.1913.keras\n",
      "\n",
      "Epoch 27: val_loss improved from 2.21469 to 2.19127, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:43.384212: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:43.384257: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:43.384279: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3387 - loss: 2.2160 - val_accuracy: 0.3491 - val_loss: 2.1913\n",
      "Epoch 28/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3435 - loss: 2.2082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:43.666028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:43.666066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:43.666090: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_28_val_loss_2.1906.keras\n",
      "\n",
      "Epoch 28: val_loss improved from 2.19127 to 2.19065, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:43.867382: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:43.867426: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:43.867450: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3429 - loss: 2.2066 - val_accuracy: 0.3492 - val_loss: 2.1906\n",
      "Epoch 29/1000\n",
      "\u001b[1m471/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3430 - loss: 2.2005\n",
      "Epoch 29: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_29_val_loss_2.1673.keras\n",
      "\n",
      "Epoch 29: val_loss improved from 2.19065 to 2.16727, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:48.412749: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:48.412835: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3450 - loss: 2.1941 - val_accuracy: 0.3557 - val_loss: 2.1673\n",
      "Epoch 30/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3418 - loss: 2.2051\n",
      "Epoch 30: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_30_val_loss_2.1681.keras\n",
      "\n",
      "Epoch 30: val_loss did not improve from 2.16727\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3478 - loss: 2.1874 - val_accuracy: 0.3558 - val_loss: 2.1681\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:48.968343: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:48.968383: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:48.968404: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3498 - loss: 2.1783\n",
      "Epoch 31: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_31_val_loss_2.1441.keras\n",
      "\n",
      "Epoch 31: val_loss improved from 2.16727 to 2.14412, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:53.744027: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:53.744066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:53.744088: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3513 - loss: 2.1729 - val_accuracy: 0.3620 - val_loss: 2.1441\n",
      "Epoch 32/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3632 - loss: 2.1522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:54.004119: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_32_val_loss_2.1444.keras\n",
      "\n",
      "Epoch 32: val_loss did not improve from 2.14412\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.3546 - loss: 2.1649 - val_accuracy: 0.3619 - val_loss: 2.1444\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:54.249050: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:54.249087: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:54.249108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3557 - loss: 2.1573\n",
      "Epoch 33: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_33_val_loss_2.1235.keras\n",
      "\n",
      "Epoch 33: val_loss improved from 2.14412 to 2.12355, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:58.563602: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:58.563663: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3568 - loss: 2.1530 - val_accuracy: 0.3675 - val_loss: 2.1235\n",
      "Epoch 34/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3682 - loss: 2.1251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:49:58.840606: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:49:59.038529: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:49:59.038570: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:49:59.038591: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_34_val_loss_2.1234.keras\n",
      "\n",
      "Epoch 34: val_loss improved from 2.12355 to 2.12337, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.3588 - loss: 2.1435 - val_accuracy: 0.3673 - val_loss: 2.1234\n",
      "Epoch 35/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3603 - loss: 2.1401\n",
      "Epoch 35: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_35_val_loss_2.1074.keras\n",
      "\n",
      "Epoch 35: val_loss improved from 2.12337 to 2.10742, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:04.327186: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:04.327226: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:04.327249: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3614 - loss: 2.1362 - val_accuracy: 0.3712 - val_loss: 2.1074\n",
      "Epoch 36/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3668 - loss: 2.1225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:04.655182: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_36_val_loss_2.1060.keras\n",
      "\n",
      "Epoch 36: val_loss improved from 2.10742 to 2.10602, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:04.885376: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:50:04.885459: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3664 - loss: 2.1236 - val_accuracy: 0.3713 - val_loss: 2.1060\n",
      "Epoch 37/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3641 - loss: 2.1254\n",
      "Epoch 37: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_37_val_loss_2.0919.keras\n",
      "\n",
      "Epoch 37: val_loss improved from 2.10602 to 2.09188, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:09.972355: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3652 - loss: 2.1214 - val_accuracy: 0.3751 - val_loss: 2.0919\n",
      "Epoch 38/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3608 - loss: 2.1380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:10.240634: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:10.240686: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:10.240717: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_38_val_loss_2.0920.keras\n",
      "\n",
      "Epoch 38: val_loss did not improve from 2.09188\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.3669 - loss: 2.1130 - val_accuracy: 0.3755 - val_loss: 2.0920\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:10.470397: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:10.470436: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:10.470458: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3672 - loss: 2.1117\n",
      "Epoch 39: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_39_val_loss_2.0794.keras\n",
      "\n",
      "Epoch 39: val_loss improved from 2.09188 to 2.07936, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:14.871451: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:14.871492: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:14.871514: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3677 - loss: 2.1091 - val_accuracy: 0.3779 - val_loss: 2.0794\n",
      "Epoch 40/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3810 - loss: 2.0897\n",
      "Epoch 40: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_40_val_loss_2.0798.keras\n",
      "\n",
      "Epoch 40: val_loss did not improve from 2.07936\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.3730 - loss: 2.1069 - val_accuracy: 0.3779 - val_loss: 2.0798\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:15.352005: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:15.352045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:15.352055: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3695 - loss: 2.1021\n",
      "Epoch 41: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_41_val_loss_2.0680.keras\n",
      "\n",
      "Epoch 41: val_loss improved from 2.07936 to 2.06800, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:20.264525: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:20.264564: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:20.264586: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3701 - loss: 2.0993 - val_accuracy: 0.3805 - val_loss: 2.0680\n",
      "Epoch 42/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3796 - loss: 2.0571\n",
      "Epoch 42: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_42_val_loss_2.0682.keras\n",
      "\n",
      "Epoch 42: val_loss did not improve from 2.06800\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.3724 - loss: 2.0856 - val_accuracy: 0.3797 - val_loss: 2.0682\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:20.766950: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:20.766991: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:20.767012: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3720 - loss: 2.0922\n",
      "Epoch 43: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_43_val_loss_2.0608.keras\n",
      "\n",
      "Epoch 43: val_loss improved from 2.06800 to 2.06083, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:26.320045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:26.320086: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:26.320108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3719 - loss: 2.0900 - val_accuracy: 0.3810 - val_loss: 2.0608\n",
      "Epoch 44/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3760 - loss: 2.0864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:26.601341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:26.601396: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:26.601431: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_44_val_loss_2.0593.keras\n",
      "\n",
      "Epoch 44: val_loss improved from 2.06083 to 2.05929, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:26.889699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:26.889739: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:26.889760: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3765 - loss: 2.0792 - val_accuracy: 0.3820 - val_loss: 2.0593\n",
      "Epoch 45/1000\n",
      "\u001b[1m469/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3734 - loss: 2.0837\n",
      "Epoch 45: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_45_val_loss_2.0511.keras\n",
      "\n",
      "Epoch 45: val_loss improved from 2.05929 to 2.05108, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:31.955981: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:31.956019: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:31.956039: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3736 - loss: 2.0822 - val_accuracy: 0.3830 - val_loss: 2.0511\n",
      "Epoch 46/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3745 - loss: 2.0810\n",
      "Epoch 46: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_46_val_loss_2.0509.keras\n",
      "\n",
      "Epoch 46: val_loss improved from 2.05108 to 2.05094, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:32.446706: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:50:32.446759: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.3737 - loss: 2.0785 - val_accuracy: 0.3835 - val_loss: 2.0509\n",
      "Epoch 47/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3747 - loss: 2.0772\n",
      "Epoch 47: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_47_val_loss_2.0439.keras\n",
      "\n",
      "Epoch 47: val_loss improved from 2.05094 to 2.04388, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:37.797441: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:37.797480: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:37.797501: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3750 - loss: 2.0754 - val_accuracy: 0.3852 - val_loss: 2.0439\n",
      "Epoch 48/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3674 - loss: 2.0842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:38.084927: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:38.084971: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:38.084998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_48_val_loss_2.0441.keras\n",
      "\n",
      "Epoch 48: val_loss did not improve from 2.04388\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.3742 - loss: 2.0752 - val_accuracy: 0.3850 - val_loss: 2.0441\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:38.318091: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-08-30 05:50:38.318133: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:38.318140: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:38.318159: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3762 - loss: 2.0707\n",
      "Epoch 49: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_49_val_loss_2.0379.keras\n",
      "\n",
      "Epoch 49: val_loss improved from 2.04388 to 2.03794, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:43.717617: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:43.717670: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:43.717691: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3765 - loss: 2.0695 - val_accuracy: 0.3855 - val_loss: 2.0379\n",
      "Epoch 50/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3750 - loss: 2.0787"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:43.984188: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_50_val_loss_2.0372.keras\n",
      "\n",
      "Epoch 50: val_loss improved from 2.03794 to 2.03716, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:44.246211: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:44.246259: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:44.246288: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3710 - loss: 2.0798 - val_accuracy: 0.3866 - val_loss: 2.0372\n",
      "Epoch 51/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3771 - loss: 2.0664\n",
      "Epoch 51: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_51_val_loss_2.0321.keras\n",
      "\n",
      "Epoch 51: val_loss improved from 2.03716 to 2.03208, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:49.699731: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:49.699785: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3776 - loss: 2.0642 - val_accuracy: 0.3877 - val_loss: 2.0321\n",
      "Epoch 52/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3788 - loss: 2.0670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:49.969729: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:49.969777: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:49.969809: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_52_val_loss_2.0329.keras\n",
      "\n",
      "Epoch 52: val_loss did not improve from 2.03208\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3762 - loss: 2.0656 - val_accuracy: 0.3870 - val_loss: 2.0329\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:50.248155: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3780 - loss: 2.0608\n",
      "Epoch 53: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_53_val_loss_2.0284.keras\n",
      "\n",
      "Epoch 53: val_loss improved from 2.03208 to 2.02836, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:55.510638: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:55.510677: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:55.510699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3785 - loss: 2.0599 - val_accuracy: 0.3883 - val_loss: 2.0284\n",
      "Epoch 54/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3726 - loss: 2.0647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:55.788540: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:55.788583: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:55.788607: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_54_val_loss_2.0283.keras\n",
      "\n",
      "Epoch 54: val_loss improved from 2.02836 to 2.02831, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:50:56.019367: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:50:56.019407: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:50:56.019429: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3794 - loss: 2.0542 - val_accuracy: 0.3878 - val_loss: 2.0283\n",
      "Epoch 55/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3797 - loss: 2.0562\n",
      "Epoch 55: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_55_val_loss_2.0234.keras\n",
      "\n",
      "Epoch 55: val_loss improved from 2.02831 to 2.02336, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:01.411671: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:01.411719: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:01.411741: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3797 - loss: 2.0556 - val_accuracy: 0.3892 - val_loss: 2.0234\n",
      "Epoch 56/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3751 - loss: 2.0656\n",
      "Epoch 56: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_56_val_loss_2.0236.keras\n",
      "\n",
      "Epoch 56: val_loss did not improve from 2.02336\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.3798 - loss: 2.0550 - val_accuracy: 0.3891 - val_loss: 2.0236\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:01.906783: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:01.906825: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:01.906846: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3800 - loss: 2.0538\n",
      "Epoch 57: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_57_val_loss_2.0202.keras\n",
      "\n",
      "Epoch 57: val_loss improved from 2.02336 to 2.02016, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:06.375003: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:06.375042: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:06.375062: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3805 - loss: 2.0528 - val_accuracy: 0.3896 - val_loss: 2.0202\n",
      "Epoch 58/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3875 - loss: 2.0138\n",
      "Epoch 58: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_58_val_loss_2.0196.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:06.631333: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:06.631371: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:06.631394: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:06.817201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:06.817239: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:06.817261: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58: val_loss improved from 2.02016 to 2.01957, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.3837 - loss: 2.0423 - val_accuracy: 0.3897 - val_loss: 2.0196\n",
      "Epoch 59/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3811 - loss: 2.0498\n",
      "Epoch 59: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_59_val_loss_2.0166.keras\n",
      "\n",
      "Epoch 59: val_loss improved from 2.01957 to 2.01658, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3809 - loss: 2.0497 - val_accuracy: 0.3905 - val_loss: 2.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:11.058637: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:11.058675: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:11.058703: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3894 - loss: 2.0451\n",
      "Epoch 60: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_60_val_loss_2.0164.keras\n",
      "\n",
      "Epoch 60: val_loss improved from 2.01658 to 2.01639, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:11.545123: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:11.545163: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:11.545185: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3853 - loss: 2.0399 - val_accuracy: 0.3907 - val_loss: 2.0164\n",
      "Epoch 61/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3815 - loss: 2.0474\n",
      "Epoch 61: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_61_val_loss_2.0141.keras\n",
      "\n",
      "Epoch 61: val_loss improved from 2.01639 to 2.01412, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:15.206931: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:15.206971: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:15.206993: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3815 - loss: 2.0470 - val_accuracy: 0.3912 - val_loss: 2.0141\n",
      "Epoch 62/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3851 - loss: 2.0230\n",
      "Epoch 62: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_62_val_loss_2.0146.keras\n",
      "\n",
      "Epoch 62: val_loss did not improve from 2.01412\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.3820 - loss: 2.0457 - val_accuracy: 0.3915 - val_loss: 2.0146\n",
      "Epoch 63/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:15.692666: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:15.692707: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:15.692731: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3820 - loss: 2.0460\n",
      "Epoch 63: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_63_val_loss_2.0131.keras\n",
      "\n",
      "Epoch 63: val_loss improved from 2.01412 to 2.01309, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:19.721935: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:19.721973: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:19.721995: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3822 - loss: 2.0443 - val_accuracy: 0.3914 - val_loss: 2.0131\n",
      "Epoch 64/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3827 - loss: 2.0547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:19.988639: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_64_val_loss_2.0126.keras\n",
      "\n",
      "Epoch 64: val_loss improved from 2.01309 to 2.01264, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:20.196905: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:20.196964: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:20.196986: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.3823 - loss: 2.0471 - val_accuracy: 0.3910 - val_loss: 2.0126\n",
      "Epoch 65/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3834 - loss: 2.0424\n",
      "Epoch 65: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_65_val_loss_2.0108.keras\n",
      "\n",
      "Epoch 65: val_loss improved from 2.01264 to 2.01082, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:24.086314: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:24.086354: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:24.086401: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3826 - loss: 2.0432 - val_accuracy: 0.3917 - val_loss: 2.0108\n",
      "Epoch 66/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3698 - loss: 2.0734\n",
      "Epoch 66: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_66_val_loss_2.0107.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:24.342887: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:24.529368: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:24.529406: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:24.529427: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66: val_loss improved from 2.01082 to 2.01072, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.3822 - loss: 2.0418 - val_accuracy: 0.3921 - val_loss: 2.0107\n",
      "Epoch 67/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3826 - loss: 2.0422\n",
      "Epoch 67: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_67_val_loss_2.0088.keras\n",
      "\n",
      "Epoch 67: val_loss improved from 2.01072 to 2.00883, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3828 - loss: 2.0417 - val_accuracy: 0.3922 - val_loss: 2.0088\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:29.370231: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:29.370273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:29.370295: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3812 - loss: 2.0355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:29.614325: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_68_val_loss_2.0089.keras\n",
      "\n",
      "Epoch 68: val_loss did not improve from 2.00883\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.3813 - loss: 2.0475 - val_accuracy: 0.3920 - val_loss: 2.0089\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:29.865234: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:29.865273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:29.865294: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3825 - loss: 2.0426\n",
      "Epoch 69: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_69_val_loss_2.0082.keras\n",
      "\n",
      "Epoch 69: val_loss improved from 2.00883 to 2.00816, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3831 - loss: 2.0407 - val_accuracy: 0.3924 - val_loss: 2.0082\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:34.746031: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3783 - loss: 2.0424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:34.989791: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:34.989831: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:34.989855: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_70_val_loss_2.0081.keras\n",
      "\n",
      "Epoch 70: val_loss improved from 2.00816 to 2.00813, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:35.219410: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:35.219449: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:35.219471: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.3835 - loss: 2.0348 - val_accuracy: 0.3927 - val_loss: 2.0081\n",
      "Epoch 71/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3833 - loss: 2.0403\n",
      "Epoch 71: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_71_val_loss_2.0072.keras\n",
      "\n",
      "Epoch 71: val_loss improved from 2.00813 to 2.00720, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:40.152616: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:40.152654: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:40.152676: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3832 - loss: 2.0397 - val_accuracy: 0.3922 - val_loss: 2.0072\n",
      "Epoch 72/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3828 - loss: 2.0569\n",
      "Epoch 72: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_72_val_loss_2.0064.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:40.396071: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:40.587487: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:40.587527: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:40.587548: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72: val_loss improved from 2.00720 to 2.00635, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.3832 - loss: 2.0421 - val_accuracy: 0.3927 - val_loss: 2.0064\n",
      "Epoch 73/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3836 - loss: 2.0393\n",
      "Epoch 73: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_73_val_loss_2.0055.keras\n",
      "\n",
      "Epoch 73: val_loss improved from 2.00635 to 2.00553, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:45.351607: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:45.351645: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:45.351669: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3836 - loss: 2.0390 - val_accuracy: 0.3925 - val_loss: 2.0055\n",
      "Epoch 74/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3807 - loss: 2.0593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:45.606041: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:45.803258: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:45.803298: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:45.803319: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_74_val_loss_2.0056.keras\n",
      "\n",
      "Epoch 74: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.3835 - loss: 2.0418 - val_accuracy: 0.3931 - val_loss: 2.0056\n",
      "Epoch 75/1000\n",
      "\u001b[1m469/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3839 - loss: 2.0365\n",
      "Epoch 75: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_75_val_loss_2.0062.keras\n",
      "\n",
      "Epoch 75: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0382 - val_accuracy: 0.3926 - val_loss: 2.0062\n",
      "Epoch 76/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3705 - loss: 2.0623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:49.854537: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:49.854575: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:49.854597: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:50.054393: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:50.054432: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:50.054455: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_76_val_loss_2.0065.keras\n",
      "\n",
      "Epoch 76: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.3797 - loss: 2.0445 - val_accuracy: 0.3921 - val_loss: 2.0065\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:50.248995: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:50.249034: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:50.249056: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0376\n",
      "Epoch 77: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_77_val_loss_2.0059.keras\n",
      "\n",
      "Epoch 77: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3836 - loss: 2.0382 - val_accuracy: 0.3929 - val_loss: 2.0059\n",
      "Epoch 78/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3955 - loss: 2.0214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:54.439337: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:54.439375: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:54.439397: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_78_val_loss_2.0058.keras\n",
      "\n",
      "Epoch 78: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.3847 - loss: 2.0353 - val_accuracy: 0.3930 - val_loss: 2.0058\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:54.883123: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:54.883159: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:54.883179: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3832 - loss: 2.0387\n",
      "Epoch 79: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_79_val_loss_2.0067.keras\n",
      "\n",
      "Epoch 79: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3835 - loss: 2.0382 - val_accuracy: 0.3926 - val_loss: 2.0067\n",
      "Epoch 80/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3857 - loss: 2.0235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:58.752010: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:58.752047: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:58.752071: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:51:58.949437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:58.949480: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:58.949508: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_80_val_loss_2.0062.keras\n",
      "\n",
      "Epoch 80: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.3839 - loss: 2.0347 - val_accuracy: 0.3924 - val_loss: 2.0062\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:51:59.200276: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:51:59.200314: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:51:59.200337: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3838 - loss: 2.0364\n",
      "Epoch 81: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_81_val_loss_2.0057.keras\n",
      "\n",
      "Epoch 81: val_loss did not improve from 2.00553\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3837 - loss: 2.0380 - val_accuracy: 0.3926 - val_loss: 2.0057\n",
      "Epoch 82/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3827 - loss: 2.0352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:03.809529: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:03.809566: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:03.809587: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:04.016692: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:04.016735: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:04.016760: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_82_val_loss_2.0051.keras\n",
      "\n",
      "Epoch 82: val_loss improved from 2.00553 to 2.00512, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:04.280803: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:04.280855: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3833 - loss: 2.0381 - val_accuracy: 0.3932 - val_loss: 2.0051\n",
      "Epoch 83/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3840 - loss: 2.0376\n",
      "Epoch 83: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_83_val_loss_2.0054.keras\n",
      "\n",
      "Epoch 83: val_loss did not improve from 2.00512\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3839 - loss: 2.0372 - val_accuracy: 0.3929 - val_loss: 2.0054\n",
      "Epoch 84/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3857 - loss: 2.0232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:09.301391: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:09.301446: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3824 - loss: 2.0430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:09.543365: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:09.543410: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:09.543437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_84_val_loss_2.0057.keras\n",
      "\n",
      "Epoch 84: val_loss did not improve from 2.00512\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.3813 - loss: 2.0502 - val_accuracy: 0.3932 - val_loss: 2.0057\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:09.771305: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:09.771342: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:09.771364: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3836 - loss: 2.0384\n",
      "Epoch 85: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_85_val_loss_2.0053.keras\n",
      "\n",
      "Epoch 85: val_loss did not improve from 2.00512\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3836 - loss: 2.0377 - val_accuracy: 0.3931 - val_loss: 2.0053\n",
      "Epoch 86/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3834 - loss: 2.0336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:14.504773: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:14.504816: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:14.504841: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:14.716273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:14.716341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_86_val_loss_2.0049.keras\n",
      "\n",
      "Epoch 86: val_loss improved from 2.00512 to 2.00494, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:14.990301: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:14.990341: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:14.990363: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3879 - loss: 2.0290 - val_accuracy: 0.3928 - val_loss: 2.0049\n",
      "Epoch 87/1000\n",
      "\u001b[1m469/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3834 - loss: 2.0391\n",
      "Epoch 87: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_87_val_loss_2.0047.keras\n",
      "\n",
      "Epoch 87: val_loss improved from 2.00494 to 2.00475, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:19.034513: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:19.034554: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:19.034576: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0374 - val_accuracy: 0.3934 - val_loss: 2.0047\n",
      "Epoch 88/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3849 - loss: 2.0506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:19.294366: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_88_val_loss_2.0054.keras\n",
      "\n",
      "Epoch 88: val_loss did not improve from 2.00475\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.3857 - loss: 2.0343 - val_accuracy: 0.3930 - val_loss: 2.0054\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:19.499347: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:19.499385: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:19.499407: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3842 - loss: 2.0366\n",
      "Epoch 89: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_89_val_loss_2.0042.keras\n",
      "\n",
      "Epoch 89: val_loss improved from 2.00475 to 2.00420, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:23.188267: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:23.188321: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3837 - loss: 2.0375 - val_accuracy: 0.3934 - val_loss: 2.0042\n",
      "Epoch 90/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3905 - loss: 2.0259\n",
      "Epoch 90: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_90_val_loss_2.0046.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:23.453364: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:23.453420: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:23.639614: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:23.639652: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:23.639673: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90: val_loss did not improve from 2.00420\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.3850 - loss: 2.0280 - val_accuracy: 0.3929 - val_loss: 2.0046\n",
      "Epoch 91/1000\n",
      "\u001b[1m468/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3837 - loss: 2.0381\n",
      "Epoch 91: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_91_val_loss_2.0051.keras\n",
      "\n",
      "Epoch 91: val_loss did not improve from 2.00420\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3839 - loss: 2.0371 - val_accuracy: 0.3930 - val_loss: 2.0051\n",
      "Epoch 92/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3835 - loss: 2.0358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:27.148125: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:27.148167: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:27.148208: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:27.345091: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:27.345130: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:27.345155: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_92_val_loss_2.0041.keras\n",
      "\n",
      "Epoch 92: val_loss improved from 2.00420 to 2.00406, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:27.555043: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:27.555085: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:27.555108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.3842 - loss: 2.0384 - val_accuracy: 0.3931 - val_loss: 2.0041\n",
      "Epoch 93/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3839 - loss: 2.0366\n",
      "Epoch 93: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_93_val_loss_2.0045.keras\n",
      "\n",
      "Epoch 93: val_loss did not improve from 2.00406\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3841 - loss: 2.0363 - val_accuracy: 0.3935 - val_loss: 2.0045\n",
      "Epoch 94/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3816 - loss: 2.0404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:31.721559: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:31.721599: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:31.721621: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:52:31.970860: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_94_val_loss_2.0034.keras\n",
      "\n",
      "Epoch 94: val_loss improved from 2.00406 to 2.00335, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:32.180602: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:32.180651: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:32.180683: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3831 - loss: 2.0383 - val_accuracy: 0.3940 - val_loss: 2.0034\n",
      "Epoch 95/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3839 - loss: 2.0352\n",
      "Epoch 95: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_95_val_loss_2.0033.keras\n",
      "\n",
      "Epoch 95: val_loss improved from 2.00335 to 2.00327, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:36.931278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:36.931337: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:36.931370: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3841 - loss: 2.0359 - val_accuracy: 0.3938 - val_loss: 2.0033\n",
      "Epoch 96/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3953 - loss: 2.0233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:37.211502: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:37.211547: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:37.211572: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_96_val_loss_2.0034.keras\n",
      "\n",
      "Epoch 96: val_loss did not improve from 2.00327\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.3851 - loss: 2.0379 - val_accuracy: 0.3932 - val_loss: 2.0034\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:37.452130: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:37.452172: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:37.452196: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3845 - loss: 2.0353\n",
      "Epoch 97: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_97_val_loss_2.0020.keras\n",
      "\n",
      "Epoch 97: val_loss improved from 2.00327 to 2.00205, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:42.267436: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:42.267474: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:42.267496: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3843 - loss: 2.0354 - val_accuracy: 0.3938 - val_loss: 2.0020\n",
      "Epoch 98/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3905 - loss: 2.0367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:42.561439: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:42.561478: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:42.561501: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_98_val_loss_2.0007.keras\n",
      "\n",
      "Epoch 98: val_loss improved from 2.00205 to 2.00073, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:42.797816: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3878 - loss: 2.0288 - val_accuracy: 0.3939 - val_loss: 2.0007\n",
      "Epoch 99/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3845 - loss: 2.0337\n",
      "Epoch 99: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_99_val_loss_2.0002.keras\n",
      "\n",
      "Epoch 99: val_loss improved from 2.00073 to 2.00018, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:48.185401: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:48.185439: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:48.185463: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3844 - loss: 2.0341 - val_accuracy: 0.3940 - val_loss: 2.0002\n",
      "Epoch 100/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3882 - loss: 2.0257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:48.501064: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_100_val_loss_2.0009.keras\n",
      "\n",
      "Epoch 100: val_loss did not improve from 2.00018\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3854 - loss: 2.0319 - val_accuracy: 0.3938 - val_loss: 2.0009\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:48.814945: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:48.814984: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:48.815008: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3857 - loss: 2.0310\n",
      "Epoch 101: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_101_val_loss_1.9985.keras\n",
      "\n",
      "Epoch 101: val_loss improved from 2.00018 to 1.99855, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:54.586529: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:54.586569: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:54.586592: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3850 - loss: 2.0326 - val_accuracy: 0.3944 - val_loss: 1.9985\n",
      "Epoch 102/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3814 - loss: 2.0381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:54.904916: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:54.904981: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:54.905029: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_102_val_loss_1.9986.keras\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.99855\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3819 - loss: 2.0382 - val_accuracy: 0.3947 - val_loss: 1.9986\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:52:55.159259: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:52:55.159300: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:52:55.159323: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3852 - loss: 2.0309\n",
      "Epoch 103: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_103_val_loss_1.9962.keras\n",
      "\n",
      "Epoch 103: val_loss improved from 1.99855 to 1.99623, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:00.369278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:00.369319: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:00.369343: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3852 - loss: 2.0311 - val_accuracy: 0.3950 - val_loss: 1.9962\n",
      "Epoch 104/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3893 - loss: 2.0133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:00.652201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_104_val_loss_1.9965.keras\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.99623\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3816 - loss: 2.0376 - val_accuracy: 0.3949 - val_loss: 1.9965\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:00.923162: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:00.923202: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:00.923224: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3856 - loss: 2.0303\n",
      "Epoch 105: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_105_val_loss_1.9945.keras\n",
      "\n",
      "Epoch 105: val_loss improved from 1.99623 to 1.99452, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:06.987221: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:06.987330: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:06.987387: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3856 - loss: 2.0293 - val_accuracy: 0.3959 - val_loss: 1.9945\n",
      "Epoch 106/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3880 - loss: 2.0314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:07.310756: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:07.310808: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:07.310842: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_106_val_loss_1.9941.keras\n",
      "\n",
      "Epoch 106: val_loss improved from 1.99452 to 1.99409, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:07.591117: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:07.591164: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:07.591190: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3852 - loss: 2.0345 - val_accuracy: 0.3959 - val_loss: 1.9941\n",
      "Epoch 107/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3857 - loss: 2.0274\n",
      "Epoch 107: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_107_val_loss_1.9938.keras\n",
      "\n",
      "Epoch 107: val_loss improved from 1.99409 to 1.99384, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:13.687951: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:13.687995: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:13.688018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3857 - loss: 2.0273 - val_accuracy: 0.3957 - val_loss: 1.9938\n",
      "Epoch 108/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3895 - loss: 2.0245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:13.980469: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:13.980524: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:13.980553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_108_val_loss_1.9918.keras\n",
      "\n",
      "Epoch 108: val_loss improved from 1.99384 to 1.99180, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:14.240278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:14.240315: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:14.240338: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3869 - loss: 2.0252 - val_accuracy: 0.3964 - val_loss: 1.9918\n",
      "Epoch 109/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3862 - loss: 2.0253\n",
      "Epoch 109: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_109_val_loss_1.9893.keras\n",
      "\n",
      "Epoch 109: val_loss improved from 1.99180 to 1.98931, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:20.213761: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:20.213802: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:20.213824: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3865 - loss: 2.0247 - val_accuracy: 0.3968 - val_loss: 1.9893\n",
      "Epoch 110/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3903 - loss: 2.0175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:20.576075: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:20.576144: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:20.576195: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_110_val_loss_1.9897.keras\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.98931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:20.874943: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3904 - loss: 2.0174 - val_accuracy: 0.3966 - val_loss: 1.9897\n",
      "Epoch 111/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3867 - loss: 2.0244\n",
      "Epoch 111: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_111_val_loss_1.9858.keras\n",
      "\n",
      "Epoch 111: val_loss improved from 1.98931 to 1.98577, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:26.634782: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:26.634834: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3873 - loss: 2.0223 - val_accuracy: 0.3976 - val_loss: 1.9858\n",
      "Epoch 112/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3911 - loss: 2.0133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:26.919957: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:26.919994: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:26.920018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_112_val_loss_1.9852.keras\n",
      "\n",
      "Epoch 112: val_loss improved from 1.98577 to 1.98522, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:27.145827: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:27.145864: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:27.145886: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3872 - loss: 2.0170 - val_accuracy: 0.3978 - val_loss: 1.9852\n",
      "Epoch 113/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3874 - loss: 2.0195\n",
      "Epoch 113: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_113_val_loss_1.9826.keras\n",
      "\n",
      "Epoch 113: val_loss improved from 1.98522 to 1.98257, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:32.574719: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:32.574768: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:32.574794: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3878 - loss: 2.0194 - val_accuracy: 0.3977 - val_loss: 1.9826\n",
      "Epoch 114/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3904 - loss: 2.0115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:32.892334: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:32.892382: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:32.892408: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 114: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_114_val_loss_1.9822.keras\n",
      "\n",
      "Epoch 114: val_loss improved from 1.98257 to 1.98216, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:33.139021: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:33.139066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:33.139090: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3900 - loss: 2.0124 - val_accuracy: 0.3982 - val_loss: 1.9822\n",
      "Epoch 115/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3881 - loss: 2.0170\n",
      "Epoch 115: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_115_val_loss_1.9786.keras\n",
      "\n",
      "Epoch 115: val_loss improved from 1.98216 to 1.97857, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:39.334397: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:39.334432: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:39.334454: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3883 - loss: 2.0166 - val_accuracy: 0.3991 - val_loss: 1.9786\n",
      "Epoch 116/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3906 - loss: 2.0109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:39.643519: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:39.643572: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:39.643598: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_116_val_loss_1.9790.keras\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.97857\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3916 - loss: 2.0140 - val_accuracy: 0.3992 - val_loss: 1.9790\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:39.925168: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:39.925204: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:39.925225: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3888 - loss: 2.0129\n",
      "Epoch 117: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_117_val_loss_1.9751.keras\n",
      "\n",
      "Epoch 117: val_loss improved from 1.97857 to 1.97506, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:45.622018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:45.622053: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:45.622074: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3891 - loss: 2.0128 - val_accuracy: 0.4003 - val_loss: 1.9751\n",
      "Epoch 118/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3867 - loss: 2.0152\n",
      "Epoch 118: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_118_val_loss_1.9748.keras\n",
      "\n",
      "Epoch 118: val_loss improved from 1.97506 to 1.97481, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:46.184316: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:46.184354: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:46.184378: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3874 - loss: 2.0133 - val_accuracy: 0.3998 - val_loss: 1.9748\n",
      "Epoch 119/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3899 - loss: 2.0096\n",
      "Epoch 119: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_119_val_loss_1.9711.keras\n",
      "\n",
      "Epoch 119: val_loss improved from 1.97481 to 1.97105, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:51.568784: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:51.568821: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:51.568842: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3899 - loss: 2.0094 - val_accuracy: 0.4011 - val_loss: 1.9711\n",
      "Epoch 120/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3865 - loss: 2.0212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:51.859634: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:51.859672: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:51.859698: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_120_val_loss_1.9708.keras\n",
      "\n",
      "Epoch 120: val_loss improved from 1.97105 to 1.97082, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:52.168054: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:52.168094: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:52.168119: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3902 - loss: 2.0096 - val_accuracy: 0.4010 - val_loss: 1.9708\n",
      "Epoch 121/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3910 - loss: 2.0062\n",
      "Epoch 121: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_121_val_loss_1.9655.keras\n",
      "\n",
      "Epoch 121: val_loss improved from 1.97082 to 1.96552, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:57.885294: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3910 - loss: 2.0055 - val_accuracy: 0.4019 - val_loss: 1.9655\n",
      "Epoch 122/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3947 - loss: 2.0034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:58.200570: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:58.200649: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:58.200712: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 122: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_122_val_loss_1.9658.keras\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.96552\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.3925 - loss: 2.0027 - val_accuracy: 0.4020 - val_loss: 1.9658\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:53:58.425373: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:53:58.425442: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:53:58.425482: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3912 - loss: 2.0032\n",
      "Epoch 123: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_123_val_loss_1.9630.keras\n",
      "\n",
      "Epoch 123: val_loss improved from 1.96552 to 1.96304, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:04.189805: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:04.189845: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:04.189868: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3917 - loss: 2.0017 - val_accuracy: 0.4021 - val_loss: 1.9630\n",
      "Epoch 124/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3967 - loss: 1.9794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:04.476247: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:04.476288: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:04.476311: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_124_val_loss_1.9628.keras\n",
      "\n",
      "Epoch 124: val_loss improved from 1.96304 to 1.96277, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:04.739045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:04.739086: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:04.739109: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3937 - loss: 1.9977 - val_accuracy: 0.4024 - val_loss: 1.9628\n",
      "Epoch 125/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3920 - loss: 2.0008\n",
      "Epoch 125: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_125_val_loss_1.9567.keras\n",
      "\n",
      "Epoch 125: val_loss improved from 1.96277 to 1.95671, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:09.966262: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:09.966301: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:09.966322: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3925 - loss: 1.9984 - val_accuracy: 0.4036 - val_loss: 1.9567\n",
      "Epoch 126/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3927 - loss: 1.9879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:10.257890: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:10.257930: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:10.257954: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 126: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_126_val_loss_1.9574.keras\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.95671\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.3930 - loss: 1.9889 - val_accuracy: 0.4035 - val_loss: 1.9574\n",
      "Epoch 127/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:10.510961: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:10.511001: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:10.511023: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3933 - loss: 1.9941\n",
      "Epoch 127: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_127_val_loss_1.9525.keras\n",
      "\n",
      "Epoch 127: val_loss improved from 1.95671 to 1.95250, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:16.157195: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:16.157234: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:16.157256: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3934 - loss: 1.9940 - val_accuracy: 0.4047 - val_loss: 1.9525\n",
      "Epoch 128/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3989 - loss: 1.9894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:16.456676: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 128: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_128_val_loss_1.9526.keras\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.95250\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3971 - loss: 1.9891 - val_accuracy: 0.4047 - val_loss: 1.9526\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:16.709079: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:16.709119: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:16.709142: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3942 - loss: 1.9909\n",
      "Epoch 129: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_129_val_loss_1.9494.keras\n",
      "\n",
      "Epoch 129: val_loss improved from 1.95250 to 1.94941, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:21.973870: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:21.973909: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:21.973919: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3945 - loss: 1.9895 - val_accuracy: 0.4059 - val_loss: 1.9494\n",
      "Epoch 130/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3989 - loss: 1.9817\n",
      "Epoch 130: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_130_val_loss_1.9498.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:22.259383: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:54:22.452216: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130: val_loss did not improve from 1.94941\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.3977 - loss: 1.9819 - val_accuracy: 0.4056 - val_loss: 1.9498\n",
      "Epoch 131/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3951 - loss: 1.9876\n",
      "Epoch 131: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_131_val_loss_1.9445.keras\n",
      "\n",
      "Epoch 131: val_loss improved from 1.94941 to 1.94449, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:26.526537: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:26.526577: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:26.526598: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3956 - loss: 1.9855 - val_accuracy: 0.4061 - val_loss: 1.9445\n",
      "Epoch 132/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3911 - loss: 1.9753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:26.790254: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 132: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_132_val_loss_1.9428.keras\n",
      "\n",
      "Epoch 132: val_loss improved from 1.94449 to 1.94278, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:26.997928: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:26.997966: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:26.997987: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3939 - loss: 1.9835 - val_accuracy: 0.4070 - val_loss: 1.9428\n",
      "Epoch 133/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3959 - loss: 1.9834\n",
      "Epoch 133: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_133_val_loss_1.9379.keras\n",
      "\n",
      "Epoch 133: val_loss improved from 1.94278 to 1.93793, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:32.547377: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:32.547422: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:32.547445: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3964 - loss: 1.9809 - val_accuracy: 0.4084 - val_loss: 1.9379\n",
      "Epoch 134/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3985 - loss: 1.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:33.016068: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 134: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_134_val_loss_1.9385.keras\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.93793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:33.331878: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:33.331921: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:33.331943: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3978 - loss: 1.9802 - val_accuracy: 0.4076 - val_loss: 1.9385\n",
      "Epoch 135/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3974 - loss: 1.9775\n",
      "Epoch 135: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_135_val_loss_1.9329.keras\n",
      "\n",
      "Epoch 135: val_loss improved from 1.93793 to 1.93293, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:40.873077: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:40.873152: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:40.873201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.3974 - loss: 1.9771 - val_accuracy: 0.4098 - val_loss: 1.9329\n",
      "Epoch 136/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.3976 - loss: 1.9733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:41.351028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 136: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_136_val_loss_1.9338.keras\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.93293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:41.722292: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:41.722377: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:41.722428: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3957 - loss: 1.9737 - val_accuracy: 0.4096 - val_loss: 1.9338\n",
      "Epoch 137/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3981 - loss: 1.9738\n",
      "Epoch 137: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_137_val_loss_1.9292.keras\n",
      "\n",
      "Epoch 137: val_loss improved from 1.93293 to 1.92917, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:48.927022: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:48.927061: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:48.927084: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.3984 - loss: 1.9724 - val_accuracy: 0.4097 - val_loss: 1.9292\n",
      "Epoch 138/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.3965 - loss: 1.9891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:49.401613: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:49.401699: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:49.401756: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 138: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_138_val_loss_1.9280.keras\n",
      "\n",
      "Epoch 138: val_loss improved from 1.92917 to 1.92795, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:49.753697: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3982 - loss: 1.9825 - val_accuracy: 0.4104 - val_loss: 1.9280\n",
      "Epoch 139/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3989 - loss: 1.9709\n",
      "Epoch 139: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_139_val_loss_1.9242.keras\n",
      "\n",
      "Epoch 139: val_loss improved from 1.92795 to 1.92421, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:56.888413: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:56.888457: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:56.888480: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.3995 - loss: 1.9686 - val_accuracy: 0.4109 - val_loss: 1.9242\n",
      "Epoch 140/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.3987 - loss: 1.9633\n",
      "Epoch 140: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_140_val_loss_1.9240.keras\n",
      "\n",
      "Epoch 140: val_loss improved from 1.92421 to 1.92398, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:54:57.790173: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:54:57.790257: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:54:57.790306: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3982 - loss: 1.9676 - val_accuracy: 0.4115 - val_loss: 1.9240\n",
      "Epoch 141/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4001 - loss: 1.9657\n",
      "Epoch 141: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_141_val_loss_1.9206.keras\n",
      "\n",
      "Epoch 141: val_loss improved from 1.92398 to 1.92058, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:05.844648: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.4005 - loss: 1.9645 - val_accuracy: 0.4118 - val_loss: 1.9206\n",
      "Epoch 142/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.4053 - loss: 1.9495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:06.396380: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 142: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_142_val_loss_1.9214.keras\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.92058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:06.768705: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:06.768761: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:06.768787: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4050 - loss: 1.9566 - val_accuracy: 0.4118 - val_loss: 1.9214\n",
      "Epoch 143/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4015 - loss: 1.9618\n",
      "Epoch 143: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_143_val_loss_1.9147.keras\n",
      "\n",
      "Epoch 143: val_loss improved from 1.92058 to 1.91466, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:13.058172: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:13.058217: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:13.058240: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4017 - loss: 1.9604 - val_accuracy: 0.4135 - val_loss: 1.9147\n",
      "Epoch 144/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.4028 - loss: 1.9548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:13.434305: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 144: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_144_val_loss_1.9147.keras\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.91466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:13.717864: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:13.717907: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:13.717929: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4028 - loss: 1.9541 - val_accuracy: 0.4136 - val_loss: 1.9147\n",
      "Epoch 145/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4028 - loss: 1.9565\n",
      "Epoch 145: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_145_val_loss_1.9101.keras\n",
      "\n",
      "Epoch 145: val_loss improved from 1.91466 to 1.91012, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:20.687663: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:20.687784: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:20.687836: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4028 - loss: 1.9559 - val_accuracy: 0.4151 - val_loss: 1.9101\n",
      "Epoch 146/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.4050 - loss: 1.9465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:21.119454: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:21.119502: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:21.119528: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_146_val_loss_1.9093.keras\n",
      "\n",
      "Epoch 146: val_loss improved from 1.91012 to 1.90930, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:21.450975: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4037 - loss: 1.9524 - val_accuracy: 0.4154 - val_loss: 1.9093\n",
      "Epoch 147/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4032 - loss: 1.9545\n",
      "Epoch 147: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_147_val_loss_1.9066.keras\n",
      "\n",
      "Epoch 147: val_loss improved from 1.90930 to 1.90657, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:28.460328: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:28.460371: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:28.460394: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4039 - loss: 1.9523 - val_accuracy: 0.4151 - val_loss: 1.9066\n",
      "Epoch 148/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4040 - loss: 1.9505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:28.776569: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 148: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_148_val_loss_1.9054.keras\n",
      "\n",
      "Epoch 148: val_loss improved from 1.90657 to 1.90538, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:29.055732: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:29.055773: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:29.055795: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4031 - loss: 1.9499 - val_accuracy: 0.4161 - val_loss: 1.9054\n",
      "Epoch 149/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4045 - loss: 1.9495\n",
      "Epoch 149: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_149_val_loss_1.9024.keras\n",
      "\n",
      "Epoch 149: val_loss improved from 1.90538 to 1.90237, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:35.122104: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:35.122145: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:35.122171: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4048 - loss: 1.9482 - val_accuracy: 0.4169 - val_loss: 1.9024\n",
      "Epoch 150/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3993 - loss: 1.9800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:35.415621: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_150_val_loss_1.9012.keras\n",
      "\n",
      "Epoch 150: val_loss improved from 1.90237 to 1.90120, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:35.690090: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:35.690130: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:35.690152: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4026 - loss: 1.9567 - val_accuracy: 0.4165 - val_loss: 1.9012\n",
      "Epoch 151/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4056 - loss: 1.9460\n",
      "Epoch 151: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_151_val_loss_1.8981.keras\n",
      "\n",
      "Epoch 151: val_loss improved from 1.90120 to 1.89812, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:41.696289: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:41.696348: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:41.696384: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4060 - loss: 1.9440 - val_accuracy: 0.4180 - val_loss: 1.8981\n",
      "Epoch 152/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4047 - loss: 1.9539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:41.998573: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 152: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_152_val_loss_1.8976.keras\n",
      "\n",
      "Epoch 152: val_loss improved from 1.89812 to 1.89761, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:42.281220: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:42.281276: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:42.281308: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4072 - loss: 1.9506 - val_accuracy: 0.4173 - val_loss: 1.8976\n",
      "Epoch 153/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4065 - loss: 1.9413\n",
      "Epoch 153: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_153_val_loss_1.8942.keras\n",
      "\n",
      "Epoch 153: val_loss improved from 1.89761 to 1.89420, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:48.203386: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:48.203423: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:48.203445: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4067 - loss: 1.9404 - val_accuracy: 0.4186 - val_loss: 1.8942\n",
      "Epoch 154/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4077 - loss: 1.9343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:48.500133: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:48.500220: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:48.500273: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 154: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_154_val_loss_1.8937.keras\n",
      "\n",
      "Epoch 154: val_loss improved from 1.89420 to 1.89369, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:48.794654: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:48.794698: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:48.794721: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4073 - loss: 1.9365 - val_accuracy: 0.4190 - val_loss: 1.8937\n",
      "Epoch 155/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4073 - loss: 1.9385\n",
      "Epoch 155: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_155_val_loss_1.8904.keras\n",
      "\n",
      "Epoch 155: val_loss improved from 1.89369 to 1.89044, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:55.016667: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:55.016746: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:55.016796: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4077 - loss: 1.9371 - val_accuracy: 0.4195 - val_loss: 1.8904\n",
      "Epoch 156/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4050 - loss: 1.9447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:55.363548: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:55.363604: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:55.363632: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 156: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_156_val_loss_1.8901.keras\n",
      "\n",
      "Epoch 156: val_loss improved from 1.89044 to 1.89011, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:55:55.656425: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:55:55.656467: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:55:55.656489: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4055 - loss: 1.9417 - val_accuracy: 0.4196 - val_loss: 1.8901\n",
      "Epoch 157/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4084 - loss: 1.9343\n",
      "Epoch 157: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_157_val_loss_1.8889.keras\n",
      "\n",
      "Epoch 157: val_loss improved from 1.89011 to 1.88889, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:02.273915: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:02.273976: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:02.274017: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4085 - loss: 1.9338 - val_accuracy: 0.4203 - val_loss: 1.8889\n",
      "Epoch 158/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.4120 - loss: 1.9189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:02.667781: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 158: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_158_val_loss_1.8863.keras\n",
      "\n",
      "Epoch 158: val_loss improved from 1.88889 to 1.88628, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:02.939702: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:02.939767: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:02.939811: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4087 - loss: 1.9324 - val_accuracy: 0.4201 - val_loss: 1.8863\n",
      "Epoch 159/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4094 - loss: 1.9307\n",
      "Epoch 159: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_159_val_loss_1.8838.keras\n",
      "\n",
      "Epoch 159: val_loss improved from 1.88628 to 1.88378, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:09.048154: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:09.048196: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:09.048220: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4094 - loss: 1.9304 - val_accuracy: 0.4202 - val_loss: 1.8838\n",
      "Epoch 160/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4058 - loss: 1.9365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:09.376884: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:09.376927: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:09.376952: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_160_val_loss_1.8816.keras\n",
      "\n",
      "Epoch 160: val_loss improved from 1.88378 to 1.88160, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:09.655109: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:09.655148: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:09.655171: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4074 - loss: 1.9322 - val_accuracy: 0.4223 - val_loss: 1.8816\n",
      "Epoch 161/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4099 - loss: 1.9272\n",
      "Epoch 161: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_161_val_loss_1.8805.keras\n",
      "\n",
      "Epoch 161: val_loss improved from 1.88160 to 1.88047, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:15.147803: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:15.147843: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:15.147865: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4102 - loss: 1.9269 - val_accuracy: 0.4218 - val_loss: 1.8805\n",
      "Epoch 162/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4108 - loss: 1.9398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:15.409690: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:15.409728: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:15.409752: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 162: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_162_val_loss_1.8799.keras\n",
      "\n",
      "Epoch 162: val_loss improved from 1.88047 to 1.87995, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:15.675836: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:15.675877: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:15.675900: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4112 - loss: 1.9196 - val_accuracy: 0.4223 - val_loss: 1.8799\n",
      "Epoch 163/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4108 - loss: 1.9251\n",
      "Epoch 163: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_163_val_loss_1.8752.keras\n",
      "\n",
      "Epoch 163: val_loss improved from 1.87995 to 1.87518, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:21.125815: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:21.125887: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:21.125933: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4110 - loss: 1.9233 - val_accuracy: 0.4240 - val_loss: 1.8752\n",
      "Epoch 164/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4143 - loss: 1.9157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:21.418128: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 164: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_164_val_loss_1.8750.keras\n",
      "\n",
      "Epoch 164: val_loss improved from 1.87518 to 1.87495, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:21.701544: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:21.701583: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:21.701605: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4157 - loss: 1.9120 - val_accuracy: 0.4230 - val_loss: 1.8750\n",
      "Epoch 165/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4120 - loss: 1.9199\n",
      "Epoch 165: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_165_val_loss_1.8718.keras\n",
      "\n",
      "Epoch 165: val_loss improved from 1.87495 to 1.87184, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:27.321196: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:27.321231: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:27.321254: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4118 - loss: 1.9210 - val_accuracy: 0.4241 - val_loss: 1.8718\n",
      "Epoch 166/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4177 - loss: 1.8994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:27.609863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:27.609923: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:27.609959: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 166: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_166_val_loss_1.8708.keras\n",
      "\n",
      "Epoch 166: val_loss improved from 1.87184 to 1.87083, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:27.890143: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:27.890183: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:27.890205: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4141 - loss: 1.9109 - val_accuracy: 0.4244 - val_loss: 1.8708\n",
      "Epoch 167/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4120 - loss: 1.9180\n",
      "Epoch 167: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_167_val_loss_1.8694.keras\n",
      "\n",
      "Epoch 167: val_loss improved from 1.87083 to 1.86935, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:33.736165: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:33.736203: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:33.736225: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4122 - loss: 1.9178 - val_accuracy: 0.4254 - val_loss: 1.8694\n",
      "Epoch 168/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4139 - loss: 1.9142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:34.037692: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 168: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_168_val_loss_1.8686.keras\n",
      "\n",
      "Epoch 168: val_loss improved from 1.86935 to 1.86861, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:34.260958: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:34.260997: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:34.261018: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4105 - loss: 1.9268 - val_accuracy: 0.4260 - val_loss: 1.8686\n",
      "Epoch 169/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4127 - loss: 1.9161\n",
      "Epoch 169: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_169_val_loss_1.8648.keras\n",
      "\n",
      "Epoch 169: val_loss improved from 1.86861 to 1.86478, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:38.633892: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:38.633937: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:38.633961: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4130 - loss: 1.9153 - val_accuracy: 0.4265 - val_loss: 1.8648\n",
      "Epoch 170/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4156 - loss: 1.9245\n",
      "Epoch 170: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_170_val_loss_1.8649.keras\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.86478\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.4128 - loss: 1.9205 - val_accuracy: 0.4264 - val_loss: 1.8649\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:39.149910: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4135 - loss: 1.9129\n",
      "Epoch 171: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_171_val_loss_1.8623.keras\n",
      "\n",
      "Epoch 171: val_loss improved from 1.86478 to 1.86228, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:44.315676: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:44.315715: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:44.315737: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4137 - loss: 1.9126 - val_accuracy: 0.4268 - val_loss: 1.8623\n",
      "Epoch 172/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4198 - loss: 1.8981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:44.629398: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:44.629444: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:44.629472: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 172: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_172_val_loss_1.8618.keras\n",
      "\n",
      "Epoch 172: val_loss improved from 1.86228 to 1.86181, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:44.885579: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:44.885628: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:44.885649: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4112 - loss: 1.9170 - val_accuracy: 0.4270 - val_loss: 1.8618\n",
      "Epoch 173/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4141 - loss: 1.9105\n",
      "Epoch 173: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_173_val_loss_1.8599.keras\n",
      "\n",
      "Epoch 173: val_loss improved from 1.86181 to 1.85993, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:50.140054: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:50.140108: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4144 - loss: 1.9100 - val_accuracy: 0.4274 - val_loss: 1.8599\n",
      "Epoch 174/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4154 - loss: 1.9079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:50.408689: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:50.408745: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:50.408781: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 174: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_174_val_loss_1.8619.keras\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.85993\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4126 - loss: 1.9158 - val_accuracy: 0.4271 - val_loss: 1.8619\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:50.676701: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:50.676739: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:56:50.676761: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4147 - loss: 1.9082\n",
      "Epoch 175: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_175_val_loss_1.8589.keras\n",
      "\n",
      "Epoch 175: val_loss improved from 1.85993 to 1.85886, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:56.393560: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:56.393608: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4147 - loss: 1.9077 - val_accuracy: 0.4280 - val_loss: 1.8589\n",
      "Epoch 176/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4167 - loss: 1.8985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:56.696312: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 176: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_176_val_loss_1.8583.keras\n",
      "\n",
      "Epoch 176: val_loss improved from 1.85886 to 1.85831, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:56:56.929134: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:56:56.929201: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4169 - loss: 1.8994 - val_accuracy: 0.4283 - val_loss: 1.8583\n",
      "Epoch 177/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4153 - loss: 1.9063\n",
      "Epoch 177: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_177_val_loss_1.8554.keras\n",
      "\n",
      "Epoch 177: val_loss improved from 1.85831 to 1.85538, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:02.419331: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:02.419366: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:02.419388: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4154 - loss: 1.9058 - val_accuracy: 0.4297 - val_loss: 1.8554\n",
      "Epoch 178/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4140 - loss: 1.9078\n",
      "Epoch 178: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_178_val_loss_1.8548.keras\n",
      "\n",
      "Epoch 178: val_loss improved from 1.85538 to 1.85477, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:02.956086: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:02.956129: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:02.956153: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4132 - loss: 1.9111 - val_accuracy: 0.4287 - val_loss: 1.8548\n",
      "Epoch 179/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4156 - loss: 1.9047\n",
      "Epoch 179: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_179_val_loss_1.8520.keras\n",
      "\n",
      "Epoch 179: val_loss improved from 1.85477 to 1.85200, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:08.350310: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:08.350351: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:08.350375: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4158 - loss: 1.9033 - val_accuracy: 0.4297 - val_loss: 1.8520\n",
      "Epoch 180/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4169 - loss: 1.9026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:08.637026: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:08.637073: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:08.637102: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_180_val_loss_1.8528.keras\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.85200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.4176 - loss: 1.8978 - val_accuracy: 0.4296 - val_loss: 1.8528\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:08.845878: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:08.845917: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:08.845939: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m470/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4162 - loss: 1.9018\n",
      "Epoch 181: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_181_val_loss_1.8506.keras\n",
      "\n",
      "Epoch 181: val_loss improved from 1.85200 to 1.85058, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:13.304620: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:13.304659: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:13.304680: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4165 - loss: 1.9014 - val_accuracy: 0.4300 - val_loss: 1.8506\n",
      "Epoch 182/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4124 - loss: 1.9231\n",
      "Epoch 182: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_182_val_loss_1.8497.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:13.599987: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:13.600028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:13.600052: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:57:13.790931: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:13.790970: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:13.790993: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 182: val_loss improved from 1.85058 to 1.84974, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.4144 - loss: 1.9079 - val_accuracy: 0.4298 - val_loss: 1.8497\n",
      "Epoch 183/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4170 - loss: 1.9006\n",
      "Epoch 183: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_183_val_loss_1.8495.keras\n",
      "\n",
      "Epoch 183: val_loss improved from 1.84974 to 1.84955, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:17.986921: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:17.986966: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:17.986987: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4168 - loss: 1.8999 - val_accuracy: 0.4301 - val_loss: 1.8495\n",
      "Epoch 184/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4253 - loss: 1.8691\n",
      "Epoch 184: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_184_val_loss_1.8478.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:18.275812: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:18.275865: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:18.275890: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:57:18.467609: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:18.467645: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:18.467667: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 184: val_loss improved from 1.84955 to 1.84780, saving model to best_model.keras\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.4216 - loss: 1.8830 - val_accuracy: 0.4303 - val_loss: 1.8478\n",
      "Epoch 185/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4169 - loss: 1.8990\n",
      "Epoch 185: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_185_val_loss_1.8492.keras\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.84780\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4172 - loss: 1.8981 - val_accuracy: 0.4301 - val_loss: 1.8492\n",
      "Epoch 186/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4208 - loss: 1.8846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:24.148148: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:24.148188: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:24.148211: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4210 - loss: 1.8877 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:24.390535: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:24.390577: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:24.390600: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 186: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_186_val_loss_1.8471.keras\n",
      "\n",
      "Epoch 186: val_loss improved from 1.84780 to 1.84708, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:24.657801: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:24.657840: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:24.657863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4204 - loss: 1.8883 - val_accuracy: 0.4303 - val_loss: 1.8471\n",
      "Epoch 187/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4177 - loss: 1.8968\n",
      "Epoch 187: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_187_val_loss_1.8442.keras\n",
      "\n",
      "Epoch 187: val_loss improved from 1.84708 to 1.84422, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:30.244436: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:30.244485: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:30.244506: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4176 - loss: 1.8970 - val_accuracy: 0.4313 - val_loss: 1.8442\n",
      "Epoch 188/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4037 - loss: 1.9358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:30.562892: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 188: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_188_val_loss_1.8447.keras\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.84422\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.4180 - loss: 1.8938 - val_accuracy: 0.4313 - val_loss: 1.8447\n",
      "Epoch 189/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:30.803937: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:30.803977: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:30.803998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4183 - loss: 1.8938\n",
      "Epoch 189: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_189_val_loss_1.8443.keras\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.84422\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4179 - loss: 1.8951 - val_accuracy: 0.4318 - val_loss: 1.8443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:36.364936: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:36.364998: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4156 - loss: 1.8964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:36.636972: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:36.637011: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:36.637035: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 190: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_190_val_loss_1.8432.keras\n",
      "\n",
      "Epoch 190: val_loss improved from 1.84422 to 1.84322, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:36.849400: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:36.849441: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:36.849463: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4177 - loss: 1.8934 - val_accuracy: 0.4315 - val_loss: 1.8432\n",
      "Epoch 191/1000\n",
      "\u001b[1m475/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4181 - loss: 1.8959\n",
      "Epoch 191: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_191_val_loss_1.8425.keras\n",
      "\n",
      "Epoch 191: val_loss improved from 1.84322 to 1.84254, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:43.825490: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:57:43.825578: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4184 - loss: 1.8938 - val_accuracy: 0.4322 - val_loss: 1.8425\n",
      "Epoch 192/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4170 - loss: 1.8960\n",
      "Epoch 192: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_192_val_loss_1.8410.keras\n",
      "\n",
      "Epoch 192: val_loss improved from 1.84254 to 1.84103, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:44.471311: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:44.471403: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:44.471451: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4165 - loss: 1.8923 - val_accuracy: 0.4325 - val_loss: 1.8410\n",
      "Epoch 193/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4180 - loss: 1.8934\n",
      "Epoch 193: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_193_val_loss_1.8414.keras\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.84103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:50.441269: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:50.441328: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4186 - loss: 1.8929 - val_accuracy: 0.4316 - val_loss: 1.8414\n",
      "Epoch 194/1000\n",
      "\u001b[1m  6/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4184 - loss: 1.8811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:50.796991: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 194: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_194_val_loss_1.8405.keras\n",
      "\n",
      "Epoch 194: val_loss improved from 1.84103 to 1.84047, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:51.117372: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:51.117425: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:51.117456: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4196 - loss: 1.8818 - val_accuracy: 0.4318 - val_loss: 1.8405\n",
      "Epoch 195/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4192 - loss: 1.8908\n",
      "Epoch 195: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_195_val_loss_1.8401.keras\n",
      "\n",
      "Epoch 195: val_loss improved from 1.84047 to 1.84012, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:57.715096: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:57.715161: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:57.715195: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.4190 - loss: 1.8908 - val_accuracy: 0.4323 - val_loss: 1.8401\n",
      "Epoch 196/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4161 - loss: 1.8981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:58.100941: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:58.101016: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:58.101069: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 196: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_196_val_loss_1.8401.keras\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.84012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:57:58.419448: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:57:58.419532: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:57:58.419586: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4189 - loss: 1.8874 - val_accuracy: 0.4326 - val_loss: 1.8401\n",
      "Epoch 197/1000\n",
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4192 - loss: 1.8912\n",
      "Epoch 197: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_197_val_loss_1.8386.keras\n",
      "\n",
      "Epoch 197: val_loss improved from 1.84012 to 1.83861, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:05.104183: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:05.104223: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:05.104245: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4194 - loss: 1.8901 - val_accuracy: 0.4330 - val_loss: 1.8386\n",
      "Epoch 198/1000\n",
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4161 - loss: 1.8993\n",
      "Epoch 198: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_198_val_loss_1.8397.keras\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.83861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:05.737384: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:05.737468: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:05.737535: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4178 - loss: 1.8937 - val_accuracy: 0.4328 - val_loss: 1.8397\n",
      "Epoch 199/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4195 - loss: 1.8890\n",
      "Epoch 199: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_199_val_loss_1.8371.keras\n",
      "\n",
      "Epoch 199: val_loss improved from 1.83861 to 1.83715, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:12.003472: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:12.003537: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:12.003576: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4196 - loss: 1.8894 - val_accuracy: 0.4332 - val_loss: 1.8371\n",
      "Epoch 200/1000\n",
      "\u001b[1m  5/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4202 - loss: 1.8936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:12.362553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:12.362638: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:12.362684: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_200_val_loss_1.8368.keras\n",
      "\n",
      "Epoch 200: val_loss improved from 1.83715 to 1.83679, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:12.620317: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:12.620355: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:12.620376: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4169 - loss: 1.8961 - val_accuracy: 0.4331 - val_loss: 1.8368\n",
      "Epoch 201/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4200 - loss: 1.8883\n",
      "Epoch 201: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_201_val_loss_1.8362.keras\n",
      "\n",
      "Epoch 201: val_loss improved from 1.83679 to 1.83625, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:18.448857: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:18.448908: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4196 - loss: 1.8884 - val_accuracy: 0.4336 - val_loss: 1.8362\n",
      "Epoch 202/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4263 - loss: 1.8937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:18.765170: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:18.765210: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:18.765233: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 202: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_202_val_loss_1.8362.keras\n",
      "\n",
      "Epoch 202: val_loss improved from 1.83625 to 1.83619, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:18.987689: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:18.987747: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:18.987759: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4187 - loss: 1.8917 - val_accuracy: 0.4333 - val_loss: 1.8362\n",
      "Epoch 203/1000\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4196 - loss: 1.8894\n",
      "Epoch 203: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_203_val_loss_1.8361.keras\n",
      "\n",
      "Epoch 203: val_loss improved from 1.83619 to 1.83613, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:24.971824: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:24.971863: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:24.971885: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4199 - loss: 1.8878 - val_accuracy: 0.4337 - val_loss: 1.8361\n",
      "Epoch 204/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4226 - loss: 1.8899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:25.254080: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 204: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_204_val_loss_1.8354.keras\n",
      "\n",
      "Epoch 204: val_loss improved from 1.83613 to 1.83538, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:25.472925: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:25.472968: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:25.472992: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4196 - loss: 1.8874 - val_accuracy: 0.4337 - val_loss: 1.8354\n",
      "Epoch 205/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4199 - loss: 1.8867\n",
      "Epoch 205: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_205_val_loss_1.8355.keras\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.83538\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4199 - loss: 1.8871 - val_accuracy: 0.4334 - val_loss: 1.8355\n",
      "Epoch 206/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4163 - loss: 1.9176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:30.031874: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:30.031914: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:30.031937: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:30.252211: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:30.252253: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:30.252278: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 206: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_206_val_loss_1.8340.keras\n",
      "\n",
      "Epoch 206: val_loss improved from 1.83538 to 1.83396, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:30.453344: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:30.453380: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:30.453400: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4223 - loss: 1.8877 - val_accuracy: 0.4339 - val_loss: 1.8340\n",
      "Epoch 207/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4207 - loss: 1.8861\n",
      "Epoch 207: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_207_val_loss_1.8341.keras\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.83396\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4203 - loss: 1.8866 - val_accuracy: 0.4338 - val_loss: 1.8341\n",
      "Epoch 208/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4192 - loss: 1.8805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:34.287092: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:34.287129: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:34.287151: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:34.510491: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:34.510535: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:34.510558: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 208: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_208_val_loss_1.8354.keras\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.83396\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.4174 - loss: 1.8854 - val_accuracy: 0.4336 - val_loss: 1.8354\n",
      "Epoch 209/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:34.722622: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:34.722661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:34.722683: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4200 - loss: 1.8858\n",
      "Epoch 209: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_209_val_loss_1.8349.keras\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.83396\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4203 - loss: 1.8859 - val_accuracy: 0.4334 - val_loss: 1.8349\n",
      "Epoch 210/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4244 - loss: 1.8902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:38.925517: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:38.925571: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:39.150548: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 210: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_210_val_loss_1.8338.keras\n",
      "\n",
      "Epoch 210: val_loss improved from 1.83396 to 1.83377, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:39.360553: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:39.360593: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:39.360615: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4197 - loss: 1.8925 - val_accuracy: 0.4339 - val_loss: 1.8338\n",
      "Epoch 211/1000\n",
      "\u001b[1m470/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4200 - loss: 1.8866\n",
      "Epoch 211: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_211_val_loss_1.8336.keras\n",
      "\n",
      "Epoch 211: val_loss improved from 1.83377 to 1.83361, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:43.945601: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:43.945639: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:43.945661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4204 - loss: 1.8857 - val_accuracy: 0.4339 - val_loss: 1.8336\n",
      "Epoch 212/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4202 - loss: 1.9039\n",
      "Epoch 212: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_212_val_loss_1.8336.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:44.228004: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:44.228044: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:44.228066: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:44.423691: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:44.423732: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:44.423754: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 212: val_loss did not improve from 1.83361\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.4225 - loss: 1.8797 - val_accuracy: 0.4339 - val_loss: 1.8336\n",
      "Epoch 213/1000\n",
      "\u001b[1m473/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4208 - loss: 1.8856\n",
      "Epoch 213: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_213_val_loss_1.8320.keras\n",
      "\n",
      "Epoch 213: val_loss improved from 1.83361 to 1.83200, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:48.166123: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4208 - loss: 1.8850 - val_accuracy: 0.4343 - val_loss: 1.8320\n",
      "Epoch 214/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4147 - loss: 1.8967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:48.431437: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 214: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_214_val_loss_1.8328.keras\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.4211 - loss: 1.8802 - val_accuracy: 0.4345 - val_loss: 1.8328\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:48.664912: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:48.664950: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:48.664973: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4205 - loss: 1.8848\n",
      "Epoch 215: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_215_val_loss_1.8340.keras\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4207 - loss: 1.8846 - val_accuracy: 0.4339 - val_loss: 1.8340\n",
      "Epoch 216/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4175 - loss: 1.8922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:53.012326: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:53.012364: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:53.012386: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:58:53.224264: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:53.224304: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:53.224328: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 216: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_216_val_loss_1.8330.keras\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.4218 - loss: 1.8846 - val_accuracy: 0.4342 - val_loss: 1.8330\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:53.450131: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:53.450168: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:53.450191: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4212 - loss: 1.8847\n",
      "Epoch 217: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_217_val_loss_1.8325.keras\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4211 - loss: 1.8842 - val_accuracy: 0.4342 - val_loss: 1.8325\n",
      "Epoch 218/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4078 - loss: 1.9121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:57.357876: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:57.357917: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:57.357942: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 218: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_218_val_loss_1.8327.keras\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.4191 - loss: 1.8862 - val_accuracy: 0.4339 - val_loss: 1.8327\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:58:57.775433: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:58:57.775469: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:58:57.775490: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4210 - loss: 1.8843\n",
      "Epoch 219: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_219_val_loss_1.8328.keras\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4208 - loss: 1.8844 - val_accuracy: 0.4339 - val_loss: 1.8328\n",
      "Epoch 220/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4122 - loss: 1.9098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:03.588362: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-08-30 05:59:03.588404: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:03.588411: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:03.588432: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4209 - loss: 1.8903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:03.814316: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:03.814410: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 220: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_220_val_loss_1.8326.keras\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4236 - loss: 1.8803 - val_accuracy: 0.4341 - val_loss: 1.8326\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:04.123593: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:04.123635: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:04.123661: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4207 - loss: 1.8845\n",
      "Epoch 221: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_221_val_loss_1.8323.keras\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4210 - loss: 1.8841 - val_accuracy: 0.4341 - val_loss: 1.8323\n",
      "Epoch 222/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4183 - loss: 1.8761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:09.041899: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:09.041940: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:09.041963: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 222: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_222_val_loss_1.8331.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:09.255621: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:09.255667: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:09.255697: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:09.450973: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:09.451012: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:09.451035: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 222: val_loss did not improve from 1.83200\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.4218 - loss: 1.8741 - val_accuracy: 0.4336 - val_loss: 1.8331\n",
      "Epoch 223/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4212 - loss: 1.8828\n",
      "Epoch 223: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_223_val_loss_1.8313.keras\n",
      "\n",
      "Epoch 223: val_loss improved from 1.83200 to 1.83129, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:13.937850: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:13.937888: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:13.937911: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4208 - loss: 1.8840 - val_accuracy: 0.4345 - val_loss: 1.8313\n",
      "Epoch 224/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4379 - loss: 1.8542\n",
      "Epoch 224: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_224_val_loss_1.8324.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:14.194228: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:14.387029: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:14.387068: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:14.387089: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 224: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.4235 - loss: 1.8803 - val_accuracy: 0.4340 - val_loss: 1.8324\n",
      "Epoch 225/1000\n",
      "\u001b[1m474/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4212 - loss: 1.8825\n",
      "Epoch 225: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_225_val_loss_1.8321.keras\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4210 - loss: 1.8840 - val_accuracy: 0.4339 - val_loss: 1.8321\n",
      "Epoch 226/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4207 - loss: 1.8796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:20.112736: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:20.112778: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:20.112800: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 226: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_226_val_loss_1.8315.keras\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.4221 - loss: 1.8769 - val_accuracy: 0.4348 - val_loss: 1.8315\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:20.564988: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:20.565028: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:20.565051: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4211 - loss: 1.8832\n",
      "Epoch 227: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_227_val_loss_1.8314.keras\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4210 - loss: 1.8839 - val_accuracy: 0.4343 - val_loss: 1.8314\n",
      "Epoch 228/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4264 - loss: 1.8770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:26.196775: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:26.196816: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:26.196837: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:26.408379: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:26.408424: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:26.408448: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 228: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_228_val_loss_1.8326.keras\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.4208 - loss: 1.8815 - val_accuracy: 0.4345 - val_loss: 1.8326\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:26.643549: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:26.643589: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:26.643612: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4209 - loss: 1.8847\n",
      "Epoch 229: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_229_val_loss_1.8323.keras\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4210 - loss: 1.8831 - val_accuracy: 0.4339 - val_loss: 1.8323\n",
      "Epoch 230/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4213 - loss: 1.8930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:32.535014: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4215 - loss: 1.8924\n",
      "Epoch 230: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_230_val_loss_1.8325.keras\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4205 - loss: 1.8958 - val_accuracy: 0.4343 - val_loss: 1.8325\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:33.029431: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:33.029472: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:33.029494: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4210 - loss: 1.8838\n",
      "Epoch 231: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_231_val_loss_1.8331.keras\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4211 - loss: 1.8834 - val_accuracy: 0.4339 - val_loss: 1.8331\n",
      "Epoch 232/1000\n",
      "\u001b[1m  1/477\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4307 - loss: 1.8457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:37.746615: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:37.746655: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:37.746677: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n",
      "2025-08-30 05:59:37.964604: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 232: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_232_val_loss_1.8322.keras\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.83129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:38.251228: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:38.251307: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:38.251354: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4238 - loss: 1.8775 - val_accuracy: 0.4341 - val_loss: 1.8322\n",
      "Epoch 233/1000\n",
      "\u001b[1m476/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4210 - loss: 1.8840\n",
      "Epoch 233: saving model to /home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_233_val_loss_1.8321.keras\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.83129\n",
      "\u001b[1m477/477\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4211 - loss: 1.8837 - val_accuracy: 0.4345 - val_loss: 1.8321\n",
      "Epoch 233: early stopping\n",
      "Restoring model weights from the end of the best epoch: 223.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 05:59:45.027896: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12784347005969143345\n",
      "2025-08-30 05:59:45.027970: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11096966766647997284\n",
      "2025-08-30 05:59:45.028045: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 15582442386654234270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "Best validation loss: 1.8313\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAHqCAYAAADrpwd3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAwD5JREFUeJzs3Xd8U/X+x/F3km462C2jUGTvKVBQQEARFFFQEdACAi5AxsWLvQ5ARfCqiMpSZIiCcFWGCgjIj6KyZYmKKMgoo2XZlha6kvz+aBuotFBoktPxej4eeWhOTk4+yeV6OO988vma7Ha7XQAAAAAAAAAA4CpmowsAAAAAAAAAAKCgIkQHAAAAAAAAACAXhOgAAAAAAAAAAOSCEB0AAAAAAAAAgFwQogMAAAAAAAAAkAtCdAAAAAAAAAAAckGIDgAAAAAAAABALgjRAQAAAAAAAADIBSE6AAAAAAAAAAC5IEQHIEkymUwaP378DT/vyJEjMplMmj9/vtNrAgAAAAAAUlRUlEwmk6Kiolz2Gh06dFCHDh1cdnygMCNEBwqQ+fPny2QyyWQy6ccff7zqcbvdrtDQUJlMJt17770GVHjzsk74X3zxhdGlAAAAAABwTVden5tMJvn4+KhWrVoaNmyYYmNjjS7PLU6ePKnx48drz549RpcCGM7D6AIAXM3Hx0eLFi3Sbbfdlm37xo0bdfz4cXl7extUGQAAAAAAxccrr7yiatWqKTk5WT/++KNmzpypVatW6ZdffpGfn5/R5TnV2rVrs90/efKkJkyYoLCwMDVp0sSYooACgk50oADq1q2bPv/8c6Wnp2fbvmjRIjVv3lwhISEGVQYAAAAAQPHRtWtXPfrooxo8eLDmz5+vkSNH6vDhw1qxYkW+jnvx4kUnVeg8Xl5e8vLyMroMoEAiRAcKoD59+ujcuXNat26dY1tqaqq++OIL9e3bN8fnJCUl6V//+pdCQ0Pl7e2t2rVr66233pLdbs+2X0pKikaNGqVy5copICBA9913n44fP57jMU+cOKHHH39cwcHB8vb2Vv369TV37lznvdEc/PXXX3rooYdUunRp+fn5qXXr1lq5cuVV+73//vuqX7++/Pz8VKpUKbVo0UKLFi1yPH7hwgWNHDlSYWFh8vb2Vvny5XXnnXdq165dLq0fAAAAAFB0dezYUZJ0+PBhSdKnn36q5s2by9fXV6VLl9Yjjzyi6OjobM/p0KGDGjRooJ07d6pdu3by8/PTf/7zH0lSWFiY7r33Xq1du1ZNmjSRj4+P6tWrp6VLl+apnm3btunuu+9WUFCQ/Pz81L59e23atMnx+P79++Xr66uIiIhsz/vxxx9lsVg0duzYbHVmzUSPiorSrbfeKkkaOHCgY6zN/PnzNW7cOHl6eurMmTNX1fPEE0+oZMmSSk5OzlP9QGFBiA4UQGFhYQoPD9dnn33m2LZ69WrFx8frkUceuWp/u92u++67T++8847uvvtuTZkyRbVr19Zzzz2n0aNHZ9t38ODBmjp1qu666y5NnjxZnp6euueee646ZmxsrFq3bq3vvvtOw4YN07vvvqsaNWpo0KBBmjp1qtPfc9ZrtmnTRmvWrNEzzzyjiRMnKjk5Wffdd5+WLVvm2G/27Nl69tlnVa9ePU2dOlUTJkxQkyZNtG3bNsc+Tz31lGbOnKlevXppxowZGjNmjHx9fbV//36X1A4AAAAAKPoOHTokSSpTpowmTpyoiIgI1axZU1OmTNHIkSO1fv16tWvXTnFxcdmed+7cOXXt2lVNmjTR1KlTdccddzge+/PPP9W7d2917dpVkyZNkoeHhx566KFsjXU5+b//+z+1a9dOCQkJGjdunF5//XXFxcWpY8eO2r59uySpbt26evXVV/XJJ5/oq6++kpTRhDdgwADVqVNHr7zySo7Hrlu3ruOxJ554Qp988ok++eQTtWvXTo899pjS09O1ZMmSbM/Jav7r1auXfHx88v6hAoWBHUCBMW/ePLsk+44dO+zTpk2zBwQE2C9evGi32+32hx56yH7HHXfY7Xa7vWrVqvZ77rnH8bzly5fbJdlfe+21bMd78MEH7SaTyX7w4EG73W6379mzxy7J/swzz2Tbr2/fvnZJ9nHjxjm2DRo0yF6hQgX72bNns+37yCOP2IOCghx1HT582C7JPm/evGu+tw0bNtgl2T///PNc9xk5cqRdkv2HH35wbLtw4YK9WrVq9rCwMLvVarXb7XZ7jx497PXr17/m6wUFBdmHDh16zX0AAAAAAMhJ1vX5d999Zz9z5ow9OjravnjxYnuZMmXsvr6+9iNHjtgtFot94sSJ2Z63b98+u4eHR7bt7du3t0uyz5o166rXqVq1ql2S/csvv3Rsi4+Pt1eoUMHetGlTx7asa+oNGzbY7Xa73Waz2WvWrGnv0qWL3WazOfa7ePGivVq1avY777zTsc1qtdpvu+02e3BwsP3s2bP2oUOH2j08POw7duzIVkv79u3t7du3d9zfsWNHrtf74eHh9latWmXbtnTp0mw1AkUJnehAAfXwww/r0qVL+uabb3ThwgV98803uY5yWbVqlSwWi5599tls2//1r3/Jbrdr9erVjv0kXbXfyJEjs9232+368ssv1b17d9ntdp09e9Zx69Kli+Lj410yFmXVqlVq2bJltgVV/f399cQTT+jIkSP67bffJEklS5bU8ePHtWPHjlyPVbJkSW3btk0nT550ep0AAAAAgOKhc+fOKleunEJDQ/XII4/I399fy5Yt09KlS2Wz2fTwww9nu2YOCQlRzZo1tWHDhmzH8fb21sCBA3N8jYoVK+qBBx5w3A8MDFRERIR2796tmJiYHJ+zZ88e/fnnn+rbt6/OnTvneP2kpCR16tRJ33//vWw2myTJbDZr/vz5SkxMVNeuXTVjxgxFRkaqRYsWN/25REREaNu2bY7OfElauHChQkND1b59+5s+LlBQeRhdAICclStXTp07d9aiRYt08eJFWa1WPfjggznue/ToUVWsWFEBAQHZttetW9fxeNY/zWazqlevnm2/2rVrZ7t/5swZxcXF6cMPP9SHH36Y42uePn36pt7XtRw9elStWrW6avuV76NBgwYaO3asvvvuO7Vs2VI1atTQXXfdpb59+6pt27aO5/z3v/9V//79FRoaqubNm6tbt26KiIjQLbfc4vS6AQAAAABF0/Tp01WrVi15eHgoODhYtWvXltls1ooVK2S321WzZs0cn+fp6ZntfqVKlXJdtLNGjRoymUzZttWqVUuSdOTIEYWEhFz1nD///FOS1L9//1xrj4+PV6lSpSRJ1atX1/jx4/Xcc8+pQYMGeumll3J9Xl707t1bI0eO1MKFC/Xyyy8rPj5e33zzjUaNGnXVewGKAkJ0oADr27evhgwZopiYGHXt2lUlS5Z0y+tmfVv96KOP5npCbtSokVtqyUndunV14MABffPNN/r222/15ZdfasaMGXr55Zc1YcIESRmd/LfffruWLVumtWvX6s0339Qbb7yhpUuXqmvXrobVDgAAAAAoPFq2bJljx7bNZpPJZNLq1atlsViuetzf3z/bfV9fX6fWlXXd/uabb6pJkyY57vPPGtauXStJOnnypM6dO5djOJ9XpUqV0r333usI0b/44gulpKTo0UcfveljAgUZITpQgD3wwAN68skntXXr1qsW7LhS1apV9d133+nChQvZutF///13x+NZ/7TZbDp06FC27vMDBw5kO165cuUUEBAgq9Wqzp07O/MtXVPVqlWvqkW6+n1IUokSJdS7d2/17t1bqamp6tmzpyZOnKjIyEjHAiYVKlTQM888o2eeeUanT59Ws2bNNHHiREJ0AAAAAEC+VK9eXXa7XdWqVXN0jd+sgwcPym63Z+vg/uOPPyRJYWFhub6+lDH6JS/X7bNmzdK6des0ceJETZo0SU8++aRWrFhxzedcr6M8IiJCPXr00I4dO7Rw4UI1bdpU9evXv24tQGHETHSgAPP399fMmTM1fvx4de/ePdf9unXrJqvVqmnTpmXb/s4778hkMjlC46x/vvfee9n2mzp1arb7FotFvXr10pdffqlffvnlqtc7c+bMzbyd6+rWrZu2b9+uLVu2OLYlJSXpww8/VFhYmOrVqycpY1XzK3l5ealevXqy2+1KS0uT1WpVfHx8tn3Kly+vihUrKiUlxSW1AwAAAACKj549e8pisWjChAmy2+3ZHrPb7Vddt17LyZMntWzZMsf9hIQELViwQE2aNMm1W7x58+aqXr263nrrLSUmJl71+JXX7YcPH9Zzzz2nXr166T//+Y/eeustffXVV1qwYME16ypRooQkKS4uLsfHu3btqrJly+qNN97Qxo0b6UJHkUYnOlDAXWu+WZbu3bvrjjvu0AsvvKAjR46ocePGWrt2rVasWKGRI0c6vqFu0qSJ+vTpoxkzZig+Pl5t2rTR+vXrdfDgwauOOXnyZG3YsEGtWrXSkCFDVK9ePZ0/f167du3Sd999p/Pnz9/U+/nyyy8dneX/fJ/PP/+8PvvsM3Xt2lXPPvusSpcurY8//liHDx/Wl19+KbM543u/u+66SyEhIWrbtq2Cg4O1f/9+TZs2Tffcc48CAgIUFxenypUr68EHH1Tjxo3l7++v7777Tjt27NDbb799U3UDAAAAAJClevXqeu211xQZGakjR47o/vvvV0BAgA4fPqxly5bpiSee0JgxY/J0rFq1amnQoEHasWOHgoODNXfuXMXGxmrevHm5PsdsNuujjz5S165dVb9+fQ0cOFCVKlXSiRMntGHDBgUGBurrr7+W3W7X448/Ll9fX82cOVOS9OSTT+rLL7/UiBEj1LlzZ1WsWDHX91iyZEnNmjVLAQEBKlGihFq1aqVq1apJypj7/sgjj2jatGmyWCzq06fPDX6KQOFBiA4UAWazWV999ZVefvllLVmyRPPmzVNYWJjefPNN/etf/8q279y5c1WuXDktXLhQy5cvV8eOHbVy5UqFhoZm2y84OFjbt2/XK6+8oqVLl2rGjBkqU6aM6tevrzfeeOOma128eHGO2zt06KDbbrtNmzdv1tixY/X+++8rOTlZjRo10tdff6177rnHse+TTz6phQsXasqUKUpMTFTlypX17LPP6sUXX5Qk+fn56ZlnntHatWsdK6bXqFFDM2bM0NNPP33TtQMAAAAAkOX5559XrVq19M477zjW5woNDdVdd92l++67L8/HqVmzpt5//30999xzOnDggKpVq6YlS5aoS5cu13xehw4dtGXLFr366quaNm2aEhMTFRISolatWunJJ5+UJL3//vuKiorSl19+qXLlyjmeO2fOHDVo0EBDhgzRypUrczy+p6enPv74Y0VGRuqpp55Senq65s2b5wjRpYyRLtOmTVOnTp1UoUKFPL9noLAx2f/5mxMAAAAAAAAALhcWFqYGDRrom2++MbqUm7J37141adJECxYs0GOPPWZ0OYDLMBMdAAAAAAAAwA2bPXu2/P391bNnT6NLAVyKcS4AAAAAAAAA8uzrr7/Wb7/9pg8//FDDhg1zLEIKFFWE6AAAAAAAAADybPjw4YqNjVW3bt0c8+CBooxxLgAA4IZ9//336t69uypWrCiTyaTly5df9zlRUVFq1qyZvL29VaNGDc2fP9/ldQIAAAAF2ZEjRwrlPPQjR47o0qVLWr58uQICAowuB3A5QnQAAHDDkpKS1LhxY02fPj1P+x8+fFj33HOP7rjjDu3Zs0cjR47U4MGDtWbNGhdXCgAAAABA/pjsdrvd6CIAAEDhZTKZtGzZMt1///257jN27FitXLlSv/zyi2PbI488ori4OH377bduqBIAAAAAgJtT7Gai22w2nTx5UgEBATKZTEaXAwCAJMlut+vChQsKCAhQYGBgkTtHbdmyRZ07d862rUuXLho5cmSuz0lJSVFKSorjvs1m0/nz51WmTJki9/kAAAq3rPN4xYoVZTbzg++ccC0OACiI8noOL3Yh+smTJxUaGmp0GQAA5Co+Pl6BgYFGl+FUMTExCg4OzrYtODhYCQkJunTpknx9fa96zqRJk1ikCABQqERHR6ty5cpGl1EgcS0OACjIrncOLzAh+uTJkxUZGakRI0Zo6tSpue73+eef66WXXtKRI0dUs2ZNvfHGG+rWrVueXydrsYPo6OgiF1AAAAqvhIQEhYaGKjo6moV5MkVGRmr06NGO+/Hx8apSpQrncABAgZN1HuccnjuuxQEABVFez+EFIkTfsWOHPvjgAzVq1Oia+23evFl9+vTRpEmTdO+992rRokW6//77tWvXLjVo0CBPr5X1s7HAwEBO3ACAAqcojnKRpJCQEMXGxmbbFhsbq8DAwBy70CXJ29tb3t7eV23nHA4AKKiK4jncWbgWBwAUZNc7hxs+rC0xMVH9+vXT7NmzVapUqWvu++677+ruu+/Wc889p7p16+rVV19Vs2bNNG3aNDdVCwAAbkZ4eLjWr1+fbdu6desUHh5uUEUAAAAAAOSN4SH60KFDdc8991y12FhOcluUbMuWLbk+JyUlRQkJCdluAAAgfxITE7Vnzx7t2bNHknT48GHt2bNHx44dk5QxiiUiIsKx/1NPPaW//vpL//73v/X7779rxowZ+t///qdRo0YZUT4AAAAAAHlm6DiXxYsXa9euXdqxY0ee9s9tUbKYmJhcn8OiZAAAON9PP/2kO+64w3E/a3Z5//79NX/+fJ06dcoRqEtStWrVtHLlSo0aNUrvvvuuKleurI8++khdunRxe+0AAAAAANwIw0L06OhojRgxQuvWrZOPj4/LXuefi5JlDYsHgGuxWq1KS0szugwUMZ6enrJYLEaX4RQdOnSQ3W7P9fH58+fn+Jzdu3e7sCoAAAAAhQnX3nA1Z12HGxai79y5U6dPn1azZs0c26xWq77//ntNmzZNKSkpV73B3BYlCwkJyfV1cluUDAByYrfbFRMTo7i4OKNLQRFVsmRJhYSEsPAYAAAAgGKLa2+4kzOuww0L0Tt16qR9+/Zl2zZw4EDVqVNHY8eOzfEbgqxFyUaOHOnYxqJkAJwp6yRevnx5+fn5EXTCaex2uy5evKjTp09LkipUqGBwRQAAAABgDK694Q7OvA43LEQPCAhQgwYNsm0rUaKEypQp49geERGhSpUqadKkSZKkESNGqH379nr77bd1zz33aPHixfrpp5/04Ycfur1+AEWP1Wp1nMTLlCljdDkognx9fSVJp0+fVvny5YvMaBcAAAAAyCuuveFOzroONzuzKGc7duyYTp065bjfpk0bLVq0SB9++KEaN26sL774QsuXL78qjAeAm5E1h83Pz8/gSlCUZf35Yu4fAAAAgOKIa2+4mzOuww3rRM9JVFTUNe9L0kMPPaSHHnrIPQUBKJb4GRlciT9fAAAAAMC1EdzHGX/WCnQnOgAAAAAAAAAARiJEBwBcJSwsTFOnTs3z/lFRUTKZTKysDgAAAADADbjR6++Cxtn1jx8/Xk2aNHHa8ZyFEB0ACjGTyXTN2/jx42/quDt27NATTzyR5/3btGmjU6dOKSgo6KZeL68I6wEAAAAARigo19856dChg6MOHx8f1atXTzNmzMjXMY0yZswYrV+/3nF/wIABuv/++40rKFOBmokOALgxVy6+vGTJEr388ss6cOCAY5u/v7/j3+12u6xWqzw8rv+f/nLlyt1QHV5eXgoJCbmh5wAAAAAAUFgUlOvv3AwZMkSvvPKKLl68qAULFmjo0KEqVaqU+vTpc8PHSk1NlZeXl1PqulH+/v7ZPsuCgk50ACjEQkJCHLegoCCZTCbH/d9//10BAQFavXq1mjdvLm9vb/344486dOiQevTooeDgYPn7++vWW2/Vd999l+24//w5lslk0kcffaQHHnhAfn5+qlmzpr766ivH4//sEJ8/f75KliypNWvWqG7duvL399fdd9+d7S8d6enpevbZZ1WyZEmVKVNGY8eOVf/+/fP1DfPff/+tiIgIlSpVSn5+furatav+/PNPx+NHjx5V9+7dVapUKZUoUUL169fXqlWrHM/t16+fypUrJ19fX9WsWVPz5s276VoAAAAAAEVHQbn+zo2fn59CQkJ0yy23aPz48dmeFxcXp8GDB6tcuXIKDAxUx44dtXfvXsdzs0aofPTRR6pWrZp8fHwkZXS4Dxs2TMOGDVNQUJDKli2rl156SXa7Pdc6rvVaZ86cUUhIiF5//XXH/ps3b5aXl5ej+/zKcS7jx4/Xxx9/rBUrVjg67aOiotSxY0cNGzYs2+ueOXMm23GcjRA9H/Ydj9fKn0/p4OkLRpcCwEXsdrsupqa7/XatE9KNev755zV58mTt379fjRo1UmJiorp166b169dr9+7duvvuu9W9e3cdO3bsmseZMGGCHn74Yf3888/q1q2b+vXrp/Pnz+e6/8WLF/XWW2/pk08+0ffff69jx45pzJgxjsffeOMNLVy4UPPmzdOmTZuUkJCg5cuX5+u9DhgwQD/99JO++uorbdmyRXa7Xd26dVNaWpokaejQoUpJSdH333+vffv26Y033nB8w/3SSy/pt99+0+rVq7V//37NnDlTZcuWzVc9AAAAcK7kNKtW7zul1ftOXX9nAIWGUdfeReX6Oye+vr5KTU2VJD300EM6ffq0Vq9erZ07d6pZs2bq1KlTtmMePHhQX375pZYuXao9e/Y4tn/88cfy8PDQ9u3b9e6772rKlCn66KOPcn3da71WuXLlNHfuXI0fP14//fSTLly4oMcee0zDhg1Tp06drjrWmDFj9PDDDzua8k6dOqU2bdpo8ODBWrRokVJSUhz7fvrpp6pUqZI6dux4Q59TXjHOJR8WbjuqxTui9VyX2qpRPsDocgC4wKU0q+q9vMbtr/vbK13k5+Wc/0S/8soruvPOOx33S5curcaNGzvuv/rqq1q2bJm++uqrq77JvdKAAQMcPwN7/fXX9d5772n79u26++67c9w/LS1Ns2bNUvXq1SVJw4YN0yuvvOJ4/P3331dkZKQeeOABSdK0adMcXeE3488//9RXX32lTZs2qU2bNpKkhQsXKjQ0VMuXL9dDDz2kY8eOqVevXmrYsKEk6ZZbbnE8/9ixY2ratKlatGghKaMbAAAAAAVL3MU0Pb1wlzwtJv3ZsILR5QBwEqOuvaWicf19JavVqs8++0w///yznnjiCf3444/avn27Tp8+LW9vb0nSW2+9peXLl+uLL75wzGNPTU3VggULrhovExoaqnfeeUcmk0m1a9fWvn379M4772jIkCFXvXZeXqtbt24aMmSI+vXrpxYtWqhEiRKaNGlSju/F399fvr6+SklJyTZCtmfPnho2bJhWrFihhx9+WFLGL+IHDBggk8l03c/oZtCJng8Wc8b/KOlW531jBQDOlhUKZ0lMTNSYMWNUt25dlSxZUv7+/tq/f/91vwlv1KiR499LlCihwMBAnT59Otf9/fz8HAG6JFWoUMGxf3x8vGJjY9WyZUvH4xaLRc2bN7+h93al/fv3y8PDQ61atXJsK1OmjGrXrq39+/dLkp599lm99tpratu2rcaNG6eff/7Zse/TTz+txYsXq0mTJvr3v/+tzZs333QtAAAAhcX48eOvWhyvTp06jseTk5M1dOhQlSlTRv7+/urVq5diY2MNqzfzMlxWG9fhAAoeo66/JWnGjBmO0HnIkCEaNWqUnn76ae3du1eJiYmO/45n3Q4fPqxDhw45nl+1atUc57O3bt06WzAdHh6uP//8U1ar9ap98/pab731ltLT0/X5559r4cKFjsA9r3x8fPTYY49p7ty5kqRdu3bpl19+0YABA27oODeCTvR88Mg8e1ttNoMrAeAqvp4W/fZKF0Ne11lKlCiR7f6YMWO0bt06vfXWW6pRo4Z8fX314IMPOn7mlRtPT89s900mk2zX+O9fTvs782dyN2Pw4MHq0qWLVq5cqbVr12rSpEl6++23NXz4cHXt2lVHjx7VqlWrtG7dOnXq1ElDhw7VW2+9ZWjNAAAArla/fv1sM3qvXAhv1KhRWrlypT7//HMFBQVp2LBh6tmzpzZt2mREqTJnXoeToQNFi1HX3lmv7SxGXX9LUr9+/fTCCy/I19dXFSpUkNmc0TudmJioChUqKCoq6qrnlCxZMtfab0ZeX+vQoUM6efKkbDabjhw54vi1+I0YPHiwmjRpouPHj2vevHnq2LGjqlatmo/qr40QPR8smX8Y0zl7A0WWyWRy2s+6CopNmzZpwIABjjEqiYmJOnLkiFtrCAoKUnBwsHbs2KF27dpJyvjJ2a5duxwLiNyounXrKj09Xdu2bXOMczl37pwOHDigevXqOfYLDQ3VU089paeeekqRkZGaPXu2hg8fLiljVfT+/furf//+uv322/Xcc88RogMAgCLPw8Mj28/ks8THx2vOnDlatGiRY8bsvHnzVLduXW3dulWtW7d2d6kyX9ENabfbXfazfQDuVRSvvSX3Xn8HBQWpRo0aV21v1qyZYmJi5OHhcVNjS7dt25bt/tatW1WzZk1ZLFd/+ZCX10pNTdWjjz6q3r17q3bt2ho8eLD27dun8uXL57i/l5dXjl3vDRs2VIsWLTR79mwtWrRI06ZNu+H3diMY55IPHpasTnRCdACFR82aNR0Lhezdu1d9+/a97jfarjB8+HBNmjRJK1as0IEDBzRixAj9/fffeboQ2rdvn/bs2eO47d27VzVr1lSPHj00ZMgQ/fjjj9q7d68effRRVapUST169JAkjRw5UmvWrNHhw4e1a9cubdiwQXXr1pUkvfzyy1qxYoUOHjyoX3/9Vd98843jMQAAgKLszz//VMWKFXXLLbeoX79+jjEDO3fuVFpamjp37uzYt06dOqpSpYq2bNliSK3mK/6qyKU4gIKuIFx/d+7cWeHh4br//vu1du1aHTlyRJs3b9YLL7ygn3766brPP3bsmEaPHq0DBw7os88+0/vvv68RI0bc9Gu98MILio+P13vvvaexY8eqVq1aevzxx3N9/bCwMP388886cOCAzp49q7S0NMdjgwcP1uTJk2W32x1fVLgKIXo+OGaic+YGUIhMmTJFpUqVUps2bdS9e3d16dJFzZo1c3sdY8eOVZ8+fRQREaHw8HD5+/urS5cu8vHxue5z27Vrp6ZNmzpuWbPU582bp+bNm+vee+9VeHi47Ha7Vq1a5fgpnNVq1dChQ1W3bl3dfffdqlWrlmbMmCEp49vtyMhINWrUSO3atZPFYtHixYtd9wEAAAAUAK1atdL8+fP17bffaubMmTp8+LBuv/12XbhwQTExMfLy8sr2E3xJCg4OVkxMzDWPm5KSooSEhGw3Z7iy4YKGNgAFXUG4/jaZTFq1apXatWungQMHqlatWnrkkUd09OhRBQcHX/f5ERERunTpklq2bKmhQ4dqxIgRjsVIb/S1oqKiNHXqVH3yyScKDAyU2WzWJ598oh9++EEzZ87M8ZhDhgxR7dq11aJFC5UrVy7bOLE+ffrIw8NDffr0yVOWkB8mu9EDat0sISFBQUFBio+PV2BgYL6O9fbaA3r//w5qQJswjb+vvpMqBGCU5ORkHT58WNWqVXP5f3xxNZvNprp16+rhhx/Wq6++anQ5LpPbnzNnnp+KKj4jAEBBVZTOUXFxcapataqmTJkiX19fDRw4UCkpKdn2admype644w698cYbuR5n/PjxmjBhwlXb8/sZJaakq8G4NZKk31+9Wz5OnGUMwD249i48OnTooCZNmmjq1KlGl5KjI0eOqHr16tqxY8c1v5y41p+5vJ7D6UTPh8ud6CwsCgA36ujRo5o9e7b++OMP7du3T08//bQOHz6svn37Gl0aAABAsVWyZEnVqlVLBw8eVEhIiFJTUxUXF5dtn9jY2BxnqF8pMjJS8fHxjlt0dLRT6rtynEvxagkEAGRJS0tTTEyMXnzxRbVu3dot3f2E6PngYWYmOgDcLLPZrPnz5+vWW29V27ZttW/fPn333XfMIQcAADBQYmKiDh06pAoVKqh58+by9PTU+vXrHY8fOHBAx44dU3h4+DWP4+3trcDAwGw3Z7hyYVEbKToAFEubNm1ShQoVtGPHDs2aNcstr1n0lr11I4s54zuIdCsnbgC4UaGhodlmmQEAAMD9xowZo+7du6tq1ao6efKkxo0bJ4vFoj59+igoKEiDBg3S6NGjVbp0aQUGBmr48OEKDw9X69atDanXlG1hUa7FAcCVoqKijC4hRx06dJC7J5QToueDJbOPn050AAAAAEBhdPz4cfXp00fnzp1TuXLldNttt2nr1q0qV66cJOmdd96R2WxWr169lJKSoi5dujgWZjdCtk50JqsCANyEED0fHJ3ohOgAAAAAgEJo8eLF13zcx8dH06dP1/Tp091U0bVZGOcCADAAM9HzgZnoAAAAAAC4D+NcAABGIETPB0tmiJ7Ob8gAAAAAAHA5k8nkCNLpZwMAuAshej7QiQ4AAAAAgHtlzUWnEx0A4C6E6PlwuROdEzcAAAAAAO5gIUQHALgZIXo+eFjoRAdQNHTo0EEjR4503A8LC9PUqVOv+RyTyaTly5fn+7WddRwAAAAUD4xzAVCY/fP6uyAZP368mjRp4rTjHTlyRCaTSXv27HHaMY1CiJ4PFnPGx0eIDsAo3bt31913353jYz/88INMJpN+/vnnGz7ujh079MQTT+S3vGxyOxmfOnVKXbt2depr/dP8+fNVsmRJl74GAAAA3MMxzoVrcQBu5Krr73+aP39+5voPJpnNZlWuXFkDBw7U6dOn831sdwsNDdWpU6fUoEEDSVJUVJRMJpPi4uKMLewmEKLngwfjXAAYbNCgQVq3bp2OHz9+1WPz5s1TixYt1KhRoxs+brly5eTn5+eMEq8rJCRE3t7ebnktAAAAFH5mRyc61+IA3MdV1985CQwM1KlTp3T8+HHNnj1bq1ev1mOPPXbTx0tLS3NKXTfKYrEoJCREHh4ehry+MxGi54OFhUUBGOzee+9VuXLlNH/+/GzbExMT9fnnn2vQoEE6d+6c+vTpo0qVKsnPz08NGzbUZ599ds3j/nOcy59//ql27drJx8dH9erV07p16656ztixY1WrVi35+fnplltu0UsvveQ4Uc+fP18TJkzQ3r17Hd+oZ9X8z3Eu+/btU8eOHeXr66syZcroiSeeUGJiouPxAQMG6P7779dbb72lChUqqEyZMho6dGi+/lJw7Ngx9ejRQ/7+/goMDNTDDz+s2NhYx+N79+7VHXfcoYCAAAUGBqp58+b66aefJElHjx5V9+7dVapUKZUoUUL169fXqlWrbroWAAAAXNvlhUUNLgRAseKq6++cmEwmhYSEqGLFiurataueffZZfffdd7p06ZIk6aOPPlLdunXl4+OjOnXqaMaMGY7nZo1QWbJkidq3by8fHx8tXLjQ8Qvt5cuXq2bNmvLx8VGXLl0UHR19zVqu9VqPP/64GjVqpJSUFElSamqqmjZtqoiIiGy17NmzR0eOHNEdd9whSSpVqpRMJpMGDBigBQsWqEyZMo5jZLn//vvz9cWBsxX+rwEMRCc6UAzY7VLaRfe/rqff5WGP1+Dh4aGIiAjNnz9fL7zwgkyZz/n8889ltVrVp08fJSYmqnnz5ho7dqwCAwO1cuVKPfbYY6pevbpatmx53dew2Wzq2bOngoODtW3bNsXHx+c4vy0gIEDz589XxYoVtW/fPg0ZMkQBAQH697//rd69e+uXX37Rt99+q++++06SFBQUdNUxkpKS1KVLF4WHh2vHjh06ffq0Bg8erGHDhmX7i8qGDRtUoUIFbdiwQQcPHlTv3r3VpEkTDRky5LrvJ6f3lxWgb9y4Uenp6Ro6dKh69+6tqKgoSVK/fv3UtGlTzZw5UxaLRXv27JGnp6ckaejQoUpNTdX333+vEiVK6LfffpO/v/8N1wEAAIC8MZtZWBQocoy69pYK1PV3bnx9fWWz2ZSenq6FCxfq5Zdf1rRp09S0aVPt3r1bQ4YMUYkSJdS/f3/Hc55//nm9/fbbatq0qXx8fLRmzRpdvHhREydO1IIFC+Tl5aVnnnlGjzzyiDZt2pTj617vtd577z01btxYzz//vN555x298MILiouL07Rp0646VmhoqL788kv16tVLBw4cUGBgoHx9feXl5aVnn31WX331lR566CFJ0unTp7Vy5UqtXbv2pj8zZyNEz4fLneg2gysB4DJpF6XXK7r/df9zUvIqkaddH3/8cb355pvauHGjOnToICnjp2S9evVSUFCQgoKCNGbMGMf+w4cP15o1a/S///0vTyfx7777Tr///rvWrFmjihUzPovXX3/9qjnmL774ouPfw8LCNGbMGC1evFj//ve/5evrK39/f3l4eCgkJCTX11q0aJGSk5O1YMEClSiR8f6nTZum7t2764033lBwcLCkjG+tp02bJovFojp16uiee+7R+vXrbypEX79+vfbt26fDhw8rNDRUkrRgwQLVr19fO3bs0K233qpjx47pueeeU506dSRJNWvWdDz/2LFj6tWrlxo2bChJuuWWW264BgAAAORd1jgXOyE6UHQYde0tFajr75z8+eefmjVrllq0aKGAgACNGzdOb7/9tnr27ClJqlatmn777Td98MEH2UL0kSNHOvbJkpaWpmnTpqlVq1aSpI8//lh169bV9u3bc6zveq/l7++vTz/9VO3bt1dAQICmTp2qDRs2KDAw8KpjWSwWlS5dWpJUvnz5bOuW9e3bV/PmzXOE6J9++qmqVKni+IwLAsa55INH5sKi6VZO3ACMU6dOHbVp00Zz586VJB08eFA//PCDBg0aJEmyWq169dVX1bBhQ5UuXVr+/v5as2aNjh07lqfj79+/X6GhoY4AXZLCw8Ov2m/JkiVq27atQkJC5O/vrxdffDHPr3HlazVu3NgRoEtS27ZtZbPZdODAAce2+vXry2KxOO5XqFDhphdZyXp/WQG6JNWrV08lS5bU/v37JUmjR4/W4MGD1blzZ02ePFmHDh1y7Pvss8/qtddeU9u2bTVu3DinLCQDAACA3DHOBYBRXH39nSU+Pl7+/v7y8/NT7dq1FRwcrIULFyopKUmHDh3SoEGD5O/v77i99tpr2a5TJalFixZXHdfDw0O33nprtvdz5bXvlfL6WuHh4RozZoxeffVV/etf/9Jtt912Q+9VkoYMGaK1a9fqxIkTkjJGwg4YMMDR7V8Q0ImeD8xEB4oBT7+Mb6WNeN0bMGjQIA0fPlzTp0/XvHnzVL16dbVv316S9Oabb+rdd9/V1KlT1bBhQ5UoUUIjR45Uamqq08rdsmWL+vXrpwkTJqhLly4KCgrS4sWL9fbbbzvtNa6UNUoli8lkks2FvwoaP368+vbtq5UrV2r16tUaN26cFi9erAceeECDBw9Wly5dHD81mzRpkt5++20NHz7cZfUAAAAUZ1mhCtfiQBFi1LV31mvfAHdcfwcEBGjXrl0ym82qUKGCfH19Jcmxdtfs2bMd3eRZrmw0k5StOe1mZK1Ndr3Xstls2rRpkywWiw4ePHhTr9W0aVM1btxYCxYs0F133aVff/1VK1euvPniXYAQPR88LJy4gSLPZMrzz7qM9PDDD2vEiBFatGiRFixYoKefftpxcbFp0yb16NFDjz76qKSME9wff/yhevXq5enYdevWVXR0tE6dOqUKFSpIkrZu3Zptn82bN6tq1ap64YUXHNuOHj2abR8vLy9Zrdbrvtb8+fOVlJTkOOFv2rRJZrNZtWvXzlO9Nyrr/UVHRzu60X/77TfFxcVl+4xq1aqlWrVqadSoUerTp4/mzZunBx54QFLGbLennnpKTz31lCIjIzV79mxCdAAAABexZP6mnpnoQBFSSK69Jddef2cxm82qUaPGVduDg4NVsWJF/fXXX+rXr98N156enq6ffvrJMbrlwIEDiouLU926dW/6td588039/vvv2rhxo7p06aJ58+Zp4MCBOe7r5eUlSTlmA4MHD9bUqVN14sQJde7cOduvxQsCxrnkg4WFRQEUEP7+/urdu7ciIyN16tQpDRgwwPFYzZo1tW7dOm3evFn79+/Xk08+6fj2Oi86d+6sWrVqqX///tq7d69++OGHbGF51mscO3ZMixcv1qFDh/Tee+9p2bJl2fYJCwvT4cOHtWfPHp09e/aqlbeljAU8fXx81L9/f/3yyy/asGGDhg8frscee8wxD/1mWa1W7dmzJ9tt//796ty5sxo2bKh+/fpp165d2r59uyIiItS+fXu1aNFCly5d0rBhwxQVFaWjR49q06ZN2rFjh+MvGSNHjtSaNWt0+PBh7dq1Sxs2bMjxLyAAAABwjqxxLmToAIzgyuvvvJgwYYImTZqk9957T3/88Yf27dunefPmacqUKdd9rqenp4YPH65t27Zp586dGjBggFq3bp3rvPbrvdbu3bv18ssv66OPPlLbtm01ZcoUjRgxQn/99VeOx6tatapMJpO++eYbnTlzxtHtLmXMRT9+/Lhmz56txx9//CY+GdciRM8HD8a5AChABg0apL///ltdunTJNr/8xRdfVLNmzdSlSxd16NBBISEhuv/++/N8XLPZrGXLlunSpUtq2bKlBg8erIkTJ2bb57777tOoUaM0bNgwNWnSRJs3b9ZLL72UbZ9evXrp7rvv1h133KFy5crps88+u+q1/Pz8tGbNGp0/f1633nqrHnzwQXXq1CnHlb1vVGJiopo2bZrt1r17d5lMJq1YsUKlSpVSu3bt1LlzZ91yyy1asmSJpIyfqZ07d04RERGqVauWHn74YXXt2lUTJkyQlBHODx06VHXr1tXdd9+tWrVqacaMGfmuFwAAADm7PBOda3EAxnDV9XdeDB48WB999JHmzZunhg0bqn379po/f76qVat23ef6+flp7Nix6tu3r9q2bSt/f3/Hte+NvlZycrIeffRRDRgwQN27d5ckPfHEE7rjjjv02GOP5dhtXqlSJU2YMEHPP/+8goODNWzYMMdjQUFB6tWrl/z9/Z3+mTmDyV7MlrNOSEhQUFCQ4uPjc1wp9kb8ejJe97z3o4IDvbXtP52dVCEAoyQnJ+vw4cOqVq2afHx8jC4HRVRuf86ceX4qqviMAAAFFeeo63PmZ3TbG/+n439f0rJn2qhplVJOqhCAu3DtbYz58+dr5MiRiouLM7qUXHXq1En169fXe++959TjXuvPXF7PT8xEzwcPc0YjP53oAAAAAAC4x+VOdIMLAQA4xd9//62oqChFRUUV2F92E6LnAzPRAQAAAABwr6xr8WL2w3oAKLKaNm2qv//+W2+88YZq165tdDk5IkTPB8dMdCsnbgAAAAAA3CGzEZ1OdAC4AQMGDMi2CGpBcuTIEaNLuC4WFs0HOtEBAAAAAHAvFhYFALgbIXo+eFgyO9EJ0QEAAAAAcAtzVic61+IAADchRM+Hy53oNoMrAeBMNv4/DRfizxcAAED+sLAoUDRwbQR3ccafNWai54OHOeM7CJs94xtwc9bX4QAKJS8vL5nNZp08eVLlypWTl5eXTCb+fw3nsNvtSk1N1ZkzZ2Q2m+Xl5WV0SQAAAIUS41yAwo1rb7iLM6/DCdHzwXJFaG6122UW/4cHCjOz2axq1arp1KlTOnnypNHloIjy8/NTlSpVZDbzYzAAAICbkfXXKEJ0oHDi2hvu5ozrcEL0fPC4MkS32eVpMbAYAE7h5eWlKlWqKD09XVar1ehyUMRYLBZ5eHjQZQEAAJAPdKIDhR/X3nAXZ12HE6Lnw5Wd6OkMYwOKDJPJJE9PT3l6ehpdCgAAAIB/yApCGKcMFG5ce6Mw4bfk+ZCtE91KiA4AAAAAgKtZMi/F6UQHALgLIXo+ZO9E5ytwAAAAAABc7fI4F4MLAQAUG4To+WAymRxBupWzNwAAAAAALpcVotvpRAcAuAkhej5lhejMRAcAAAAAwPWy1oazEqIDANyEED2fPOhEBwAAAADAbbKa2bgMBwC4CyF6PtGJDgAAAACA+zDOBQDgboTo+XS5E52FRQEAAAAAcLWscS42QnQAgJsQoueTxZzxEdKJDgAAAACA62V1olvpZQMAuAkhej5ldaKnWwnRAQAAAABwtcsz0bkOBwC4ByF6PllYWBQAAAAAALfJvAxnJjoAwG0I0fPJw8LCogAAAAAAuIvJlNWJbnAhAIBigxA9n+hEBwAAAADAfcwsLAoAcDNC9HxyzES3saIJAAAAAACulrWwqI1mNgCAmxCi55PFnPER0okOAAAAAIDrmc2McwEAuBchej5d7kTn7A0AAAAAgKs5OtEZ5wIAcBNC9HzK+gbcauXkDQAAAACAq12eiW5sHQCA4oMQPZ/oRAcAAAAAwH2YiQ4AcDdC9HyyZHWic/IGAAAAAMDlGOcCAHA3QvR8utyJbjO4EgAAAAAAij7GuQAA3I0QPZ/oRAcAAAAAwH3oRAcAuBshej4xEx0AAAAAAPcxZyYZdkJ0AICbEKLnkyXz7E0nOgCgOJo+fbrCwsLk4+OjVq1aafv27dfcf+rUqapdu7Z8fX0VGhqqUaNGKTk52U3VAgCAosBkyvpFuMGFAACKDUL0fKITHQBQXC1ZskSjR4/WuHHjtGvXLjVu3FhdunTR6dOnc9x/0aJFev755zVu3Djt379fc+bM0ZIlS/Sf//zHzZUDAIDCzMI4FwCAmxGi55PFknnyJkQHABQzU6ZM0ZAhQzRw4EDVq1dPs2bNkp+fn+bOnZvj/ps3b1bbtm3Vt29fhYWF6a677lKfPn2u270OAABwpayFRRnnAgBwF0L0fKITHQBQHKWmpmrnzp3q3LmzY5vZbFbnzp21ZcuWHJ/Tpk0b7dy50xGa//XXX1q1apW6deuW4/4pKSlKSEjIdgMAADA5OtENLgQAUGx4GF1AYWcxZ81iYxgbAKD4OHv2rKxWq4KDg7NtDw4O1u+//57jc/r27auzZ8/qtttuk91uV3p6up566qlcx7lMmjRJEyZMcHrtAACgcDNnzUSnEx0A4CZ0oucTnegAAORNVFSUXn/9dc2YMUO7du3S0qVLtXLlSr366qs57h8ZGan4+HjHLTo62s0VAwCAgsiSmWQwEx0A4C50oueTxZxx9rZaOXkDAIqPsmXLymKxKDY2Ntv22NhYhYSE5Picl156SY899pgGDx4sSWrYsKGSkpL0xBNP6IUXXpDZnP27fW9vb3l7e7vmDQAAgEIrqxOdDB0A4C50oucTnegAgOLIy8tLzZs31/r16x3bbDab1q9fr/Dw8Byfc/HixauCcovFIomFwQAAQN45ZqJzHQ4AcBM60fPp8kx0Tt4AgOJl9OjR6t+/v1q0aKGWLVtq6tSpSkpK0sCBAyVJERERqlSpkiZNmiRJ6t69u6ZMmaKmTZuqVatWOnjwoF566SV1797dEaYDAABcT+ZlODPRAQBuQ4ieT3SiAwCKq969e+vMmTN6+eWXFRMToyZNmujbb791LDZ67NixbJ3nL774okwmk1588UWdOHFC5cqVU/fu3TVx4kSj3gIAACiEGOcCAHA3QvR8sliyOtFtBlcCAID7DRs2TMOGDcvxsaioqGz3PTw8NG7cOI0bN84NlQEAgKLKnNnMxsKiAAB3YSZ6PtGJDgAAAACA+2SNcyFEBwC4i6Eh+syZM9WoUSMFBgYqMDBQ4eHhWr16da77z58/XyaTKdvNx8fHjRVfzZL5M3VmogMAAAAA4HpZ41y4DAcAuIuh41wqV66syZMnq2bNmrLb7fr444/Vo0cP7d69W/Xr18/xOYGBgTpw4IDjftaq3EahEx0AAAAAAPdxdKJzHQ4AcBNDQ/Tu3btnuz9x4kTNnDlTW7duzTVEN5lMCgkJcUd5eWLJPHtbrZy8AQAAAABwNWaiAwDcrcDMRLdarVq8eLGSkpIUHh6e636JiYmqWrWqQkND1aNHD/3666/XPG5KSooSEhKy3ZyJTnQAAAAAANyHcS4AAHczPETft2+f/P395e3traeeekrLli1TvXr1cty3du3amjt3rlasWKFPP/1UNptNbdq00fHjx3M9/qRJkxQUFOS4hYaGOrV+Rye6zebU4wIAAAAAgKuxsCgAwN0MD9Fr166tPXv2aNu2bXr66afVv39//fbbbznuGx4eroiICDVp0kTt27fX0qVLVa5cOX3wwQe5Hj8yMlLx8fGOW3R0tFPrpxMdAAAAAAD3cXSicx0OAHATQ2eiS5KXl5dq1KghSWrevLl27Nihd99995rBeBZPT081bdpUBw8ezHUfb29veXt7O63ef7JYMr6HsHLyBgAAAADA5UyMcwEAuJnhnej/ZLPZlJKSkqd9rVar9u3bpwoVKri4qtzRiQ4AAAAAgPtYGOcCAHAzQzvRIyMj1bVrV1WpUkUXLlzQokWLFBUVpTVr1kiSIiIiVKlSJU2aNEmS9Morr6h169aqUaOG4uLi9Oabb+ro0aMaPHiwYe/h8kx0Tt4AAAAAALiaOfM6nAwdAOAuhobop0+fVkREhE6dOqWgoCA1atRIa9as0Z133ilJOnbsmMzmy83yf//9t4YMGaKYmBiVKlVKzZs31+bNm3NdiNQd6EQHAAAAAMB9Lo9z4TocAOAehoboc+bMuebjUVFR2e6/8847euedd1xY0Y273IluM7gSAAAAAACKvszLcH4RDgBwmwI3E72w8cjslE+3cvIGAAAAAMDVLCwsCgBwM0L0fGImOgAAAAAA7mM2Zc1E5zocAOAehOj5xEx0AAAAAEBRMXnyZJlMJo0cOdKxLTk5WUOHDlWZMmXk7++vXr16KTY21rAaMzN0ZqIDANyGED2fLBY60QEAAAAAhd+OHTv0wQcfqFGjRtm2jxo1Sl9//bU+//xzbdy4USdPnlTPnj0NqvJyJzpTVQEA7kKInk90ogMAAAAACrvExET169dPs2fPVqlSpRzb4+PjNWfOHE2ZMkUdO3ZU8+bNNW/ePG3evFlbt241pNbMpckY5wIAcBtC9Hy6PBPdZnAlAAAAAADcnKFDh+qee+5R586ds23fuXOn0tLSsm2vU6eOqlSpoi1btuR6vJSUFCUkJGS7OYvZsbAoIToAwD08jC6gsPPI/AqcTnQAAAAAQGG0ePFi7dq1Szt27LjqsZiYGHl5ealkyZLZtgcHBysmJibXY06aNEkTJkxwdqmSrgjR6WUDALgJnej5dLkTnRAdAAAAAFC4REdHa8SIEVq4cKF8fHycdtzIyEjFx8c7btHR0U47Np3oAAB3I0TPJ8dMdFY0AQAAAAAUMjt37tTp06fVrFkzeXh4yMPDQxs3btR7770nDw8PBQcHKzU1VXFxcdmeFxsbq5CQkFyP6+3trcDAwGw3Z8m8DCdEBwC4DeNc8olOdAAAAABAYdWpUyft27cv27aBAweqTp06Gjt2rEJDQ+Xp6an169erV69ekqQDBw7o2LFjCg8PN6Jkmc1ZneiGvDwAoBgiRM8nD0tmJzpnbwAAAABAIRMQEKAGDRpk21aiRAmVKVPGsX3QoEEaPXq0SpcurcDAQA0fPlzh4eFq3bq1ESUzzgUA4HaE6Pnk4ehEZ0UTAAAAAEDR884778hsNqtXr15KSUlRly5dNGPGDMPquTzOxbASAADFDCF6PlnMGWPl6UQHAAAAABQFUVFR2e77+Pho+vTpmj59ujEF/YOjE53rcACAm7CwaD5ZTMxEBwAAAADAXUwsLAoAcDNC9HyyMBMdAAAAAAC3sbCwKADAzQjR8+nyTHTO3gAAAAAAuFrWOBc7negAADchRM8nyxUhOidwAAAAAABci3EuAAB3I0TPp6xOdIludAAAAAAAXM3M2mQAADcjRM8nyxUhOnPRAQAAAABwrazrcBrRAQDuQoieTx7myx8h34IDAAAAAOBaZsa5AADcjBA9n+hEBwAAAADAfUyZ41y4BAcAuAshej4xEx0AAAAAAPdhJjoAwN0I0fPJbDY5VgZPt9mMLQYAAAAAgCLOYsqaiU6IDgBwD0J0J8jqRidDBwAAAADAtUyOmejG1gEAKD4I0Z0gay46negAAAAAALiW2TETnRQdAOAehOhO4GHO+BjTrZzAAQAAAABwpcxLcDrRAQBuQ4juBN4eGR9jSjqd6AAAAAAAuBKd6AAAdyNEdwIfT4sk6VKa1eBKAAAAAAAo2gjRAQDuRojuBL5emSF6KiE6AAAAAACuZM5aWJR5LgAANyFEdwLfzE70ZDrRAQAAAABwqaxOdBrRAQDuQojuBL6McwEAAAAAwC2yQnQrKToAwE0I0Z3Ax4tOdAAAAAAA3MGcmWQwEx0A4C6E6E7g65nxMdKJDgAAAACAa11eWNTgQgAAxQYhuhM4xrmwsCgAAAAAAC51eSY6KToAwD0I0Z3Al3EuAAAAAAC4hTkjQ5eVVnQAgJsQojuBtwcLiwIAAAAA4A4mxrkAANyMEN0JsjrRL6XaDK4EAAAAAICizZLVii5GugAA3IMQ3QkcM9HpRAcAAAAAwKWuyNDpRgcAuAUhen4knpZWDFWgKVkSM9EBAAAAAHC1rHEukmSjEx0A4AaE6DfLbpcW95V2f6rO+/8ji6y6lEqIDgAAAACAK13Zic7iogAAdyBEv1kmk3T3G5KHryqf+V4venzKOBcAAAAAAFws+0x0AwsBABQbhOj5Ubm51PMDSdJAjzXyTj5tcEEAAAAAABRtZsa5AADcjBA9v+r1UKpXSUmSZ2qCsbUAAAAAAFDEmbItLEqIDgBwPUJ0Z7B4SZKsaSkGFwIAAAAAQNGWrRPdZmAhAIBigxDdCewWT0mSNT3V4EoAAAAAACjaGOcCAHA3QnQnMJkzQnRbeprBlQAAAAAAULSZGecCAHAzQnRn8MgY52JLZ5wLAAAAAACuZDKZHHPRbWToAAA3IER3ApMlK0RPk51vwQEAAAAAcKmskS5cgwMA3IEQ3QlMHhnjXCz2NKVZOYEDAAAAAOBKWSNdrIToAAA3IER3AnNmJ7qn0nUpzWpwNQAAAAAAFG1ZneiMcwEAuAMhuhNkdaJ7yqpkQnQAAAAAAFzKEaKTogMA3IAQ3QlMV3aipxKiAwAAAADgSlnjXJjmAgBwB0J0Z8gK0U2McwEAAAAAwNWyOtGZiQ4AcAdCdGcwe0jKGOdCiA4AAAAAgGtlZuiyEaIDANyAEN0Zrhjnksw4FwAAAAAAXMqSOc/FTogOAHADQnRnyAzRPehEBwAAAADA5RwLi5KhAwDcgBDdGSwZ41y8lK7kNJvBxQAAAAAAULSZHCE6KToAwPUI0Z3hinEudKIDAAAAAOBamdNcZKUVHQDgBoTozpA1zsXEOBcAQPEyffp0hYWFycfHR61atdL27duvuX9cXJyGDh2qChUqyNvbW7Vq1dKqVavcVC0AACgqLs9EN7gQAECx4GF0AUWCOeNjZGFRAEBxsmTJEo0ePVqzZs1Sq1atNHXqVHXp0kUHDhxQ+fLlr9o/NTVVd955p8qXL68vvvhClSpV0tGjR1WyZEn3Fw8AAAo1M+NcAABuRIjuDJmd6F5KVyKd6ACAYmLKlCkaMmSIBg4cKEmaNWuWVq5cqblz5+r555+/av+5c+fq/Pnz2rx5szw9PSVJYWFh7iwZAAAUEZkZOguLAgDcgnEuzmDJCAI8xDgXAEDxkJqaqp07d6pz586ObWazWZ07d9aWLVtyfM5XX32l8PBwDR06VMHBwWrQoIFef/11Wa05nztTUlKUkJCQ7QYAACBd7kRnJjoAwB0I0Z0hM0T3VLouMc4FAFAMnD17VlarVcHBwdm2BwcHKyYmJsfn/PXXX/riiy9ktVq1atUqvfTSS3r77bf12muv5bj/pEmTFBQU5LiFhoY6/X0AAIDCKWthUTvjXAAAbkCI7gxZ41xM6UqmEx0AgBzZbDaVL19eH374oZo3b67evXvrhRde0KxZs3LcPzIyUvHx8Y5bdHS0mysGAAAFldmcNRPd4EIAAMUCM9Gdwcw4FwBA8VK2bFlZLBbFxsZm2x4bG6uQkJAcn1OhQgV5enrKYrE4ttWtW1cxMTFKTU2Vl5dXtv29vb3l7e3t/OIBAEChx8KiAAB3ohPdGRjnAgAoZry8vNS8eXOtX7/esc1ms2n9+vUKDw/P8Tlt27bVwYMHZbPZHNv++OMPVahQ4aoAHQAA4FrMjoVFCdEBAK5HiO4MmeNcPOlEBwAUI6NHj9bs2bP18ccfa//+/Xr66aeVlJSkgQMHSpIiIiIUGRnp2P/pp5/W+fPnNWLECP3xxx9auXKlXn/9dQ0dOtSotwAAAAopRye67To7AgDgBIxzcYYrOtGZiQ4AKC569+6tM2fO6OWXX1ZMTIyaNGmib7/91rHY6LFjx2Q2X/6+PjQ0VGvWrNGoUaPUqFEjVapUSSNGjNDYsWONegsAAKCQYpwLAMCdCNGdwdGJnq6LjHMBABQjw4YN07Bhw3J8LCoq6qpt4eHh2rp1q4urAgAARV3W9/SE6AAAd2CcizOYM76L8DBZmYkOAAAAAICLZXWik6EDANyBEN0ZMjvRvZSupNR0g4sBAAAAAKBoM2WG6FYbKToAwPUI0Z3hynEuKXSiAwAAAABcb968ebp48aLRZRjCnJGhM84FAOAWhOjOYMkc5yKrklLTZeckDgAAAABwseeff14hISEaNGiQNm/ebHQ5bmVxLCxqcCEAgGKBEN0ZruhEt9ml5DSbwQUBAAAAAIq6EydO6OOPP9bZs2fVoUMH1alTR2+88YZiYmKMLs3lLs9EJ0UHALgeIbozXBGiS2IuOgAAAADA5Tw8PPTAAw9oxYoVio6O1pAhQ7Rw4UJVqVJF9913n1asWCGbrWg2eZkc41yMrQMAUDwQojuDOWOci5cpYx56UgohOgAAAADAfYKDg3XbbbcpPDxcZrNZ+/btU//+/VW9enVFRUUZXZ7TZXWiW+lEBwC4ASG6M2R2onuZMjvRWVwUAAAAAOAGsbGxeuutt1S/fn116NBBCQkJ+uabb3T48GGdOHFCDz/8sPr37290mU5nMTPOBQDgPoaG6DNnzlSjRo0UGBiowMBAhYeHa/Xq1dd8zueff646derIx8dHDRs21KpVq9xU7TU4xrlkhOcXGecCAAAAAHCx7t27KzQ0VPPnz9eQIUN04sQJffbZZ+rcubMkqUSJEvrXv/6l6Ohogyt1vsvjXAjRAQCuZ2iIXrlyZU2ePFk7d+7UTz/9pI4dO6pHjx769ddfc9x/8+bN6tOnjwYNGqTdu3fr/vvv1/33369ffvnFzZX/gyVjnEvWTPRExrkAAAAAAFysfPny2rhxo3755ReNHDlSpUuXvmqfcuXK6fDhwwZU51pZ41yK6Mh3AEABY2iI3r17d3Xr1k01a9ZUrVq1NHHiRPn7+2vr1q057v/uu+/q7rvv1nPPPae6devq1VdfVbNmzTRt2jQ3V/4PmZ3oHpkh+sVUxrkAAAAAAFyrffv2atas2VXbU1NTtWDBAkmSyWRS1apV3V2ay2VOc2EmOgDALQrMTHSr1arFixcrKSlJ4eHhOe6zZcsWx8/SsnTp0kVbtmzJ9bgpKSlKSEjIdnM6s6ckyUNWSXY60QEAAAAALjdw4EDFx8dftf3ChQsaOHCgARW5DzPRAQDuZHiIvm/fPvn7+8vb21tPPfWUli1bpnr16uW4b0xMjIKDg7NtCw4OVkxMTK7HnzRpkoKCghy30NBQp9YvSbJ4Ov7VU1ZdJEQHAAAAALiY3W6XKWs4+BWOHz+uoKAgAypyn6z3bSNDBwC4gYfRBdSuXVt79uxRfHy8vvjiC/Xv318bN27MNUi/UZGRkRo9erTjfkJCgvOD9MxxLlLGXPQkxrkAAAAAAFykadOmMplMMplM6tSpkzw8Ll/aW61WHT58WHfffbeBFbqemYVFAQBuZHiI7uXlpRo1akiSmjdvrh07dujdd9/VBx98cNW+ISEhio2NzbYtNjZWISEhuR7f29tb3t7ezi36n67oRPdQupLoRAcAAAAAuMj9998vSdqzZ4+6dOkif39/x2NeXl4KCwtTr169DKrOPS4vLEqIDgBwPcND9H+y2WxKSUnJ8bHw8HCtX79eI0eOdGxbt25drjPU3cZ8+WP0kpWFRQEAAAAALjNu3DhJUlhYmHr37i0fHx+DK3I/M+NcAABuZOhM9MjISH3//fc6cuSI9u3bp8jISEVFRalfv36SpIiICEVGRjr2HzFihL799lu9/fbb+v333zV+/Hj99NNPGjZsmFFvIYPJ5BjpQic6AAAAAMAd+vfvn+8AfebMmWrUqJECAwMVGBio8PBwrV692vF4cnKyhg4dqjJlysjf31+9evW66hfiRjCbs0J0UnQAgOsZ2ol++vRpRURE6NSpUwoKClKjRo20Zs0a3XnnnZKkY8eOyWy+nPO3adNGixYt0osvvqj//Oc/qlmzppYvX64GDRoY9RYuM3tK1lR5mtKVlEqIDgAAAABwvtKlS+uPP/5Q2bJlVapUqRwXFs1y/vz56x6vcuXKmjx5smrWrCm73a6PP/5YPXr00O7du1W/fn2NGjVKK1eu1Oeff66goCANGzZMPXv21KZNm5z5tm7Y5ZnohpYBACgmDA3R58yZc83Ho6Kirtr20EMP6aGHHnJRRflg8ZTSJC+lKymFcS4AAAAAAOd75513FBAQ4Pj3a4XoedG9e/ds9ydOnKiZM2dq69atqly5subMmaNFixapY8eOkqR58+apbt262rp1q1q3bp2v186PrHEudjrRAQBuUOBmohdajnEuVl2kEx0AAAAA4AL9+/d3/PuAAQOcemyr1arPP/9cSUlJCg8P186dO5WWlqbOnTs79qlTp46qVKmiLVu2XDNET0lJybbeWUJCglNrzfruwEorOgDADQydiV6kWDwlSZ5KVyKd6AAAAAAAF5s/f36O29PT07OtL3Y9+/btk7+/v7y9vfXUU09p2bJlqlevnmJiYuTl5aWSJUtm2z84OFgxMTHXPOakSZMUFBTkuIWGhua5nrywsLAoAMCNCNGdJTNE91I6negAAAAAAJd79tln9dBDD+nvv/92bDtw4IBatWqlzz77LM/HqV27tvbs2aNt27bp6aefVv/+/fXbb7/lq7bIyEjFx8c7btHR0fk63j+ZTSwsCgBwn5sK0aOjo3X8+HHH/e3bt2vkyJH68MMPnVZYoWPOCNE9ZGUmOgAAAADA5Xbv3q3jx4+rYcOGWrdunaZPn65mzZqpTp062rt3b56P4+XlpRo1aqh58+aaNGmSGjdurHfffVchISFKTU1VXFxctv1jY2MVEhJyzWN6e3srMDAw282ZzJlpBjPRAQDucFMhet++fbVhwwZJUkxMjO68805t375dL7zwgl555RWnFlhoZM5E9zSlKymFTnQAAAAAgGtVr15dmzZtUs+ePXX33Xdr1KhR+uijj7Rw4UIFBQXd9HFtNptSUlLUvHlzeXp6av369Y7HDhw4oGPHjik8PNwZb+GmZS2oarUZWgYAoJi4qRD9l19+UcuWLSVJ//vf/9SgQQNt3rxZCxcuzHUmW5F3xUz0S2lWFjcBAAAAALjcypUrtXjxYoWHh6tkyZKaM2eOTp48mefnR0ZG6vvvv9eRI0e0b98+RUZGKioqSv369VNQUJAGDRqk0aNHa8OGDdq5c6cGDhyo8PDway4q6g7mzIVFGecCAHCHmwrR09LS5O3tLUn67rvvdN9990nKWKX71KlTzquuMHGE6BmjXJiLDgAAAABwpSeffFIPPfSQxo4dqx9++EE///yzvLy81LBhQ/3vf//L0zFOnz6tiIgI1a5dW506ddKOHTu0Zs0a3XnnnZKkd955R/fee6969eqldu3aKSQkREuXLnXl28qTrIVFGecCAHAHj5t5Uv369TVr1izdc889WrdunV599VVJ0smTJ1WmTBmnFlhoZI5z8TZlhehWBfh4GlkRAAAAAKAI27Rpk7Zt26bGjRtLkkJCQrRq1SpNnz5djz/+uB5++OHrHmPOnDnXfNzHx0fTp0/X9OnTnVKzs5gcC4saXAgAoFi4qU70N954Qx988IE6dOigPn36OE7YX331lWPMS7GT2YlewjPjDM5cdAAAAACAK+3cudNxPX6loUOHaufOnQZU5D5mR4hOig4AcL2b6kTv0KGDzp49q4SEBJUqVcqx/YknnpCfn5/TiitUzBkhur9HxqomSSlWI6sBAAAAABRx3t7eOnTokObNm6dDhw7p3XffVfny5bV69WpVqVLF6PJcKmsmupUQHQDgBjfViX7p0iWlpKQ4AvSjR49q6tSpOnDggMqXL+/UAguNzHEuJSyZIToz0QEAAAAALrRx40Y1bNhQ27Zt09KlS5WYmChJ2rt3r8aNG2dwda5lMWfNRDe4EABAsXBTIXqPHj20YMECSVJcXJxatWqlt99+W/fff79mzpzp1AILDUtGU7+fR8YZnIVFAQAAAACu9Pzzz+u1117TunXr5OXl5djesWNHbd261cDKXM8xE52h6AAAN7ipEH3Xrl26/fbbJUlffPGFgoODdfToUS1YsEDvvfeeUwssNDI70f0yO9ETGecCAAAAAHChffv26YEHHrhqe/ny5XX27FkDKnKfrHEuZOgAAHe4qRD94sWLCggIkCStXbtWPXv2lNlsVuvWrXX06FGnFlhoOEL0jPD8IguLAgAAAABcqGTJkjp16tRV23fv3q1KlSoZUJH7sLAoAMCdbipEr1GjhpYvX67o6GitWbNGd911lyTp9OnTCgwMdGqBhYY5Y5yLr2MmOp3oAAAAAADXeeSRRzR27FjFxMTIZDLJZrNp06ZNGjNmjCIiIowuz6Uud6ITogMAXO+mQvSXX35ZY8aMUVhYmFq2bKnw8HBJGV3pTZs2dWqBhUZmJ3pWiH4hOc3IagAAAAAARdzrr7+uOnXqKDQ0VImJiapXr57atWunNm3a6MUXXzS6PJcym+lEBwC4j8fNPOnBBx/UbbfdplOnTqlx48aO7Z06dcpxHlux8I+Z6PGXCNEBAAAAAK7j5eWl2bNn66WXXtIvv/yixMRENW3aVDVr1jS6NJe7PM7F4EIAAMXCTYXokhQSEqKQkBAdP35cklS5cmW1bNnSaYUVOpbs41wI0QEAAAAA7lClShVVqVLF6DLcKmuci51OdACAG9xUiG6z2fTaa6/p7bffVmJioiQpICBA//rXv/TCCy/IbL6pKTGFW9Y4F3PGLPT4i4ToAAAAAADnGj16dJ73nTJligsrMZYpsxPdSis6AMANbipEf+GFFzRnzhxNnjxZbdu2lST9+OOPGj9+vJKTkzVx4kSnFlkoZIboPmY60QEAAAAArrF79+487ZcVMhdVFjPjXAAA7nNTIfrHH3+sjz76SPfdd59jW6NGjVSpUiU988wzxTNEN2d8lN5ZneiE6AAAAAAAJ9uwYYPRJRQIWeNcWFgUAOAONzV35fz586pTp85V2+vUqaPz58/nu6hCKbMT3dtEiA4AAAAAcK/o6GhFR0cbXYbbZC0sSoYOAHCHmwrRGzdurGnTpl21fdq0aWrUqFG+iyqULJ6SJK/MED2OEB0AAAAA4ELp6el66aWXFBQUpLCwMIWFhSkoKEgvvvii0tKK9jWpR2YreqrVZnAlAIDi4KbGufz3v//VPffco++++07h4eGSpC1btig6OlqrVq1yaoGFRmaI7ql0SVJquk3JaVb5eFqMrAoAAAAAUEQNHz5cS5cu1X//+99s1+bjx4/XuXPnNHPmTIMrdB3vzGvtlDRCdACA691UJ3r79u31xx9/6IEHHlBcXJzi4uLUs2dP/frrr/rkk0+cXWPhkDnOxUPpjgVOGOkCAAAAAHCVRYsWaf78+XryySfVqFEjNWrUSE8++aTmzJmjRYsWGV2eS/l4ZsQZKelWgysBABQHN9WJLkkVK1a8agHRvXv3as6cOfrwww/zXVihY87oRDdZ0xTk66nzSamKv5Sm4EAfgwsDAAAAABRF3t7eCgsLu2p7tWrV5OXl5f6C3Mjbg050AID73FQnOnKQOc5FmSG6JMVdpBMdAAAAAOAaw4YN06uvvqqUlBTHtpSUFE2cOFHDhg0zsDLXy+pET6YTHQDgBjfdiY5/yBznImuqAjNDdMa5AAAAAABcZffu3Vq/fr0qV66sxo0bS8r4hXhqaqo6deqknj17OvZdunSpUWW6hE9mJ3pyGiE6AMD1CNGdJasTPTFWlUskaq8I0QEAAAAArlOyZEn16tUr27bQ0FCDqnEvb8dMdMa5AABc74ZC9Cu/xc5JXFxcfmop3IIqSzJJcUf1VsIAHTc9r/hL9YyuCgAAAABQBNntdk2YMEHlypWTr6+v0eW4nTed6AAAN7qhmehBQUHXvFWtWlURERGuqrVgC64vDVgpla4uX9tFtTf/rPiLqUZXBQAAAAAogux2u2rUqKHjx48bXYohfOhEBwC40Q11os+bN89VdRQNYW2l2l2lLdNUwnRJJxnnAgAAAABwAbPZrJo1a+rcuXOqWbOm0eW4HZ3oAAB3uqFOdOSBd4AkyV/JzEQHAAAAALjM5MmT9dxzz+mXX34xuhS38/HMCtFtstvtBlcDACjqWFjU2bz8JUklTJcI0QEAAAAALhMREaGLFy+qcePG8vLyumo2+vnz5w2qzPWyFhaVpFSrzdGZDgCAKxCiO5t3ZoiuZMURogMAAAAAXGTq1KlGl2AYnytC8+Q0QnQAgGsRojtbZic641wAAAAAAK7Uv39/o0swjKfFJJNJstullDSr5OtpdEkAgCKMmejOljkTvYTpkhII0QEAAAAALnTo0CG9+OKL6tOnj06fPi1JWr16tX799VeDK3Mtk8nk6EZPSbcZXA0AoKgjRHc2x8KiGTPRWeAEAAAAAOAKGzduVMOGDbVt2zYtXbpUiYmJkqS9e/dq3LhxBlfnYtZ0+WTORU9OsxpcDACgqCNEd7ascS6mZKVZ7bqYyskcAAAAAOB8zz//vF577TWtW7dOXl5eju0dO3bU1q1bDazMhZITpKVPSl+PcMxBpxMdAOBqhOjO5lhY9JIksbgoAAAAAMAl9u3bpwceeOCq7eXLl9fZs2cNqMgNTu+X9v1P2vOpupo2S6ITHQDgeoTozuaVNRM9RSbZdDoh2eCCAAAAAABFUcmSJXXq1Kmrtu/evVuVKlUyoCI3qNJKuv1fkqR/pcxUJZ1Rchqd6AAA1yJEd7bMTnRJKqFkxcQTogMAAAAAnO+RRx7R2LFjFRMTI5PJJJvNpk2bNmnMmDGKiIgwujzXaT9Wqnyr/JWkJzy+UUo6negAANciRHc2Dx/JlDGXrYSSdZIQHQAAAADgAq+//rrq1q2rKlWqKDExUfXq1VO7du3Upk0bvfjii0aX5zoWT6nhw5KkMqYEOtEBAC7nYXQBRY7JlNGNnhwvf9MlxcRfMroiAAAAAEARYrPZ9Oabb+qrr75SamqqHnvsMfXq1UuJiYlq2rSpatasaXSJrmfxlCR5yqokOtEBAC5GiO4KXgEZIbou0YkOAAAAAHCqiRMnavz48ercubN8fX21aNEi2e12zZ071+jS3MfiJUnyVDqd6AAAl2Ociyt4Zy0uykx0AAAAAIBzLViwQDNmzNCaNWu0fPlyff3111q4cKFstmIUJmcL0elEBwC4FiG6K2QuLuqvSzoVxzgXAAAAAIDzHDt2TN26dXPc79y5s0wmk06ePGlgVW6WOc7Fy5SulPRi9OUBAMAQhOiu4JURopdQsmIvpMhqsxtcEAAAAACgqEhPT5ePj0+2bZ6enkpLSzOoIgPQiQ4AcCNmortCZid6gDlZ1nS7zlxIUUiQz3WeBAAAAADA9dntdg0YMEDe3t6ObcnJyXrqqadUokQJx7alS5caUZ57OBYWTVcyC4sCAFyMEN0VvDJmood4p0np0qn4S4ToAAAAAACn6N+//1XbHn30UQMqMZAjRLcqhYVFAQAuRojuCpmd6ME+aVKSdCo+WU0NLgkAAFeYPn263nzzTcXExKhx48Z6//331bJly+s+b/HixerTp4969Oih5cuXu75QAACKkHnz5hldgvGuGOeSQic6AMDFmInuCpkz0ct4pkqSTrK4KACgCFqyZIlGjx6tcePGadeuXWrcuLG6dOmi06dPX/N5R44c0ZgxY3T77be7qVIAAFDkXBmi04kOAHAxQnRXyOxEL+WREaLHxCcbWQ0AAC4xZcoUDRkyRAMHDlS9evU0a9Ys+fn5ae7cubk+x2q1ql+/fpowYYJuueUWN1YLAACKlKxxLiYrM9EBAC5HiO4K3oGSpEBziqSMcS4AABQlqamp2rlzpzp37uzYZjab1blzZ23ZsiXX573yyisqX768Bg0a5I4yAQBAUXVFJ3oynegAABdjJrorZI5z8VfGGJcTjHMBABQxZ8+eldVqVXBwcLbtwcHB+v3333N8zo8//qg5c+Zoz549eXqNlJQUpaSkOO4nJCTcdL0AAKCIMWd0onsxEx0A4AZ0ortC5jiXEqaMDvTDZ5Nkt9uNrAgAAENduHBBjz32mGbPnq2yZcvm6TmTJk1SUFCQ4xYaGuriKgEAQKGRNc6FTnQAgBvQie4KmZ3oPraLMpmk+EtpOpuYqnIB3gYXBgCAc5QtW1YWi0WxsbHZtsfGxiokJOSq/Q8dOqQjR46oe/fujm02W8YFr4eHhw4cOKDq1atne05kZKRGjx7tuJ+QkECQDgAAMmSOc/GQVclpdKIDAFyLTnRX8A6QJJlTExVayk+SdPB0opEVAQDgVF5eXmrevLnWr1/v2Gaz2bR+/XqFh4dftX+dOnW0b98+7dmzx3G77777dMcdd2jPnj05huPe3t4KDAzMdgMAAJB0eSa6yarUtHSDiwEAFHV0ortCZie6Ui6oZoi/jp2/qIOnLyi8ehlj6wIAwIlGjx6t/v37q0WLFmrZsqWmTp2qpKQkDRw4UJIUERGhSpUqadKkSfLx8VGDBg2yPb9kyZKSdNV2AACA68oc5yJJ6WmpBhYCACgOCNFdIXMmulITVaNcCa3/nU50AEDR07t3b505c0Yvv/yyYmJi1KRJE3377beOxUaPHTsms5kfvQEAABfI7ESXJFs6IToAwLUI0V0hqxPdlq5aZTNO7AfPEKIDAIqeYcOGadiwYTk+FhUVdc3nzp8/3/kFAQCA4uGKTnRreoqBhQAAigPaw1whcya6JDW/+KN8lUwnOgAAAAAAzmK2yG7KiDTsjHMBALgYIbormC2SbylJUtjGEXrPc7piE1KUkJxmcGEAAAAAABQRmSNd7NY02Wx2g4sBABRlhOiu0mOGVLOLJKmx5bAk5qIDAAAAAOA0mSNdPE3pSkm3GVwMAKAoI0R3lTrdpPtnSJLK67y8lKaDsYToAAAAAAA4RWYnuqfSlZJuNbgYAEBRRojuSn5lJE8/SVIF0zntjv7b4IIAAAAAACgaTJkhupfSlZxGJzoAwHUI0V3JZJJKVpEkVTad0ZZD5wwuCAAAAACAIsKcOc5F6UpOoxMdAOA6hOiuFhQqSQo1ndWRcxd1Kv6SwQUBAAAAAFAEWC6H6MxEBwC4EiG6q2V2ojcLTJAkutEBAAAAAHCGrJnoJiud6AAAlyJEd7XMEL2eX5wkQnQAAAAAAJzCwjgXAIB7EKK7mmMm+llJ0tbDhOgAAAAAAORbVic641wAAC5GiO5qJatKkgJTTspiNin6/CUdPZdkcFEAAAAAABRyjhDdqkt0ogMAXIgQ3dUyO9HNF2LUNsxfkvTtLzFGVgQAAAAAQOGXOc7FS+m6mJpucDEAgKKMEN3VSpSVPHwl2dXzloxNqwnRAQAAAADInytmoicmE6IDAFyHEN3VTCapZKgkqX3wJZlM0p7oOJ2Kv2RwYQAAAAAAFGJZ41xM6UpMYZwLAMB1CNHdIXOkS6kfxmti6W8l2RnpAgAAAABAfmR2onvIqqQUOtEBAK5jaIg+adIk3XrrrQoICFD58uV1//3368CBA9d8zvz582UymbLdfHx83FTxTaraJuOfp39T36QFqm2KZqQLAAAAAAD5kdmJ7qV0JRKiAwBcyNAQfePGjRo6dKi2bt2qdevWKS0tTXfddZeSkpKu+bzAwECdOnXKcTt69KibKr5Jt42WnvpRqtRCktTS/Lt2HDmvMxdSDC4MAAAAAIBCKmucCyE6AMDFPIx88W+//Tbb/fnz56t8+fLauXOn2rVrl+vzTCaTQkJCXF2e85hMUkhDqVYX6cRPurPEX/okQVr7W4z6tapqdHUAAAAAABQ+LCwKAHCTAjUTPT4+XpJUunTpa+6XmJioqlWrKjQ0VD169NCvv/7qjvLyr0q4JKmZ9ou56AAAAAAA5IM5M0Q3pSsplRAdAOA6BSZEt9lsGjlypNq2basGDRrkul/t2rU1d+5crVixQp9++qlsNpvatGmj48eP57h/SkqKEhISst0MU7mFZPaUf+oZhZpOa8uhc4q7mGpcPQAAAACAYi0va5UlJydr6NChKlOmjPz9/dWrVy/FxsYaVPEVmIkOAHCTAhOiDx06VL/88osWL158zf3Cw8MVERGhJk2aqH379lq6dKnKlSunDz74IMf9J02apKCgIMctNDTUFeXnjaevVLGpJKlHqaNKt9m19rcC8BcPAAAAAECxlJe1ykaNGqWvv/5an3/+uTZu3KiTJ0+qZ8+eBladKXOci4esjHMBALiUoTPRswwbNkzffPONvv/+e1WuXPmGnuvp6ammTZvq4MGDOT4eGRmp0aNHO+4nJCQYG6RXDZeOb1eE+VslWs7r290BeriFgfUAAAAAAIqt661VFh8frzlz5mjRokXq2LGjJGnevHmqW7eutm7dqtatWxtRdoYrFhZNohMdAOBChnai2+12DRs2TMuWLdP//d//qVq1ajd8DKvVqn379qlChQo5Pu7t7a3AwMBsN0Pd0kGSVD7xd433XKDQI1/q9IVkY2sCAAAAAEBXr1W2c+dOpaWlqXPnzo596tSpoypVqmjLli25Hscto1WvGOdygRAdAOBChoboQ4cO1aeffqpFixYpICBAMTExiomJ0aVLlxz7REREKDIy0nH/lVde0dq1a/XXX39p165devTRR3X06FENHjzYiLdw4265Q3r4E6l6xjf4tU1HtfLnUwYXBQAAAAAo7nJaqywmJkZeXl4qWbJktn2Dg4MVExOT67HcMlo1c5xLVie63W53/msAACCDQ/SZM2cqPj5eHTp0UIUKFRy3JUuWOPY5duyYTp26HDL//fffGjJkiOrWratu3bopISFBmzdvVr169Yx4CzfOZJLq3Sc17iNJqm4+pRV7ThpcFAAAAACguMvrWmV5ERkZqfj4eMctOjraCRX+Q1aIbkqXzS4lp9mc/xoAAMjgmeh5+ZY4Kioq2/133nlH77zzjosqcqMy1SVJt5hOaU90nE7FX1KFIF+DiwIAAAAAFEe5rVUWEhKi1NRUxcXFZetGj42NVUhISK7H8/b2lre3tytLzjbORZIupKTJ18vi2tcEABRLhnaiF2tlakqSypniFaCL2n74vMEFAQAAAACKm+utVda8eXN5enpq/fr1jm0HDhzQsWPHFB4e7u5ys8vsRPc2Z3SgJ6VYjawGAFCEGdqJXqz5BEr+wVJirKqZTmn74fPq0aSS0VUBAAAAAIqRoUOHatGiRVqxYoVjrTJJCgoKkq+vr4KCgjRo0CCNHj1apUuXVmBgoIYPH67w8HC1bt3a2OIzO9F9M0P0xGQWFwUAuAYhupHK1JQSY3WL6ZR2HKETHQAAAADgXjNnzpQkdejQIdv2efPmacCAAZIyxqqazWb16tVLKSkp6tKli2bMmOHmSnOQGaJ7mzPC88QUQnQAgGsQohupTHXp6I+6xXxSy2MT9XdSqkqV8DK6KgAAAABAMZGXtcp8fHw0ffp0TZ8+3Q0V3YDMcS4+5owxLkmE6AAAF2EmupHKZsxFb+xzRpLoRgcAAAAAIK/MmTPRTRkhOp3oAABXIUQ3UubiojU9YiURogMAAAAAkGeZ41y8xDgXAIBrEaIbKbMTPTg1WhGWNdr9yy9Kt9oMLgoAAAAAgEIgc5yLJ53oAAAXI0Q3UsmqkoevLLYUveL5scYkTdGy3SeMrgoAAAAAgIIvsxPdM7MTnZnoAABXIUQ3ksVDenCu1KSfJKmF6YBmr/9ZaXSjAwAAAABwbZkhugfjXAAALkaIbrQ63aT7Z8hWsqo8TDZVjN+jz7YfM7oqAAAAAAAKtsxxLh72zBA9mRAdAOAahOgFhLlaO0lSuPlXvbnmgE5fSDa4IgAAAAAACrCsTvTMED0plRAdAOAahOgFRWaI3tH7gC4kp+u1b/YbXBAAAAAAAAVYZie6xZ4mSbpAJzoAwEUI0QuKsNslSTWsh1TSlKiv9p7Uz8fjjK0JAAAAAICCKjNEN9syQnQWFgUAuAohekERWEEqU1Mm2fV10Nsaalmuaev/NLoqAAAAAAAKpsxxLuascS4pViOrAQAUYYToBUm9HpKk0OQDes7zf4r9fbN+j0kwuCgAAAAAAAqgzBDdZLfKLJsS6UQHALgIIXpB0vFF6cnvpRqdJUn3WzbpjdW/y2azG1wYAAAAAAAFTOY4F0nyVDohOgDAZQjRCxKTSarQWGr1lCTpPssW/XDglKZtOGhwYQAAAAAAFDCZnehSRoh+ITmNJjQAgEsQohdEt9whlSinMqYEtTP/rCnr/tCmg2eNrgoAAAAAgILDnL0T3WaX4i6lGVgQAKCoIkQviCweUoMHJUkfeb2tH7xGaOGKlXyjDgAAAABAFrNZMlkkSWV9TZKkc4kpRlYEACiiCNELqlsHST4lZZZdoeYzuv3vZfr655NGVwUAAAAAQMGROdKlrF9GvHE2MdXIagAARRQhekFVtqb077+kPkskSXdbdmjqmt+Umm4zuDAAAAAAAAqIzBC9XGaIfi6JTnQAgPMRohdkZotU807Z/cqplClRofE7tHjHMaOrAgAAAACgYLBkzEUv55tx9xyd6AAAFyBEL+jMFpnq3SdJuse8Te+tP6iklHSDiwIAAAAAoADI7EQv45M1zoVOdACA8xGiFwb1H5AkPejxvdam9df2z141uCAAAAAAAAoAi4ckqXRmJzoz0QEArkCIXhhUbSOVqyOLbCptSlSjw3P05Y4jRlcFAAAAAICxMjvRS3ln3D1HJzoAwAUI0QsDs0V68gfZh+/SRUuQypgu6Mtl/9Pmg2eNrgwAAAAAAONkheg+JknSuSQ60QEAzkeIXlh4eMlUprp8G3aXJN1l3qGxS3/WpVSrwYUBAAAAAGCQzIVFS3qmSaITHQDgGoTohYxjkVGPn3T8fJLe+e4PgysCAAAAAMAgXv6SpBobh2u4ZanOMRMdAOAChOiFzS0dJK8AldN5LfJ8XR6bp2rzIca6AAAAAACKoTv+IwU3lDk9Wc96LFNiSqqS0/jFNgDAuQjRCxsPb6l+D0lSuOU3/dtjsd5d9JVOJyQbXBgAAAAAAG4Wdps0+DtJkqfJqgBdYi46AMDpCNELo25vSX0/l7VyK0lSy+RNily6z+CiAAAAAAAwgKeP5OknSSppSmQuOgDA6QjRCyNPX6nWXbI0e0yS1MXyk9b/flo/HTlvcGEAAAAAABjAt7QkqaQSmYsOAHA6QvTCrHZXyWRWA/MRVTad0X/XHJDdbje6KgAAAAAA3MuvlCSplClRZ+lEBwA4GSF6YVairFSljSRppOcy+R7doAWbDxtcFAAAAAAAbuboRL/ATHQAgNMRohd2dbtLkh40R+ljrzf088oPNHn17wYXBQAAAACAG/le7kRnJjoAwNkI0Qu7Zo9JLZ+UvWJTSVIvy/eatfGQNh88a3BhAAAAAAC4iV9mJ7opUTEJhOgAAOciRC/svEpI3f4r00MfS5JaW/arvP7WpNW/y2ZjPjoAAAAAoBi4YmHRv84kGlwMAKCoIUQvKkpVlUJbySy7enlt074T8Vq2+4TRVQEAAAAA4HqZneilTIk6dCaRpjIAgFMRohclDR6UJD3lt14venyij5Z+o1kbD8lu5y8PAAAAAIAiLHMmemlTopLTbDoRd8ngggAARQkhelFS/37J7KGg5BMa7LFab1pmavLq3/X8l/tk5Vt4AAAAAEBRlTnOpbzHRUnSIUa6AACciBC9KPEvL/VdIt0+RnaLlxqYj6ie+aiW/BStUUv20JEOAAAAACiaMse5lDEnSZIOniZEBwA4DyF6UVOjs9TpJZlqd5UkTa/3uzwtJn2196QWbjtmcHEAAAAAALhAZid6gD1BEp3oAADnIkQvqpo8KkmqdvIbvdKxrMyy6fVV+3X0XJLBhQEAAAAA4GSZM9G9rUnyUDqd6AAApyJEL6qqd5T8g6WL59Tnhzu10f8/Sk9N1hMLdupcYorR1QEAAAAA4Dy+JSWZJElBSiJEBwA4FSF6UWXxkDo8L/kESZJC04/poRJ7dCD2gvrO3qa/k1INLhAAUBRMnz5dYWFh8vHxUatWrbR9+/Zc9509e7Zuv/12lSpVSqVKlVLnzp2vuT8AAECemS2O699S5kT9fTGNBjIAgNMQohdlLR6Xnj8mtX9ekvRiyFaVD/DWgdgLGvW/PbLZWGgUAHDzlixZotGjR2vcuHHatWuXGjdurC5duuj06dM57h8VFaU+ffpow4YN2rJli0JDQ3XXXXfpxIkTbq4cAAAUSZmLi9byz2ga+5NudACAkxCiFwfNIiSTWb4ntuizB0rL28OsqANnNG3DQaMrAwAUYlOmTNGQIUM0cOBA1atXT7NmzZKfn5/mzp2b4/4LFy7UM888oyZNmqhOnTr66KOPZLPZtH79ejdXDgAAiqTMuegNStskSbuO/W1kNQCAIoQQvTgIqiTV7CJJqv7VA9pUdpIqm85oyro/NObzvUpMSTe4QABAYZOamqqdO3eqc+fOjm1ms1mdO3fWli1b8nSMixcvKi0tTaVLl3ZVmQAAoDjxzfg7RcPSVknS1r/OG1kNAKAIIUQvLtoMk2SSkuNUNm6vpoX9KJNJ+mLncT396U7Z7Yx2AQDk3dmzZ2W1WhUcHJxte3BwsGJiYvJ0jLFjx6pixYrZgvgrpaSkKCEhIdsNAAAgV1njXALTJEk/HTmvNKvNyIoAAEUEIXpxEXabNOZP6f5ZkqQm59doyYBG8vYw64c/z+rzn44bXCAAoDiZPHmyFi9erGXLlsnHxyfHfSZNmqSgoCDHLTQ01M1VAgCAQiWzE7285aJK+nnqYqpV+07EG1wUAKAoIEQvTvzLSY16S6VvkVIS1DJpg0bfWUuS9OrK33TkbJLBBQIACouyZcvKYrEoNjY22/bY2FiFhIRc87lvvfWWJk+erLVr16pRo0a57hcZGan4+HjHLTo62im1AwCAIipzJrpp63Qt93hBZRSvbYx0AQA4ASF6cWM2S80HZvz72pf0xL4+GlF2py4kp+uBGZu04wh/wQAAXJ+Xl5eaN2+ebVHQrEVCw8PDc33ef//7X7366qv69ttv1aJFi2u+hre3twIDA7PdAAAAclXtdsnDV7KmKiz1D3Wy7NLWv84ZXRUAoAggRC+OmvSTPEtIyXEynT2gZ+2fqkklf/19MU2Pzdmm304ycxYAcH2jR4/W7Nmz9fHHH2v//v16+umnlZSUpIEDM76sjYiIUGRkpGP/N954Qy+99JLmzp2rsLAwxcTEKCYmRomJiUa9BQAAUJRUbSONPSy1fEKS1Mj0l7YfPq8LyWkGFwYAKOwI0YujEmWkJzZIvT+V/MrKkhSrJXck6LYaZZWcZtOTn/6kv5NSja4SAFDA9e7dW2+99ZZefvllNWnSRHv27NG3337rWGz02LFjOnXqlGP/mTNnKjU1VQ8++KAqVKjguL311ltGvQUAAFDUePpmhOmSWngd1aU0q5bvPmFwUQCAws5kt9vtRhfhTgkJCQoKClJ8fDw/C5ektS9Km9+XanZR3AOf6r5pm3Ts/EW1qFpK8x9vKX9vD6MrBIBigfPT9fEZAQAKKs5R1+fWz+jvI9K7jWU1eajupTmqFlxa3468XSaTybWvCwAodPJ6fqITvbhr1j/jnwfXqeSyR/Vlg80K9PHQT0f/1sB525XAz94AAAAAAIVJyaqSbylZ7Olq6HlCB2Iv6KejfxtdFQCgECNEL+7K1pSqtZPsNunPNSq3/b/6sruXAnw8tOPI37rv/R/1ewwz0gEAAAAAhYTJJFVsKknqF3pekjT7+7+MrAgAUMgRokPqOVvq/q5UvZMkqeah+fpsSGtVKumrI+cu6qFZW3Ts3EWDiwQAAAAAII8yQ/ROQSdkNklrf4vVnug4Y2sCABRahOiQAkKk5gOku17NuL//KzXwPq1vhrVR49CSupCcrqGLdikl3WpomQAAAAAA5ElmiB50bL3mVlihyqYzemvNAYOLAgAUVoTouCy4fkY3ut0mTWuhUu/X1EedTCrl56l9J+LV/r9RGv2/PTp9IdnoSgEAAAAAyF3lWyWzh5R0Wh3OL9FrnvP048Gz2vjHGaMrAwAUQoToyK5DpOTpl/HvKQkqt/F5vftwI5XwsigmIVlLd51QzxmbdfB0orF1AgAAAACQm4AQaeBqqdM4SVJ7815VNp3WhK9+5VfWAIAbRoiO7EJvlZ4/Jo3cJ3kHSaf2qt3fS7Ujsp0+HdRKYWX8dPzvS+r67vca/tlufb33pE4n0JkOAAAAAChgQltKt4+WqneUSXYN9onSX2eTNOfHw0ZXBgAoZAjRcTWLp1SyinTHfzLur4mU31tVddv5L/Xl023UtkYZpVnt+nrvSQ3/bLfCJ/+fZn//l+x2u7F1AwAAAADwT7cOliT18YzSAMu3WrU+SifiLhlcFACgMCFER+5uHSw17iN5lpCsqdK3kSqT8JsWDm6tb4bfpoFtw1S3QqCsNrsmrtqv57/cR5AOAAAAAChYanaRAivLOzVO4z0XaJ55gl7/ep/RVQEAChFCdOTO4iE9MEv6zwmp/gOS3Sp9OUT6v4lqkLRN47rX16pnb9P47vVkMZu05Kdo/e+naKVbbYq7mGp09QAAAAAAZFzbPjRfajFIVk9/lTMl6NRvm/Q9i4wCAPKIEB3XZzJJ3d6S/MpK5/6Uvv+vtOhh6fD3MplMGtC2mv7dpbYk6ZWvf9Pt/92gFq99p29+Pmlw4QAAAAAAKGP9r3unyFKzsyTpdvM+vbv+T4OLAgAUFoToyJsSZaW+SzJGvITdLskufTlY2veF9MdaDb6tmlqGlVZSqlWn4pOVbrNr9JK9eu2b3/TYnG2atGq/fo9JyPHQf8Ze0Enm0QEAAAAAXK16R0lSe8vP2nn0b+2JjjO2HgBAoeBhdAEoRCq3yLilXpRmd5TO7Je+HCRJstzxgt7r86ymfveHGlUuqagDp7X2t1h9lLnq+Q9/ntUH3/+luhUC1aJqKfl5W9S9UUUdOpOoEYv3KMjXU+tGt1P5AB8j3yEAAAAAoCir0UmS1MR8SIFK1NwfD+u9Pk0NLgoAUNARouPGeflJvT+RVo6W0i5Jx3dIG15XiHegJjcIk8JuUc9mlRS5dJ+SUtLV6pYy2n74nP7v99PafypB+09ldKTP/v4vmU0mSVL8pTRNWvW73undxLj3BQAAAAAo2oIqS2Vry3z2gJ72+FpRvzTTwdM1VKN8gNGVAQAKMJPdbrcbXYQ7JSQkKCgoSPHx8QoMDDS6nKLhm9HST3Mu3y9VTer9qRTSINtucRdTtebXGJ2IS9YfMRf07a8xkqTwW8po6+FzstulxpWD5Gkxa+gdNXRHnfLufBcAYCjOT9fHZwQAKKg4R11fgfqMvo2Uts5w3B3h8ZLGPPOMQkv7GVgUAMAIeT0/0YmO/Lt7smTxyuhIj4+W/j4sfXC7VPoWqc49UseXJIunSvp5qfetVRxP2/bXOf0Re0G9b62iV775VZ9uPaa9x+MlSQPn79Bd9YL10r31VC7AWwmX0uTv4yFfT4tMmd3rAAAAAADcsNbPSImxSj/1qzzO/a4BqZ/p4VlNNGdAS9WryJcgAICr0YkO57p4Xlr2lPTnmsvbbrlDajlECgiRKjaTcgjBk9OsWr77hAJ9PbUnOk5zfzysdJtdHmaTrHa7sv6Ulg/wVstqpTWycy3VKO8vq80us0kFPlhPSE5ToI+n0WUAKMA4P10fnxEAoKDiHHV9BfIzuhAr+9RGMlmT9WhqpHZ5NNGsR5urXa1yRlcGAHCTvJ6fCNHhGgmnpMPfS9+MktKSLm9v9Ih05wTJw1vyLZXr0/+IvaCXlv+ibYfPS8rI3a/8k1ouwFvP3VVb/11zQFVK+2rugFu1+1ictvx1ThWCfBRWpoRK+nlq61/ndSE5Tfc1qag6IZf/9z6dkKxZG/9StbJ+6teqqszmvIXwqek2XUqzKsg374H4G9/+rg82HlJk17oa0u6WPD8PQPHC+en6+IwAAAUV56jrK7Cf0ernpW0zdcnkpwPWEE2x99PQgQPV6pYyRlcGAHADQvRcFNgTd1F1co+04XXp4jnp5C7Jbrv8WM0u0r1TMhZ2yYHdbtdfZ5MU6OOpsv5eSkxJ128nEzTuq1/1e8yFbPuWD/DW6Qsp1ywlrIyfwsqWkJfFrM2HzikxJV2S1LZGGf33wcaqGOSj7YfP6/s/z+jP2EQ1rVJKFUv6aMuhcwoO9FHNYH+9vnK/ziamauSdNfXE7bfIw2JW1v+FsrrhrTa70qw2eZhN2vjHGQ36+CdJktkkLRrSWq3z8Jcxu92uCynpKuHlIYvZJKvNLrvdLg+L+brPvZLNZs/zFwQAjMX56fr4jAAABRXnqOsrsJ9RwilpRispOWO06N92f/Wy/1dD7r1dvVuEcj0FAEUcIXouCuyJuzg4ulla/rT095HL20xmybe0VKW1dMd/pMCKGdt8gnI9TGxCsnrO2KwTcZfUs2klRf1xRv/f3p1HSVWd+/9/nxq7queBnruZ51FQscUhKhGcIg5xiPESl4nXiPnFGDP5DaI3iWjMNaPRxJtEc3PVBBONMWpiUCRKi4qgIIMyNjQ9z1PN+/fHaRpaumloe4TPa61aXXXOrqp9HqrYZz+1z961LSEALp2VSzAcY3dNC5VNQWbkJxPncvLylgqisc4f9ck5SeyubqEtHMXvcTIuM4H32+dkPxrZSXHMHpnC27vraAlGWDg1m/LGAG/urCFm7NHzDstOgB9I8o9I9PLUTaexZns1v3tjN7NHppLgdbFqWyVnTxjBdy6czN3PfcDfN5bRFIiQ4HUxMt3PzqoWosYwKz+FmpYgpfVtzMxP4YJp2Xz+tJG0BKO8t6+ecZkJ5CTHsau6hXtf2Mrr26v4yrnjKUzz8+OXP+RTEzO588JJbCxtIGYMc0amHdM/oYj0H7VPPVOMRERkqFIb1bMhHaNAA9TuIvbcV3GUb+Dd2DiejxZRXzifexZfRKKm5hQROW4pid6NId1wnwiMgVgUanfAc1+BvWsPL2M5YNqV9qKkrjgYdQZ4EzoVaWgLs6+ulam5yWwrb+JXq3dw2Ul5nDm+67nraltCbC1vZG9tK+GondSePzmLXTUtfPvP7/P27joAvC4HF07PYUJWIm9sr6a2JUTR2HQ+rGhi7c5aPje3kCk5SfzghS00tIWP6pCn5yXzvzeeytW/epNtFU343E7awtEuyx7NiPqPm5KTRGl9W0d9HBbEjvCtzkvxUVrfBsCNZ4zmmwsn4nU5j+k9RaTvqX3qmWIkIiJDldqong2LGFVvx/zqLKz2KUkbjY/bUn/JA1+8iPQE7yBXTkRE+oOS6N0YFg33icIYaK6Ehr2w5uew+dmuy/kzYM5iO6GePhYmXghuX59VIxYzPLO+lJ3VzVx/2iiyk+O6LXfgUr5AOMqaHdVs3NfIrMIUfG4n//ygnPQELwunZZOR4CEQjlHbEqIwzY/P46SmOcgNj73dMdr95rPHEoxEaQtFKUjz8+DLHxKNGXxuJz+79iROH5tOSW0re2paGJeZAFisL6kjPcFDboqP1z+q5qcrP6IpYE9Lk5Hgpa411DHi/qwJIzhjXDr//c8PicQMV8zO468b9hOMxDqmiAH7h4NJOUmk+t3MzE/hlnPGEo0ZdlW3MCUnacgv2ipyvFD71DPFSEREhqrh3katXr2aBx54gHXr1lFWVsYzzzzDokWLOvYbY1i2bBmPPvoo9fX1zJs3j4cffpjx48cf9XsMmxjtewfe/T3BHa/jbdjBG9Gp3JX0fX7/pSLyUvquHyoiIkPDsEiiL1++nL/85S9s3boVn8/H6aefzv3338/EiROP+LwVK1awdOlSdu/ezfjx47n//vu58MILj+o9h03DfSIKNILTA1VboPiXdnK9oRQaSjqX8yTY86gn5drzqmdNtZPqmZPBEz84dT9KzcEIj6zawcyCFD49JavTvn98UM4Ta0v4yrnjOHnU0U2zsr++jUde28GUnCSunJNPKBqjKRAh2ecmzm2PLi9raCMcMRSm+9lU2sALG8u4ck4+2yub+e6zmw4b+T4pO5GqpiA1LSHmjEzljHEZbK9s5pxJmVwxO4/yxgCBcIxR6X4l2EX6kNqnnilGIiIyVA33NurFF1/kjTfeYM6cOVx++eWHJdHvv/9+li9fzuOPP87o0aNZunQpGzduZPPmzcTFdT0I6eOGXYxqdhB7eB6OSBth46TCymDjeb/n/HlzcWqedBGR48awSKIvXLiQa665hlNOOYVIJMKdd97Jpk2b2Lx5M/HxXSdD16xZw1lnncXy5cu5+OKLeeKJJ7j//vt59913mTZtWo/vOewa7hNdNALvP2XPp44Fu1dDfUnXZR0uSCmESBDiUiBjHPhSwZ8OWdMgMdtO0meMP+Kc6ycSY+wR59vKm6hoDPCTlR9R39r9NDWTshPZVtGEMZCbHMfE7ETSE7wEwlHyUn1cc0ohI9P8AFqAR+QYqX3qmWIkIiJD1fHURlmW1SmJbowhNzeXr3/969xxxx0ANDQ0kJWVxWOPPcY111xzVK87LGO07nH42//X8fDN2GR+kHE/P/vcyYzOGNoDuERE5OgMiyT6x1VVVZGZmclrr73GWWed1WWZq6++mpaWFp5//vmObaeddhqzZs3ikUce6fE9hmXDLQfFYvZI9ZZqqNgE216E5gp7FHtz+dG/TnymvfKnJ95OuDtc4PJC/AhIyLRv8Zn2XOzhAETaDv41MXD77dHvDje0Vtv7vImH3JLs18PY5Q/cLIc9LY3La79noNHelpxv/w23QqgZLCck5tjPj4YgIRtcnn4K6kGl9W08vGo7M/JSOH1cOr95fRc1zSHSEzz8vnhPxxQwHqeDUDTW7ev43E4+MzOXa04tYGZ+ihLqIkdB7VPPFCMRERmqjqc26uNJ9J07dzJ27FjWr1/PrFmzOsqdffbZzJo1i5/+9Kddvk4wGCQYPHjVa2NjIwUFBcMvRq21tFXvwvXYRbhjbfw5eiY7rJGM/fRNXDZvhvo6IiLD3NG24a4BrFOPGhrsuaLT0rqfyqK4uJjbb7+907YFCxbw7LPP9mfVZKhwOOzpWwDGnA1FSw7uqy+B+r12crul2l68NNgEjaVQvtFOWIdaoGk/tFQOTv17zYK4JDjwk5fDaY+6TxsNaWPshL87Dtrq7R8GRp5uzyXvdIP/6KaGAXvR0e8vmt7xeNklUzvuL5qVx6ptVVw8M4fcZB/rS+rYU9tKbUsIr8vBmh01vLqtEmOgLRzlj+/s5Y/v7GVEopeJWYkUpvu5YnY+swtTCEcNHpejj2IjIiIiIiL9pbzcHqyUldV5OsqsrKyOfV1Zvnw599xzT7/WbUD40/AVpsGF98LzX+MK57+Bf7Pmn+9y1cYHeOjzJ5OVdHRT2oiIyPA1ZJLosViM2267jXnz5h1xWpby8vJjary7+vVbjlMphfatJ6219nzrWHZSPVBvjxIPt9kLnTZXQEuVfT/UYien3X57BLk7rn3EeMAeNR4N2dPFuH12wr7j1mhPK2M5DrlZ9kj6aBAiIYiF7VHrsQg07LPr4/Hbc75HQ/b7gz1iPRaGQEPn42irhbINPR9v2lh7CptoGFJHQfZ0+30PjKYfMQmScnp8mZkFKcwsSOl4fPq4DE4/ZP8XzxxDUyBMOGrYUdXM/xbvYeWWCqqaglQ1BWE7PLG2BLfTImbg83MLWXbJVHbXtOB2OihonwZGRERERESGv+985zudBsAdGIk+bM25AaIRYpVbiK5/gtPZzMrSJ7niF608sngu0/I0ZaiIyPFsyCTRlyxZwqZNm3j99df79HWPm1+/pe/4045pdPagiUXt5DvYSf1AA2DZyfhIAOp2Q+1OqN1lJ9TDAfCl2D8ClKw9OPVM7Q77diSpo+3R66mj7OR/YRGMPdce+X8MEuPcAKTFp3HKqDSCkSgbSuoprW9jzY4anntvP6GIPQ3M48V7eGt3HVvKGnFYsOikPMZlJpDsc3PF7PyOhVFFRERERGTwZGdnA1BRUUFOzsHBNxUVFZ2md/k4r9eL1+vt7+oNHMuCuTfhABzZU+HvX2ep+w8sDf2Bvz5yOt/P+3/cefE0ZuSnDHZNRUSkHwyJJPqtt97K888/z+rVq8nPzz9i2ezsbCoqKjptq6io6GjYP+64+/VbThyOQ5LIB+ZpP1TWVHoUaICSN6Gp3H69qm32Ldxqj7wPNkL1R1C3y74dKjEHkvLsxPrYc+1R/vEZ9sh16+jm/fO6nMwdkw7A5bPzWXbJFBoDEdburOGOFe+xpcy+MiRm4C/vlnY870/v7GPh1GxWf1hFdnIcswtTOGP8CEal+7G6ee9gJEplY1Aj2kVERERE+tDo0aPJzs5m5cqVHUnzxsZG1q5dy5e//OXBrdxgOflG2LkKtvwNgEuda9i/7xGufOQ6frBoGpfPzsepudJFRI4rg5pEN8bwla98hWeeeYZVq1YxevToHp9TVFTEypUrue222zq2vfzyyxQVFXVZ/rj79VvkWMQlw4QFRy4TaIC9b0FJsT2XfCxqnww2ldm30ndg09MHy2dMgIK59jQ0hUUw/Up7HvajkBjnJjHOzeWz80mKc/Py5gquLxpJJGb449slhKOGf22p4L299by3t77jec+stxPs8R4nKX4PRWPT+czMXE4fm47L6aC6OcjVvypmV3ULD39+Dgumdv2jmoiIiIiIHK65uZnt27d3PN61axcbNmwgLS2NwsJCbrvtNr7//e8zfvx4Ro8ezdKlS8nNze1YfPSEY1lw9R8g2AzbXoC/fIkvu/7Gwthb7PxrLhe9tIQzZk3lutNGMjrj6PpKIiIytFnGGNNzsf5xyy238MQTT/DXv/6ViRMndmxPTk7G5/MB8B//8R/k5eWxfPlyANasWcPZZ5/Nfffdx0UXXcRTTz3Fvffey7vvvnvEudQPOJ5WTRfpN6FW2P8utNXB/g2w+3V7ypj6vfY0MYdyuO0kevo4OOk6e6S6PwNGTOjVW5fUtHLH0+8RixkunpFDQ1uEN3fW8M6eWsLRzv9dpcfbCfUPK5r4sKK5Y9s/vnYWGQn68UyGF7VPPVOMRERkqBrubdSqVas455xzDtu+ePFiHnvsMYwxLFu2jF//+tfU19dzxhln8Mtf/pIJE47+nH+4x+iI/rkU1vys4+GG2BiuCS0lgJerTs7n/104hWS/exArKCIi3Tna9mlQk+jdTcvwu9/9ji984QsAfOpTn2LUqFE89thjHftXrFjBd7/7XXbv3s348eP54Q9/yIUXXnhU73lcN9wi/S3QaI9Sbyy1Fyrd+Cd7bvaujD8fTroeMJA9A9J6vtLkSNpCUSoaA+yra+OlD8p4YWM5tS2hjv0ZCR5S/B62VzYzOiOeaXnJnD42nU9PyVJCXYYFtU89U4xERGSoUhvVs+M+RpVboKEU85cvYbXV0uJIYH8kmQciV/GObx6fn1vI54tGkpkYN9g1FRGRQwyLJPpgOO4bbpGBFItB4z575Pr2f8EHf7Gnh6nbbU/3cqjkQohLgtyT4Ly7Dp/j/RhFojHe3FnLlrJGKhoDXHNqAaGI4YqH19AWjnaU87gcLL9sOudOymTtrhqKxmaQ7NMoEBl61D71TDESEZGhSm1Uz06YGO0phv+7EkL2lbJhXNwaupV3YhNp86Ry89njuPbUQkYkaqCPiMhQoCR6N06YhltkMFVvh9fuh9qdYGJQ/n7npHpcsr1gqdMDp3wRpl1pzyt46GKqvVTW0Mb6knp2VDbz4qZyNrcvXupxOghFY2Qmevnyp8ZS1RQkM9HLxTNzDxupbozhybf2srmsgW9fMJkE75BYg1mOc2qfeqYYiYjIUKU2qmcnVIza6qFhL7z+Y9j0547NxdEpfCl8Oy2Wn1NGpXHXxVOYlpc8ePUUEREl0btzQjXcIkNFWz1UbrbnWF91n51U70r+KTD2XDAGMifDlEXgcPT6bWMxw4Mvf8gvXrUXSUrwumgORg4r53E5SPa5OWVUKrMLU9lZ3cITa0sA+MzMXL505hj+/O4+Pje3kAlZib2uj8iRqH3qmWIkIiJDldqonp2QMYqG4W9fhY1PQzQIwGbXZP637XRKTCZvMp3LT8rnstl5FI1J73bKWxER6T9KonfjhGy4RYaSaBh2vmaPUK/YCGt+bifXu5IzE6Z/FvLmQGGRPVq9F94tqcPjdDAuM4GHXt3OO7vrGJURz+ayRt7bW9/t8xwWxIz9tsbYi5auuLmIMSMSOsoYYwhFY3hdn3wUvZzY1D71TDESEZGhSm1Uz074GO3fAI9/BoINHZt+HL6Cn0avAGBaXhK3nTeBcydl4nAomS4iMlCURO/GCd9wiww10bC9YGmoGT58qX2UugUfPAuhpoPl8ubAxAsgGoHJl0D2tD55+9qWEG3hKPvr21i7s4YP9jdS0xziC/NGsaemlftf2gpAit9NfWuY7KQ4bjlnLJNzkthS1sij/95JfUuYBz47k4XTsvukTnJiUvvUM8VIRESGKrVRPVOMsBPpb/zEvlJ356sA7IyfyY5mLw+FLmaDGUdBmo/LT8rn/KlZTMlJ0uh0EZF+piR6N9RwiwwTzVXw7uNQ9p69aGm49eA+y2En0o2B9HEw92ZIzOrzKsRihiffLmFEgpfZI1O56pFidla3dFv+0lm5zMxPYXJOEvFeJx9WNDMpO1HzHMpRUfvUM8VIRESGKrVRPVOMPubfD8LKezoehi0v95rFbA2N4IPYKBqJp2hMOjedPYbCND+FaX7czt5PdSkiIl1TEr0barhFhqHmSnjr19BUBi3V9oj1Qzm9kDUFRkyCGVfDqDPB2feLgTYHIzz9zl5WrNtHSzBCWryHz8zMZXdNK4+t2d3t8z4zM5elF09hRKK32zIHbNzXQHljgPmTMzXq5ASj9qlnipGIiAxVaqN6phh1oeRNqN0FHzwDH/2jY3OzI4l7Qp9ndWQKNSQRwUWq383CaTnMzE9mZHo8mUleJdZFRPqAkujdUMMtchzYswZ2vw6eePuEc9/bh5dxuGH0WfZCpaEWyJ8D4+b3W5XWbK/mzV21bClrZEtZI62hKIVpft7bV2+vk5ro5bq5I3ntw0rmjknnmwsmsrW8ibKGNs6ZaCfM//befr72xw1EYoZll0zhspPyeHt3HWeOzyDOrTnXj3dqn3qmGImIyFClNqpnitERRCOw6l748B/QWmMPHmrXRDwPxa7gr6FTCOGihoNXuSbFuThvchZfOnMMU3IVUxGR3lASvRtquEWOM8ZA1Vao2QE7V8H7f+q0WE8nM6+1E+n+NBh9Njj6PzG9qbSB2/+0gQ8rmjttv+ykPP7+fhmhaIzb5o8n3uPi3he3cOB/ZIcF8V4XTYEIMwtSuPmsMTz33n5mFaTwxTPH8I8PyqlrDXHtKYVaeOg4ofapZ4qRiIgMVWqjeqYYHaVIyJ43/a1HobUaTKzT7vfjTuZp5lPVangnVEgVqVgWTMlJorS+jQmZiVx5cj6RqCEai1HQPhVMXqoPj9PRcbVrYyDM1rImZhem4NJodhE5gSmJ3g013CLHuWgEgo3QUmWPUq/cDJYTNj/b+QQ0fTxMXQSJ2VBwGmRNhX6aPqU1FOF7z29mW3kTY0Yk8PS6fd2W/dzcQoLhGH9+1y5jWfDx/6VHJHqpagoCsHBqNj++ehY+j/2DwAf7G/jt67uZOyaNz87J7zQljDGG2pYQ6Qk9TysjA0/tU88UIxERGarURvVMMeqFWBTW/wFWPwDNFRANdd7tcPNO/KdYVxdHrUlkdWwG200eUbofLJTidzMlJ4kNe+tpDUWZmpvEf549FmMM+ak+puYm6ypYETmhKIneDTXcIieoPcWw5ucQarIXKw18bLS6PwPSRkPubJh0kZ1U96f3eWLdGMNdf/2A/31zD1fOyScvxcdPV36E1+Xgrkum8LlTCwlFYzy6eid5qT5m5qdw8x/Wsbe2jQumZfPipnLawlHi3A5iMQhFY8wqSOEnV8/iV6t38NTbezuS7teeWsiyS6YQ53ayt7aVr694j7d21XLDvFF896IpODWCfUhR+9QzxUhERIYqtVE9U4z6QO0ueP1B2L/BTqhXbe2yWLOVwFbfbD6Km0Z1q+GdlgyKw+MI4e5UzumwiMY6p4Q8TgdT85LIS/HRGoricTpIiHOR4HUxdkQ8n5mZR1MwzJ6aVmYXphLndlDeGCAaMyR4XcR7XYQiMaqagqTGe0j2dX7P1lCEysYghWn+fr2i1hjDxtIG3E4Hk3P0eROR7imJ3g013CJCoBHee9I+6azbY8+xHmk7vJwvDSZeCHknQVyKPcd6QmafVKGiMUBWUhzGGIp31pCf4qcw3d9l2WjMEInF8Lqc7Khq5sWNZVw6K4+yhgA3/e871LeGO5U/bUwaa3fVYgwUpvmZMzKVl9qT7wfMn5zFr66fQ2sowhvba/jUxBHEue3Xz4j3kux3f7wan0goEsPjGv6XiRpj+m3BV7VPPVOMRERkqFIb1TPFqB+UrIWtz9sj1mu2w67VXfdrAGM5weEi4kmiLGkm7rQCkpJT+dv+JNY3xONzxniv3sd7rWnE6P683eWwiLQn3hO8LlL8bvbVdf2eYI9897mdeFwOHJbFnpoWYsaez/2UUWnMHplKTXOIndXNVDUFcTosspLiaAqEaQlGyUvxUd8WYlNpI3kpPmaPTCE/1e43VTUFSfV7SI13s78+QFsogtPhwOmA9SX1vLOnDoB549K5bu5IxmcmsPqjalqDEUYkeqltDRGNGj49NYtAOMarWyupaw0RjRlS/R6ixtAUCJMU58bvcVLfGsbtcpCV6GVGQQr5qT62ljURicVI8XswBiobA2wsbSDJ52ZWQQofVTTRGIhw5vgMPC4Hu6tbmZyTyMj0+N7+q4tIH1MSvRtquEXkMOE2qNwCdbtgxyuw41VoLD28nOWE/FPsEerZ02DKpZCUB54EcLoGvt7Ajqpmbvjd25TUtjIy3c8Pr5jB3DHpvLq1km//5X0qGoMdZU8dlcYls3L5/vObCUZi3Hf5dP787r6OxUtPKkjhZ69sx+20mJ6XTF17cn58ZgIelwNjYGS6n2Sfm0A4xiUzcxgzIoGWYIRIzHSMMtle2cRfN+zHsizmT87kv//5IcU7avjmwol8/rSRvL+vgTEj4sk4ymlljDGs2laF1+Xg9HEZfR/Eo6zDt/78Pmt21PDr60/ul4Wb1D71TDESEZGhSm1UzxSjAXBgasvaXbDt73ZiPRqGfW/b010eBWM5iVkOgq4kGpMmEHTGE45Z1Lgyeb/OQ2lTlDormYB3BNWtUQJ4qbeSwOEkHInRhpdWvLjddp+hK26nRTja/6koj8tBLGY6kv5DSUaChySfm3iPiySfi5MKUhmZ7md7VTMJHhfjsxJpC9s/CswdnYZlQWldG/FeFyk+N8l+Ny6Hg5gxuDWnvcgnoiR6N9Rwi8hRiQRh71uw9e/QuA/qS+xpYLpiOexkevYMe7T66LMgc3K/zbH+cQ2tYd7YUc2nJo7A7zmYzG8JRni8eDdVTUEump7DnJGpWJbFo6t38oMXtnzik9dUv5vll0/nu89+QH1riHnjMihraDtsEdVDeV0OgpEYbqfFuZMyyUjwEud24nU5aAtHiUQN2clx5Kf6yEn2EYnG+N839/DipnIArj21gKUXT8HvcdEaiuCwLOLcTowxNAUjOC0Lt9M+mdxS1khVU5AJWYmf+HLRAzEDGJXu57mvnEFSnP2jQVlDGznJvl6/9gFqn3qmGImIyFClNqpnitEgisWgqQwwUL8X9r0FbXX2rXyTvYCp02Pv62Yk+zFzxRFzxxN1xmGwiDo8RDzJeOLicLtctIQMDYEojcEoTpcHv8+Hx+MlYrlpjTpwur04XR6agyFcDouMBC/NgRA1zSGaQ1HAwudx0RaOEYgY4r1uO2luLGKA2+ViUk4SMQMbSxv5sLKFpmCUvFQ/iXFumoIxfB4XwUiMHdUtWJaDsZmJpMZ7sSyL1lAMLAdet5NAJEYoaojzuAkZJxVtDjZXR6gJOklNtueQb2kL0OpMxIpLZnx2ImWtTt4sizE2K4kEr4t/f1SNw7LIT/WxvbK5TxP7mYlespLiAHvkf0Gan4JUP5mJXnweJ1lJcRSk2v2V+PYpd0TkICXRu6GGW0R6rWYH7F8PrbWwY6U9av1ji/t08GfA6DMhcwrEj7BvGRNgxISBrXMXgpEon35wNSW1rQBcPjuPv79fRiga478+M5WisRlsKm0gKymOaMywvbIJgz2tzK7qFtpCUTbtb+g2We50WJwzcQTNwQhv7qxlam4S8ydn8YtXtxONGZLiXDQGIsdUZ5fDImoMxkBBmo8LpuXwf2/uweV08Nk5+by+vZqt5U3dPj8vxcfls/NYu7OW/Q1t/Pzak6hsCnLPcx8wPT+ZCVmJ/P39MvJSfdx18RQe/fdO3t5dx9TcJJwOi7+/X0YkZoj3OGkJRZk3Lp3/d+EUHn5tB6u2VvLy7WeTnRx3TMf0cWqfeqYYiYjIUKU2qmeK0TAQi0JzJZgoNFVA5Qf24KJoyE6wt9Xaj5sr7ZHtJgqhFmipPvgaJtr9659w2gfxWA6MJx7cfiyPn6jLT8DyEnH4CLgSaXAkU94QpDHiJJY6itpoPKVNUULedCoifrZUtFJHIvFJaQTCURrawvQ2B+92Wpw1fgQOh8W+ujYK03zkpvgwBsZmJjC7MIX61jCtoShp8W5S/R7S4j0kxbm7HZTUFAjj97i05pYMW0qid0MNt4j0GWPsyyNba+ypYPautech3FPc/QiOCRfAhPPBkwijzoCknIGtc7uXNpVz8x/WMTM/mT9/+XRK69toCUaPepqSyqYAlz20htL6NuaMTGXpxVNYu7OG3BQfZ47PIMXvAaC8IcCIRC9Oh8WWskZaQxFOKkhl0/4GinfU0BaOEgjHCEai+NxOHJbF/oY2SuvaKG8M4HE6yE3xccf5E2kKhLljxXvsbwgcVR3T4j1kJ8WxvaqZUKTzpaSJcS4C4egxjcS/ZGYuN54xmqt+Vdzp9ZwOix99dgaXnZR/1K/VFbVPPVOMRERkqFIb1TPF6AQRCUGo2U6uh1og3AIGu3/UVmf3n0zs4C0WhVjY3h4N2wn7A39jYcBqv8L3QELasvthJgYY+z7tjw+ktw7bZnp4jrHreNj+jz3HxOy6hVvtKUHDrfYN7Kk/A/X2+lvQdyP6D+VNBsvCuOKIpozCeJOJOVw0erJocKVhLCfVjgw+jOazvylKRZuhIprEnoYo+xsCHaHrDafDItXvbp+D3kNa+9+PKpp4Z08deSk+bjprTMf0nznJPrKSvP22npRIX1ISvRtquEWk30VCULoOdr8ODSX2yIzmCnsUuzk0mWtB9nRIKYTkfHtKmOQ8e/R65uR+r+bm/Y0UpPlIjOvdIqL769tY/WEVn5mV22kamf7UEozw45c/5O3dtdwwbzSWBS9uLGdqbhKfm1uI3+MiFI0RixlS/G4syyIQjvLs+lJWbq1kWm4yqz+qYl37IkMXTMsmJ9nH/vo2zpowgiffKmFjaQN5KT6+uXAie2tbsSyLKblJnN0+YmPz/ka+88xG3ttbz6TsRH545Qxm5Kd84mNT+9QzxUhERIYqtVE9U4zkhBIJ2T8agN0HDLce8sNCe/I91GqP7m+tscuFWuz57INNEAlASyW0NUAsYv8Y0VuWE+PyYmVNpdFfSHl9C8G4TJwjxlPVGqMu7KLRk8HmyhA7qltpTRiJKy6RutYwtS0hmoPHdhXxAZmJXk4qTKGmOYTDYTGrIAWP00EoGiMz0UtavAeHZdnzvPvdpPjc7K5p5Z3dtUzKSeSCaTnsq2vF43RSmO7v/fGL9EBJ9G6o4RaRQVO9HdY+Ao377TkJ97/bfdnc2ZAzAxwuezHT/FMgLhl8aeBwtI/gMODyDFz9jxMNbWHu/MtGMhI8fPfiKZ0W4glGohTvqGHOyNQj/rgQjRm2ljcyISuxzxbyUfvUM8VIRESGKrVRPVOMRD6BYJPdj8SCUJOdbA+32tPr1O+Blho72V67E2o+ah/9H4BosBdvZkFSLsSlQEoBkdQxBCOGVstPdfx46iMemoNh9ppMrJRCzp2Sw7+2VPKPTeU0BSM0tIaoaAoS/YTzvjsdVsdrTM9LZs7IVLKT44gZQ2VjkJLaVkalxzN3TBoZCR4S49wkeO0rjmPGMCo9HpcWXZWjoCR6N9Rwi8iQ0VAKZRvsv43tt4Z9sO+d9ksXu+BNhtRCqP7ITqKPOw+ypoE/HcacDSMmDdiCptK31D71TDESEZGhSm1UzxQjkQFmjD3FTDhgJ+HLNtiJeIfT7nfW7rJHyYdaoGk/RCN24r21uqdX7swVBwlZ9tXVDhd4Eogk5lLZHKGmNUwkcwbVcYVsr2qh2Z1B0DuCsqYgjW1hjIGmYIT61hB1LSFS/B5OGZXG6o+qqGoK4nM7CUdjvVqI1ed2Mj0/mel5ybSGogQjURZMzSbR6+Lt3XVMyEpg9shUNu5r4NVtlazbU8fU3GQ+NXEE++raiPc6OXV0Gs2BCE3BCDPzU7CAndUtjB0R3zGFqQx/SqJ3Qw23iAx5zVWw+Vn78r9gI+x8zU6aH828er408KdB9gx7zvVwG7jjoOA0yBgPLm+/V196R+1TzxQjEREZqtRG9UwxEhkmmiuhYS+01dsj2+t2g+Wwpymt2GSPeI9F7XXBoqFjf313PPhS7CutvUkQl3TY/YhvBNUkk5GcQDN+Vpd5+LAhRnmzwXK6SY33kJ/qY/P+RjaWNtAYCNMUiNAciOBzO4kaQ2uo/xa5tSyYkZ/CWeMz8DgdbNrfwKbSRhrbwswZlcrJI1MZl5lAYyDCjspm3ttXT7zHxbxxGVx2Uh6p8R721LTgsCwK0vw0tIYprW9jRKIXt9MiGIkR53a2rxsGlmV1/O1JNGZwOiyMMVQ2BYn3ukjwDsz0q/2lKRDG53b225UFSqJ3Qw23iAxb0TBUbYW6PfaI80gAPnwRmsrtbbtW93y5ni8VErIhMQviM6Glyh5pkDUNRp4O4xfYo9qjQXD7Nap9AKl96pliJCIiQ5XaqJ4pRiLHmVjUHvgVaobGMns0eyxmj35v3G+Pco8EYN/b0FQBJmqvFdZpnbBe8Kfbg8ecHnt6U1ecPfWML7X9lkIsLoWKsI8d9YbddWEiSXmUW5n89f0qwsZi7pgMNuytp7S+jTEj4ikak87cMem8/lEVW8qaGJURT01zkPUl9aTFe/C6Heyssuelz0jwUt3cm2lybIlxLqblJlO8054LvyDNR2ldG0c72D7V7+bC6TmEIjHeLakj2efG73FR0RigvDFAUyDCiEQvFlDZFMTpsJiYlUhLKEIoEiM/1V4XzWGBw7JwWBZOh4XDYSfqnZbVkazfXtXM7uoWxoyIZ2Z+CjPyk2kJRdlf30Zeig+f20lJbSuBiP2DhcXB/IFlgcthkZviw+tyUNYQYExGPCcVplK8s5qqpiBZSXE0ByM0tkWYkpuE1+Vg474GLMuOU0swyqvbKvn3R9WMSPTy2Tn5zB2Tjsth8f6+BkYkerlyTn6v/y0OUBK9G2q4ReS4dWAhmtZqO6Fe9p79i35rrX3iEmo+ttdzuO0TlPgM+2TEnw7p4+zHkSC4fe0nKyn2iYtl2YujJuVBc7mdhE/I7I8jPS6pfeqZYiQiIkOV2qieKUYiQiRoTyUTqIdAIwQa7KuvA43tfxvsW3OFPfI9FrET9U3l2BO994H26WeMNwHjjMPh8dtXbLt9kJhjT01jOez+bHyGvd3poTniwHJ5iPf7qW6Dd/Y183ZJM23OBMYU5DM1L4XEOBdv7qxhU2kDO6tbSPa5GZnuZ0ZeCnWtIZ5ZX8rW8iaAjpHlB+Z9T/W7qW+f4ubQ+eA/CYfFUSfnh6NTRqWy4ubTP/HrHG37NLzH84uIyEGeeMieZt8f86nO+4w5ePLRXG6PBGipbP8VPxX2r4cdr0DpuoPPiYXtss3lva9T5hQ7qe7y2jen9+D9jscecPkgpRBSR9p1bamC+hJ7vj5PQvstHrzt9w8k9S3LHgHRXGnP8+dPs/c5nEeu14Hfj3sz0j4Ws5+nUfoiIiIiIiJHz+WF9LHH/rxY1J46JtQKTWV2wj0StLeF2+ykfFtd++2Q++E2u1zdbntBVrBHx9fvwQKOpUeXcMj9DGBh+w2AHS47Oe+KY1r8CHC6wRGBmA8a4qEtEVxevlToZk9imNpAjHE5aXg9XipaDCkZWSSnZRJp76a6LIswTkLGhXG6MU4PMYcb43Czqy7M67sacbs9nDQynUDUojUC6Yl+RiT7SfTHUdkUJWgMk3LSqGmLsrm8hZR4H26Xg311bbSF7MVXo8YQMxCLGaIxQ8wcuNnTwuSn+hg7IoEdVc1s2FvPptIGErwu8lLt0fPBSIyR6f6O6WIOdLMP5O2DkSh7a9sIRWJkJnlZt6eOfXVtTMpOZEJWIuWNARK9LvxeF+/vqycUiTEzPwWPy0FTIIzf62JMRjyXz87ng/0N/OODCj4obSBqDNPykjl1VNqxfpI+EY1EFxGRg9rq7cvrnG77fmuNfWurs0cDVH9oJ6udXgi32GUC9RAJ2Zfn1ZfYJyWuOPtkpa9GC3TFl2a/T3P7pYEdLHsEvsNpt+ImZtfDcHBO+NYa8CbaSf5gk318Lq/9em775IdYBOr32qveWw77FgvboyScbogfYV9C6HDBooeh4JRPdDhqn3qmGImIyFClNqpnipGIDBpj7MR7LGr/baqw+7PhgL32WLjNTtA3ltoj4MHe31Jt92+jIbvPGz3k1pHEbx3cYzsWlsPuvzpcYDntPrPDZfdvnW77vonZA8dM1C7jdNv9Xqer/a/nYDkTs2N64P6B97Daf6Lo+GtvM9EwsWgYZ1xie587ave7Tay9bk77PU3s4PaPp60PHcyWNQ0uuO8Th0Uj0UVE5Nj5Ug7e9yZCSsGxPT8WtS+/86Xa08iUFNuPO048Au0nH0H7pCMStLeFW+1FaxpK7QbZl3pwVHqo2Z6q5tC/gUZoqz34vpYDPIkQbADaV6HvyqFT1wXqoWTNsR3fAdGQfYLV8bj3c+KJiIiIiIhIP7LaB1qBffVy6qi+e+1I8GCyPdxqX1Udi9r92kgAgs32KPgDSfhYGKKRg/cPPD/QcDBBbIydRD40aR8NH5LAD7Uv8Bo5mHA+sOCrOcKCqiZ28DUGgQX0cM34sRngceFKoouISN9xOO2TEoD4dJh8cf+8T7gNqrbZJwiJufbc6w6nfTLSVmsn8DEc/NW7fRXvSMB+jj/DPrmp/sj+4cCX1n4y0n65X7jNfk5ygf1jAu0j2i2nXT4SsJ8fjdivlzmlf45TREREREREhi6XF5LzBrsWBx24GvvQxHpXyfYD26Lh9sR+2N5mOdpHqTvsEekdif9DE/nhQ0aOt5c/9AcAzCF/YwfvO9z2c4LN9kC0A6PhLUd7vaPtP0A4D9bhQF++47UPEZ8xQEG1KYkuIiLDj9sHubMO3+502Qn1o1nQNDmv69c4WimFvX+uiIiIiIiISF+zrIPJabyDXZvjiqPnIiIiIiIiIiIiIiIiJyYl0UVEREREREREREREuqEkuoiIiIiIiIiIiIhIN5REFxERERERERERERHphpLoIiIiIiIiIiIiIiLdUBJdRERERERERERERKQbSqKLiIiIiIiIiIiIiHRDSXQRERERERERERERkW4oiS4iIiIiIiIiIiIi0g0l0UVEREREREREREREuqEkuoiIiIiIiIiIiIhIN5REFxERkV576KGHGDVqFHFxccydO5e33nrriOVXrFjBpEmTiIuLY/r06bzwwgsDVFMRERERERGR3lESXURERHrlj3/8I7fffjvLli3j3XffZebMmSxYsIDKysouy69Zs4Zrr72WG2+8kfXr17No0SIWLVrEpk2bBrjmIiIiIiIiIkdPSXQRERHplQcffJAvfelL3HDDDUyZMoVHHnkEv9/Pb3/72y7L//SnP2XhwoV84xvfYPLkyXzve99j9uzZ/OIXvxjgmouIiIiIiIgcPSXRRURE5JiFQiHWrVvH/PnzO7Y5HA7mz59PcXFxl88pLi7uVB5gwYIF3ZYXERERERERGQpcg12BgWaMAaCxsXGQayIiInLQgXapsbGRxMRELMsa5BodWXV1NdFolKysrE7bs7Ky2Lp1a5fPKS8v77J8eXl5l+WDwSDBYLDjcUNDA6A2XEREhp4DbdOB/qYcTn1xEREZio62DT/hkuhNTU0AFBQUDHJNREREDldQUEBDQwNJSUmDXZVBt3z5cu65557DtqsNFxGRoaqmpobk5OTBrsaQpL64iIgMZU1NTUdsw0+4JHpubi579+7tk1F+jY2NFBQUsHfvXiU7+oDi2XcUy76jWPYdxfLIjDE0NTWRmJhIYmLiYFenRxkZGTidTioqKjptr6ioIDs7u8vnZGdnH1P573znO9x+++0dj+vr6xk5ciQlJSVKUPQRfS/7nmLa9xTTvqeY9r2GhgYKCwtJS0sb7KoMWeqLD02KZd9RLPuOYtm3FM8jO9AXz83NPWK5Ey6J7nA4yM/P79PXTEpK0oewDymefUex7DuKZd9RLLs3nBLDHo+HOXPmsHLlShYtWgRALBZj5cqV3HrrrV0+p6ioiJUrV3Lbbbd1bHv55ZcpKirqsrzX68Xr9R62PTk5WZ+hPqbvZd9TTPueYtr3FNO+53Bo2bHuqC8+tCmWfUex7DuKZd9SPLt3NH3xEy6JLiIiIn3j9ttvZ/HixZx88smceuqp/OQnP6GlpYUbbrgBgP/4j/8gLy+P5cuXA/DVr36Vs88+m//+7//moosu4qmnnuKdd97h17/+9WAehoiIiIiIiMgRKYkuIiIivXL11VdTVVXFXXfdRXl5ObNmzeKll17qWDy0pKSk04i8008/nSeeeILvfve73HnnnYwfP55nn32WadOmDdYhiIiIiIiIiPRISfRPwOv1smzZsi4vNZdjp3j2HcWy7yiWfUexPD7deuut3U7fsmrVqsO2ffazn+Wzn/1sr95Ln6G+p5j2PcW07ymmfU8x7XuK6cBSvPuOYtl3FMu+o1j2LcWzb1jGGDPYlRARERERERERERERGYq06omIiIiIiIiIiIiISDeURBcRERERERERERER6YaS6CIiIiIiIiIiIiIi3VAS/RN46KGHGDVqFHFxccydO5e33nprsKs05N19991YltXpNmnSpI79gUCAJUuWkJ6eTkJCAldccQUVFRWDWOOhY/Xq1VxyySXk5uZiWRbPPvtsp/3GGO666y5ycnLw+XzMnz+fjz76qFOZ2tparrvuOpKSkkhJSeHGG2+kubl5AI9iaOgpll/4whcO+5wuXLiwUxnF0rZ8+XJOOeUUEhMTyczMZNGiRWzbtq1TmaP5XpeUlHDRRRfh9/vJzMzkG9/4BpFIZCAPRYaIY21bV6xYwaRJk4iLi2P69Om88MILA1TT4eNYYvroo49y5plnkpqaSmpqKvPnz9f5TRd6ew741FNPYVkWixYt6t8KDkPHGtP6+nqWLFlCTk4OXq+XCRMm6Pv/Mcca05/85CdMnDgRn89HQUEBX/va1wgEAgNU26Gtp3PHrqxatYrZs2fj9XoZN24cjz32WL/X80ShfvixUz/8k1FfvO+oL9431A8fHEqi99If//hHbr/9dpYtW8a7777LzJkzWbBgAZWVlYNdtSFv6tSplJWVddxef/31jn1f+9rX+Nvf/saKFSt47bXX2L9/P5dffvkg1nboaGlpYebMmTz00ENd7v/hD3/Iz372Mx555BHWrl1LfHw8CxYs6NT5ue666/jggw94+eWXef7551m9ejU33XTTQB3CkNFTLAEWLlzY6XP65JNPdtqvWNpee+01lixZwptvvsnLL79MOBzm/PPPp6WlpaNMT9/raDTKRRddRCgUYs2aNTz++OM89thj3HXXXYNxSDKIjrVtXbNmDddeey033ngj69evZ9GiRSxatIhNmzYNcM2HrmON6apVq7j22mt59dVXKS4upqCggPPPP5/S0tIBrvnQ1dtzwN27d3PHHXdw5plnDlBNh49jjWkoFOLTn/40u3fv5umnn2bbtm08+uij5OXlDXDNh65jjekTTzzBt7/9bZYtW8aWLVv4zW9+wx//+EfuvPPOAa750HQ0546H2rVrFxdddBHnnHMOGzZs4LbbbuOLX/wi//jHP/q5psc/9cN7T/3w3lNfvO+oL9431A8fJEZ65dRTTzVLlizpeByNRk1ubq5Zvnz5INZq6Fu2bJmZOXNml/vq6+uN2+02K1as6Ni2ZcsWA5ji4uIBquHwAJhnnnmm43EsFjPZ2dnmgQce6NhWX19vvF6vefLJJ40xxmzevNkA5u233+4o8+KLLxrLskxpaemA1X2o+XgsjTFm8eLF5tJLL+32OYpl9yorKw1gXnvtNWPM0X2vX3jhBeNwOEx5eXlHmYcfftgkJSWZYDA4sAcgg+pY29arrrrKXHTRRZ22zZ071/znf/5nv9ZzOPmk5yuRSMQkJiaaxx9/vL+qOOz0JqaRSMScfvrp5n/+5396bGNORMca04cfftiMGTPGhEKhgarisHOsMV2yZIk599xzO227/fbbzbx58/q1nsNRV+eOH/fNb37TTJ06tdO2q6++2ixYsKAfa3ZiUD+8d9QP7zvqi/cd9cX7jvrhA0Mj0XshFAqxbt065s+f37HN4XAwf/58iouLB7Fmw8NHH31Ebm4uY8aM4brrrqOkpASAdevWEQ6HO8V10qRJFBYWKq492LVrF+Xl5Z1il5yczNy5cztiV1xcTEpKCieffHJHmfnz5+NwOFi7du2A13moW7VqFZmZmUycOJEvf/nL1NTUdOxTLLvX0NAAQFpaGnB03+vi4mKmT59OVlZWR5kFCxbQ2NjIBx98MIC1l8HUm7a1uLi4U3mwPztqM2x9cb7S2tpKOBzu+E6f6Hob0//6r/8iMzOTG2+8cSCqOaz0JqbPPfccRUVFLFmyhKysLKZNm8a9995LNBodqGoPab2J6emnn866des6psXYuXMnL7zwAhdeeOGA1Pl4o/apf6gf/smoH94/1Bfve+qLHzv1wweGa7ArMBxVV1cTjUY7fdAAsrKy2Lp16yDVaniYO3cujz32GBMnTqSsrIx77rmHM888k02bNlFeXo7H4yElJaXTc7KysigvLx+cCg8TB+LT1WfywL7y8nIyMzM77Xe5XKSlpSm+H7Nw4UIuv/xyRo8ezY4dO7jzzju54IILKC4uxul0KpbdiMVi3HbbbcybN49p06YBHNX3ury8vMvP7oF9cmLoTdva3WdHnxtbX5yvfOtb3yI3N/ewZNCJqjcxff311/nNb37Dhg0bBqCGw09vYrpz505eeeUVrrvuOl544QW2b9/OLbfcQjgcZtmyZQNR7SGtNzH93Oc+R3V1NWeccQbGGCKRCDfffLOmc+ml7tqnxsZG2tra8Pl8g1Sz4U398N5TP7z/qC/et9QXP3bqhw8cJdFlQF1wwQUd92fMmMHcuXMZOXIkf/rTn3QyKUPGNddc03F/+vTpzJgxg7Fjx7Jq1SrOO++8QazZ0LZkyRI2bdrUaX5FERm+7rvvPp566ilWrVpFXFzcYFdnWGpqauL666/n0UcfJSMjY7Crc9yIxWJkZmby61//GqfTyZw5cygtLeWBBx5QEr2XVq1axb333ssvf/lL5s6dy/bt2/nqV7/K9773PZYuXTrY1RORT0j9cBku1Bc/duqHDxxN59ILGRkZOJ3Ow1a1raioIDs7e5BqNTylpKQwYcIEtm/fTnZ2NqFQiPr6+k5lFNeeHYjPkT6T2dnZhy24E4lEqK2tVXx7MGbMGDIyMti+fTugWHbl1ltv5fnnn+fVV18lPz+/Y/vRfK+zs7O7/Owe2Ccnht60rd19dvS5sX2S85Uf/ehH3Hffffzzn/9kxowZ/VnNYeVYY7pjxw52797NJZdcgsvlwuVy8fvf/57nnnsOl8vFjh07BqrqQ1ZvPqc5OTlMmDABp9PZsW3y5MmUl5cTCoX6tb7DQW9iunTpUq6//nq++MUvMn36dC677DLuvfdeli9fTiwWG4hqH1e6a5+SkpKUsPwE1A/vO+qH9x31xfuX+uJHpn74wFISvRc8Hg9z5sxh5cqVHdtisRgrV66kqKhoEGs2/DQ3N7Njxw5ycnKYM2cObre7U1y3bdtGSUmJ4tqD0aNHk52d3Sl2jY2NrF27tiN2RUVF1NfXs27duo4yr7zyCrFYjLlz5w54nYeTffv2UVNTQ05ODqBYHsoYw6233sozzzzDK6+8wujRozvtP5rvdVFRERs3bux0MvTyyy+TlJTElClTBuZAZND1pm0tKirqVB7sz47aDFtvz1d++MMf8r3vfY+XXnqp03yTcuwxnTRpEhs3bmTDhg0dt8985jOcc845bNiwgYKCgoGs/pDUm8/pvHnz2L59e6fk7ocffkhOTg4ej6ff6zzU9Samra2tOBydu4YHfqQwxvRfZY9Tap/6h/rhfUf98L6jvnj/Ul+8a+qHD5LBXdd0+HrqqaeM1+s1jz32mNm8ebO56aabTEpKSqdVbeVwX//6182qVavMrl27zBtvvGHmz59vMjIyTGVlpTHGmJtvvtkUFhaaV155xbzzzjumqKjIFBUVDXKth4ampiazfv16s379egOYBx980Kxfv97s2bPHGGPMfffdZ1JSUsxf//pX8/7775tLL73UjB492rS1tXW8xsKFC81JJ51k1q5da15//XUzfvx4c+211w7WIQ2aI8WyqanJ3HHHHaa4uNjs2rXL/Otf/zKzZ88248ePN4FAoOM1FEvbl7/8ZZOcnGxWrVplysrKOm6tra0dZXr6XkciETNt2jRz/vnnmw0bNpiXXnrJjBgxwnznO98ZjEOSQdRT23r99debb3/72x3l33jjDeNyucyPfvQjs2XLFrNs2TLjdrvNxo0bB+sQhpxjjel9991nPB6Pefrppzt9p5uamgbrEIacY43pxy1evNhceumlA1Tb4eFYY1pSUmISExPNrbfearZt22aef/55k5mZab7//e8P1iEMOcca02XLlpnExETz5JNPmp07d5p//vOfZuzYseaqq64arEMYUno6D//2t79trr/++o7yO3fuNH6/33zjG98wW7ZsMQ899JBxOp3mpZdeGqxDOG6oH9476od/MuqL9x31xfuG+uGDQ0n0T+DnP/+5KSwsNB6Px5x66qnmzTffHOwqDXlXX321ycnJMR6Px+Tl5Zmrr77abN++vWN/W1ubueWWW0xqaqrx+/3msssuM2VlZYNY46Hj1VdfNcBht8WLFxtjjInFYmbp0qUmKyvLeL1ec95555lt27Z1eo2amhpz7bXXmoSEBJOUlGRuuOGGEzIxcqRYtra2mvPPP9+MGDHCuN1uM3LkSPOlL33psBNzxdLWVRwB87vf/a6jzNF8r3fv3m0uuOAC4/P5TEZGhvn6179uwuHwAB+NDAVHalvPPvvsjv/zDvjTn/5kJkyYYDwej5k6dar5+9//PsA1HvqOJaYjR47s8ju9bNmyga/4EHasn9NDKYnetWON6Zo1a8zcuXON1+s1Y8aMMT/4wQ9MJBIZ4FoPbccS03A4bO6++24zduxYExcXZwoKCswtt9xi6urqBr7iQ1BP5+GLFy82Z5999mHPmTVrlvF4PGbMmDGdzo3kk1E//NipH/7JqC/ed9QX7xvqhw8OyxhdnyciIiIiIiIiIiIi0hXNiS4iIiIiIiIiIiIi0g0l0UVEREREREREREREuqEkuoiIiIiIiIiIiIhIN5REFxERERERERERERHphpLoIiIiIiIiIiIiIiLdUBJdRERERERERERERKQbSqKLiIiIiIiIiIiIiHRDSXQRERERERERERERkW4oiS4iA86yLJ599tnBroaIiIiIiIjICUN9cZHeUxJd5ATzhS98AcuyDrstXLhwsKsmIiIiIiIiclxSX1xkeHMNdgVEZOAtXLiQ3/3ud522eb3eQaqNiIiIiIiIyPFPfXGR4Usj0UVOQF6vl+zs7E631NRUwL686+GHH+aCCy7A5/MxZswYnn766U7P37hxI+eeey4+n4/09HRuuukmmpubO5X57W9/y9SpU/F6veTk5HDrrbd22l9dXc1ll12G3+9n/PjxPPfcc/170CIiIiIiIiKDSH1xkeFLSXQROczSpUu54ooreO+997juuuu45ppr2LJlCwAtLS0sWLCA1NRU3n77bVasWMG//vWvTg3zww8/zJIlS7jpppvYuHEjzz33HOPGjev0Hvfccw9XXXUV77//PhdeeCHXXXcdtbW1A3qcIiIiIiIiIkOF+uIiQ5dljDGDXQkRGThf+MIX+MMf/kBcXFyn7XfeeSd33nknlmVx88038/DDD3fsO+2005g9eza//OUvefTRR/nWt77F3r17iY+PB+CFF17gkksuYf/+/WRlZZGXl8cNN9zA97///S7rYFkW3/3ud/ne974H2CcDCQkJvPjii5oPTkRERERERI476ouLDG+aE13kBHTOOed0apgB0tLSOu4XFRV12ldUVMSGDRsA2LJlCzNnzuxotAHmzZtHLBZj27ZtWJbF/v37Oe+8845YhxkzZnTcj4+PJykpicrKyt4ekoiIiIiIiMiQpr64yPClJLrICSg+Pv6wS7r6is/nO6pybre702PLsojFYv1RJREREREREZFBp764yPClOdFF5DBvvvnmYY8nT54MwOTJk3nvvfdoaWnp2P/GG2/gcDiYOHEiiYmJjBo1ipUrVw5onUVERERERESGM/XFRYYujUQXOQEFg0HKy8s7bXO5XGRkZACwYsUKTj75ZM444wz+7//+j7feeovf/OY3AFx33XUsW7aMxYsXc/fdd1NVVcVXvvIVrr/+erKysgC4++67ufnmm8nMzOSCCy6gqamJN954g6985SsDe6AiIiIiIiIiQ4T64iLDl5LoIiegl156iZycnE7bJk6cyNatWwF7te6nnnqKW265hZycHJ588kmmTJkCgN/v5x//+Adf/epXOeWUU/D7/VxxxRU8+OCDHa+1ePFiAoEAP/7xj7njjjvIyMjgyiuvHLgDFBERERERERli1BcXGb4sY4wZ7EqIyNBhWRbPPPMMixYtGuyqiIiIiIiIiJwQ1BcXGdo0J7qIiIiIiIiIiIiISDeURBcRERERERERERER6YamcxERERERERERERER6YZGoouIiIiIiIiIiIiIdENJdBERERERERERERGRbiiJLiIiIiIiIiIiIiLSDSXRRURERERERERERES6oSS6iIiIiIiIiIiIiEg3lEQXEREREREREREREemGkugiIiIiIiIiIiIiIt1QEl1EREREREREREREpBtKoouIiIiIiIiIiIiIdOP/B0eVlc2ZrYUFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    # Save model every epoch with epoch number\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='/home/akshat/GPT_from_scratch/notebooks/rewrite_char_level_checkpoints/model_epoch_{epoch:02d}_val_loss_{val_loss:.4f}.keras',\n",
    "        save_freq='epoch',\n",
    "        save_best_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save best model separately\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # More reasonable early stopping\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,  # Wait 50 epochs before stopping\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "\n",
    "    keras.callbacks.CSVLogger('training_log.csv'),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=\"./char_logs\", \n",
    "        histogram_freq=1, \n",
    "        profile_batch=0,\n",
    "        write_graph=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Training\n",
    "print(\"Starting training...\")\n",
    "print(f\"Total epochs: 100\")\n",
    "print(f\"Steps per epoch: {steps_64}\")\n",
    "print(f\"Total steps: {100 * steps_64}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_64,\n",
    "    validation_data=val_ds_64,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=steps_64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "if 'learning_rate' in history.history:\n",
    "    plt.plot(history.history['learning_rate'])\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "train_perplexity = [np.exp(loss) for loss in history.history['loss']]\n",
    "val_perplexity = [np.exp(loss) for loss in history.history['val_loss']]\n",
    "plt.plot(train_perplexity, label='Train Perplexity')\n",
    "plt.plot(val_perplexity, label='Val Perplexity')\n",
    "plt.title('Perplexity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c498d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now training should work\n",
    "# history = model.fit(\n",
    "#     train_ds_32,\n",
    "#     validation_data=val_ds_32,\n",
    "#     epochs=50,\n",
    "#     steps_per_epoch=steps_32,\n",
    "#     callbacks=[\n",
    "#         keras.callbacks.ModelCheckpoint(filepath='model_epoch_{epoch:02d}.keras',save_freq='epoch'),  # saves with epoch number   save_freq='epoch',                        # save every epoch    save_best_only=False,                     # save all epochs    verbose=1)\n",
    "#         keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True, verbose=1),\n",
    "#         keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=10, verbose=1),\n",
    "#         keras.callbacks.CSVLogger('training_log.csv'),\n",
    "#         keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1, profile_batch=0)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e45dbc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Positional embeddings are working. Shape: (1, 128, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    }
   ],
   "source": [
    "# pick a small dummy batch\n",
    "import tensorflow as tf\n",
    "\n",
    "dum_model = GPT(D_MODEL, VOCAB_SIZE, CONTEXT_LEN, 8, 0.00001, 4, 0.1)\n",
    "dummy_input = tf.constant([[0] * CONTEXT_LEN], dtype=tf.int32)  # batch_size=1, length=CONTEXT_LEN\n",
    "dum_model.save('model_epoch_1.keras')\n",
    "# run the embeddings layer only\n",
    "pos_layer = dum_model.get_layer('init_embeddings')  # or however your layer is named\n",
    "try:\n",
    "    pos_emb = pos_layer(dummy_input)\n",
    "    print(\"âœ… Positional embeddings are working. Shape:\", pos_emb.shape)\n",
    "except Exception as e:\n",
    "    print(\"âŒ Embedding test failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc2606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0b33b98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'final_gpt_model.keras'\n",
      "Training history saved as 'training_history.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Save the final model\n",
    "model.save('final_gpt_model.keras')\n",
    "print(\"Model saved as 'final_gpt_model.keras'\")\n",
    "\n",
    "# Optional: Save training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"Training history saved as 'training_history.pkl'\")\n",
    "\n",
    "# Step 5: Load model later (when needed)\n",
    "def load_trained_model():\n",
    "    \"\"\"Load your saved model\"\"\"\n",
    "    loaded_model = keras.models.load_model('best_model.keras')  # or 'final_gpt_model.keras'\n",
    "    return loaded_model\n",
    "\n",
    "# Usage for inference later:\n",
    "# model = load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "87a42df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_model.save('dum_GPT.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "306ce64e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[307]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_299_val_loss_0.0130.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Loaded best_model.keras\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_299_val_loss_0.0130.keras. Please ensure the file is an accessible `.keras` zip file.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[307]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_163_val_loss_0.0303.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Loaded epoch 163 model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_163_val_loss_0.0303.keras. Please ensure the file is an accessible `.keras` zip file.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[307]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Loaded epoch 163 model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Loaded epoch 161 model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m CONTEXT_LEN = model._context_length  \u001b[38;5;66;03m# Use the model's actual context length\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# token_to_id_dict = tokenize_and_build_vocabulary_tf([r'/home/akshat/GPT_from_scratch/text_data/jane_austen_clean.txt'])\n",
    "id_to_token_dict = {id_val: token for token, id_val in token_to_id_dict.items()}\n",
    "\n",
    "# Use the latest and best model - try the best_model.keras first, then latest checkpoint\n",
    "try:\n",
    "    model = keras.models.load_model(r'/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_299_val_loss_0.0130.keras')\n",
    "    print(\"âœ… Loaded best_model.keras\")\n",
    "except:\n",
    "    try:\n",
    "        model = keras.models.load_model(r'/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_163_val_loss_0.0303.keras')\n",
    "        print(\"âœ… Loaded epoch 163 model\")\n",
    "    except:\n",
    "        model = keras.models.load_model(r'/home/akshat/GPT_from_scratch/notebooks/char_level_checkpoints/model_epoch_161_val_loss_0.0305.keras')\n",
    "        print(\"âœ… Loaded epoch 161 model\")\n",
    "\n",
    "CONTEXT_LEN = model._context_length  # Use the model's actual context length\n",
    "\n",
    "# Debug: Print vocabulary info\n",
    "print(f\"Vocabulary size: {len(token_to_id_dict)}\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "\n",
    "# Get model info from your custom GPT model\n",
    "try:\n",
    "    print(f\"Model vocab size: {model._vocab_size}\")\n",
    "    print(f\"Model context length: {model._context_length}\")\n",
    "    print(f\"Model d_model: {model._d_model}\")\n",
    "    print(f\"Model attention heads: {model._attention_heads}\")\n",
    "    print(f\"Model decoder blocks: {model._decoder_blocks}\")\n",
    "    print(f\"Vocab size matches model: {model._vocab_size == len(token_to_id_dict)}\")\n",
    "    \n",
    "    if model._vocab_size != len(token_to_id_dict):\n",
    "        print(f\"âš ï¸  VOCAB SIZE MISMATCH! Model expects {model._vocab_size}, got {len(token_to_id_dict)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error getting model info: {e}\")\n",
    "\n",
    "print(f\"Sample characters in vocab: {list(token_to_id_dict.keys())[:30]}\")\n",
    "print(f\"Common characters present: {['a' in token_to_id_dict, 'e' in token_to_id_dict, ' ' in token_to_id_dict, '.' in token_to_id_dict]}\")\n",
    "\n",
    "# Check for problematic characters in the gibberish output\n",
    "gibberish = \"4ff.mtm 64m86rfstmfm?.fmmftms777mtmkf  tm7n7m77m77\"\n",
    "print(f\"Checking gibberish characters:\")\n",
    "for char in set(gibberish):\n",
    "    if char in token_to_id_dict:\n",
    "        print(f\"  '{char}' -> ID {token_to_id_dict[char]} âœ“\")\n",
    "    else:\n",
    "        print(f\"  '{char}' -> NOT IN VOCAB âœ—\")\n",
    "\n",
    "def encode_text(text, token_to_id_dict):\n",
    "    \"\"\"Encode text to token IDs using character-level tokenizer - convert to lowercase since dataset is lowercase\"\"\"\n",
    "    # Convert input to lowercase since your dataset was lowercased\n",
    "    text = text.lower()\n",
    "    \n",
    "    token_ids = []\n",
    "    for char in text:\n",
    "        if char in token_to_id_dict:\n",
    "            token_ids.append(token_to_id_dict[char])\n",
    "        else:\n",
    "            print(f\"Warning: '{char}' (ord: {ord(char)}) not in vocabulary, skipping\")\n",
    "            continue\n",
    "    return token_ids\n",
    "\n",
    "def decode_ids(token_ids, id_to_token_dict):\n",
    "    \"\"\"Decode token IDs back to text using character-level tokenizer\"\"\"\n",
    "    text = \"\"\n",
    "    for token_id in token_ids:\n",
    "        if token_id in id_to_token_dict:\n",
    "            text += id_to_token_dict[token_id]\n",
    "        else:\n",
    "            print(f\"Warning: token ID {token_id} not in vocabulary\")\n",
    "    return text\n",
    "\n",
    "def get_special_token_ids():\n",
    "    \"\"\"Get special token IDs - adjust these based on your tokenizer setup\"\"\"\n",
    "    # For Jane Austen data, likely no special PAD token, use newline as EOS\n",
    "    pad_id = token_to_id_dict.get('<PAD>', None)\n",
    "    eos_id = token_to_id_dict.get('\\n', None)  # Use newline as natural stopping point\n",
    "    print(f\"Special tokens - PAD: {pad_id}, EOS (newline): {eos_id}\")\n",
    "    return pad_id, eos_id\n",
    "\n",
    "def top_k_sampling(logits, k=10):\n",
    "    \"\"\"Sample from logits using top-k sampling\"\"\"\n",
    "    # Ensure we don't sample more than available tokens\n",
    "    k = min(k, len(logits))\n",
    "    \n",
    "    values, indices = tf.math.top_k(logits, k=k)\n",
    "    last_val = values[-1]\n",
    "    filtered_logits = tf.where(\n",
    "        logits < last_val,\n",
    "        tf.fill(tf.shape(logits), float('-inf')),\n",
    "        logits\n",
    "    )\n",
    "    probs = tf.nn.softmax(filtered_logits).numpy()\n",
    "    \n",
    "    # Add small epsilon to avoid numerical issues\n",
    "    probs = probs + 1e-10\n",
    "    probs = probs / np.sum(probs)\n",
    "    \n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "def generate_response(prompt, max_length=100, temperature=0.7, top_k=10, use_argmax=False):\n",
    "    if not prompt.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    print(f\"\\n--- Generation Debug ---\")\n",
    "    print(f\"Input prompt: '{prompt}' (will be lowercased)\")\n",
    "    \n",
    "    # Tokenize prompt with character-level tokenizer\n",
    "    input_tokens = encode_text(prompt, token_to_id_dict)\n",
    "    print(f\"Input tokens: {input_tokens}\")\n",
    "    print(f\"Input tokens decoded back: '{decode_ids(input_tokens, id_to_token_dict)}'\")\n",
    "    \n",
    "    if not input_tokens:\n",
    "        return \"Error: Could not tokenize input\"\n",
    "    \n",
    "    # Truncate if longer than context length\n",
    "    if len(input_tokens) > CONTEXT_LEN:\n",
    "        input_tokens = input_tokens[-CONTEXT_LEN:]\n",
    "    \n",
    "    generated_tokens = input_tokens.copy()\n",
    "    pad_id, eos_id = get_special_token_ids()\n",
    "    \n",
    "    print(f\"Starting generation with {len(input_tokens)} input tokens...\")\n",
    "    \n",
    "    for step in range(max_length):\n",
    "        # Prepare inputs - pad from left to maintain most recent context\n",
    "        input_ids = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "        attention_mask = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "        \n",
    "        # Place tokens at the end of the context window\n",
    "        current_len = min(len(generated_tokens), CONTEXT_LEN)\n",
    "        start_idx = CONTEXT_LEN - current_len\n",
    "        input_ids[0, start_idx:] = generated_tokens[-current_len:]\n",
    "        attention_mask[0, start_idx:] = 1\n",
    "        \n",
    "        # Model forward pass\n",
    "        try:\n",
    "            logits = model((input_ids, attention_mask), training=False)\n",
    "            next_token_logits = logits[0, -1, :]\n",
    "            \n",
    "            # Apply temperature\n",
    "            if not use_argmax:\n",
    "                next_token_logits = next_token_logits / temperature\n",
    "        except Exception as e:\n",
    "            print(f\"Model forward pass error: {e}\")\n",
    "            break\n",
    "        \n",
    "        # Sample next token\n",
    "        try:\n",
    "            if use_argmax:\n",
    "                # Use argmax (greedy) sampling for testing\n",
    "                next_token = int(np.argmax(next_token_logits))\n",
    "            else:\n",
    "                # Use top-k sampling\n",
    "                next_token = top_k_sampling(next_token_logits, k=top_k)\n",
    "        except Exception as e:\n",
    "            print(f\"Sampling error: {e}\")\n",
    "            break\n",
    "        \n",
    "        # Debug: Print first few tokens\n",
    "        if step < 10:\n",
    "            sampled_char = id_to_token_dict.get(next_token, f\"<UNK:{next_token}>\")\n",
    "            prob = float(tf.nn.softmax(next_token_logits)[next_token])\n",
    "            print(f\"Step {step}: Token {next_token} -> '{sampled_char}' (prob: {prob:.4f})\")\n",
    "        \n",
    "        # Check if token is valid\n",
    "        if next_token >= len(id_to_token_dict):\n",
    "            print(f\"Warning: Invalid token {next_token}, vocab size is {len(id_to_token_dict)}\")\n",
    "            break\n",
    "        \n",
    "        # Stop on special tokens\n",
    "        if pad_id is not None and next_token == pad_id:\n",
    "            print(f\"Stopping at step {step}: hit PAD token\")\n",
    "            break\n",
    "        if eos_id is not None and next_token == eos_id and step > 10:  # Don't stop too early\n",
    "            print(f\"Stopping at step {step}: hit EOS token (newline)\")\n",
    "            break\n",
    "        \n",
    "        generated_tokens.append(int(next_token))\n",
    "        \n",
    "        # Maintain sliding window\n",
    "        if len(generated_tokens) > CONTEXT_LEN:\n",
    "            generated_tokens = generated_tokens[-CONTEXT_LEN:]\n",
    "    \n",
    "    # Decode only the newly generated tokens\n",
    "    new_tokens = generated_tokens[len(input_tokens):]\n",
    "    response = decode_ids(new_tokens, id_to_token_dict)\n",
    "    print(f\"Generated {len(new_tokens)} new tokens: {new_tokens[:20]}...\")  # Show first 20\n",
    "    print(f\"Generated response: '{response}'\")\n",
    "    print(f\"--- End Debug ---\\n\")\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "def chat_fn(message, history, temperature, max_length, top_k, use_argmax):\n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "    \n",
    "    bot_response = generate_response(message, max_length=max_length, temperature=temperature, top_k=top_k, use_argmax=use_argmax)\n",
    "    history.append((message, bot_response))\n",
    "    return \"\", history\n",
    "\n",
    "# Quick test with the better model\n",
    "print(\"Testing improved model:\")\n",
    "test_cases = [\"the\", \"elizabeth\", \"it is a\"]\n",
    "\n",
    "for prompt in test_cases:\n",
    "    print(f\"\\nTesting with: '{prompt}'\")\n",
    "    tokens = encode_text(prompt, token_to_id_dict)\n",
    "    \n",
    "    # Create model input\n",
    "    input_ids = np.zeros((1, 256), dtype=np.int32)\n",
    "    attention_mask = np.zeros((1, 256), dtype=np.int32)\n",
    "    input_ids[0, -len(tokens):] = tokens\n",
    "    attention_mask[0, -len(tokens):] = 1\n",
    "    \n",
    "    # Get model predictions\n",
    "    logits = model((input_ids, attention_mask), training=False)\n",
    "    next_token_logits = logits[0, -1, :]\n",
    "    \n",
    "    # Show top 5 predictions\n",
    "    top_probs, top_indices = tf.nn.top_k(tf.nn.softmax(next_token_logits), k=5)\n",
    "    print(\"Top 5 predictions:\")\n",
    "    for i in range(5):\n",
    "        token_id = int(top_indices[i])\n",
    "        prob = float(top_probs[i])\n",
    "        char = id_to_token_dict.get(token_id, f\"UNK_{token_id}\")\n",
    "        print(f\"  {i+1}. '{char}' (ID: {token_id}) - {prob:.4f}\")\n",
    "\n",
    "# Test with longer context\n",
    "print(f\"\\nTesting with longer Jane Austen context:\")\n",
    "long_prompt = \"it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a\"\n",
    "tokens = encode_text(long_prompt, token_to_id_dict)\n",
    "print(f\"Context: '{long_prompt}'\")\n",
    "print(f\"Context length: {len(tokens)} tokens\")\n",
    "\n",
    "# Use reasonable context length\n",
    "context_tokens = tokens[-100:] if len(tokens) > 100 else tokens\n",
    "\n",
    "input_ids = np.zeros((1, 256), dtype=np.int32)\n",
    "attention_mask = np.zeros((1, 256), dtype=np.int32)\n",
    "input_ids[0, -len(context_tokens):] = context_tokens\n",
    "attention_mask[0, -len(context_tokens):] = 1\n",
    "\n",
    "logits = model((input_ids, attention_mask), training=False)\n",
    "next_token_logits = logits[0, -1, :]\n",
    "\n",
    "top_probs, top_indices = tf.nn.top_k(tf.nn.softmax(next_token_logits), k=5)\n",
    "print(\"Top 5 predictions after long context:\")\n",
    "for i in range(5):\n",
    "    token_id = int(top_indices[i])\n",
    "    prob = float(top_probs[i])\n",
    "    char = id_to_token_dict.get(token_id, f\"UNK_{token_id}\")\n",
    "    print(f\"  {i+1}. '{char}' (ID: {token_id}) - {prob:.4f}\")\n",
    "\n",
    "with gr.Blocks(title=\"My Character-Level GPT Bot Trained in Tensorflow\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# ðŸ¤– Chat with Akshat's Character-Level GPT Model\")\n",
    "    gr.Markdown(\"Ask me anything! I'm a GPT model trained from scratch with character-level tokenization on Jane Austen data. Be gentle with me :)\")\n",
    "    \n",
    "    # Add vocab info\n",
    "    gr.Markdown(f\"**Model Info:** Vocabulary size: {len(token_to_id_dict)} characters\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(label=\"Conversation\", height=400, show_copy_button=True)\n",
    "    \n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(label=\"Your message\", placeholder=\"Type your message here...\", scale=4)\n",
    "        send_btn = gr.Button(\"Send\", scale=1, variant=\"primary\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        temperature = gr.Slider(minimum=0.1, maximum=1.5, value=0.3, step=0.05, label=\"Temperature\")\n",
    "        max_length = gr.Slider(minimum=10, maximum=200, value=30, step=10, label=\"Max Length\")\n",
    "        top_k = gr.Slider(minimum=1, maximum=50, value=5, step=1, label=\"Top-K Sampling\")\n",
    "        use_argmax = gr.Checkbox(label=\"Use Argmax (Greedy) - for testing\", value=True)\n",
    "    \n",
    "    clear_btn = gr.Button(\"Clear Chat\", variant=\"secondary\")\n",
    "    \n",
    "    # Event handlers\n",
    "    msg.submit(chat_fn, [msg, chatbot, temperature, max_length, top_k, use_argmax], [msg, chatbot])\n",
    "    send_btn.click(chat_fn, [msg, chatbot, temperature, max_length, top_k, use_argmax], [msg, chatbot])\n",
    "    clear_btn.click(lambda: [], None, chatbot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        share=True,          # Generate public share link\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=6019,\n",
    "        show_error=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468aeb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:  VxxZEtRh5HHeYXZtxnhx5ICxxetRx5(ZxZMqx55xejhPxYW4Rx\n",
      "GPT:  RcT2-LeJPeRHVpMKhzo37xBoxti\n",
      "GPT:  qt-45HxGefn5ZZx48.UxMeTRuOLzRHxt\n",
      "GPT:  RxHxtX5RmeMxHd2tZ\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[277]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Simple console loop\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     prompt = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prompt.lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1275\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1273\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/ml-venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1320\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1318\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1319\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, max_length=50, temperature=1.0):\n",
    "    input_tokens = [token_to_id_dict.get(c, 0) for c in prompt if c in token_to_id_dict]\n",
    "    if len(input_tokens) == 0:\n",
    "        input_tokens = [0]\n",
    "\n",
    "    if len(input_tokens) > CONTEXT_LEN:\n",
    "        input_tokens = input_tokens[-CONTEXT_LEN:]\n",
    "\n",
    "    input_ids = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "    input_ids[0, -len(input_tokens):] = input_tokens\n",
    "\n",
    "    attention_mask = np.zeros((1, CONTEXT_LEN), dtype=np.int32)\n",
    "    attention_mask[0, -len(input_tokens):] = 1\n",
    "\n",
    "    generated_tokens = input_tokens.copy()\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        predictions = model.predict([input_ids, attention_mask], verbose=0)\n",
    "        next_token_logits = predictions[0, -1, :] / temperature\n",
    "        probabilities = tf.nn.softmax(next_token_logits).numpy()\n",
    "        next_token = np.random.choice(len(probabilities), p=probabilities)\n",
    "\n",
    "        if next_token == 0:\n",
    "            break\n",
    "\n",
    "        generated_tokens.append(next_token)\n",
    "\n",
    "        # Update input_ids and attention_mask\n",
    "        if len(generated_tokens) > CONTEXT_LEN:\n",
    "            generated_tokens = generated_tokens[-CONTEXT_LEN:]\n",
    "\n",
    "        input_ids[0, -len(generated_tokens):] = generated_tokens\n",
    "        attention_mask[0, -len(generated_tokens):] = 1\n",
    "\n",
    "    id_to_token = {v: k for k, v in token_to_id_dict.items()}\n",
    "    return ''.join([id_to_token.get(t, '') for t in generated_tokens[len(input_tokens):]]).strip()\n",
    "\n",
    "\n",
    "# Simple console loop\n",
    "while True:\n",
    "    prompt = input(\"You: \")\n",
    "    if prompt.lower() in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "    response = generate_text(prompt, max_length=50, temperature=0.8)\n",
    "    print(\"GPT: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb3680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7fccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_token_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d11a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(sinusoidal_lookup_table.shape)  # should be (CONTEXT_LEN, D_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67921403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting comprehensive testing for YOUR custom model implementation...\n",
      "\n",
      "ðŸ” Testing sinusoidal lookup table creation...\n",
      "âœ… Sinusoidal lookup table created successfully. Shape: (128, 128)\n",
      "   Table type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "   Table dtype: <dtype: 'float32'>\n",
      "\n",
      "ðŸ” Testing InitializePositionalEmbeddings layer...\n",
      "âŒ Positional embeddings test failed: Unrecognized keyword arguments passed to InitializePositionalEmbeddings: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n",
      "\n",
      "ðŸ” Testing LayerNormalization layer...\n",
      "âœ… LayerNormalization working. Input shape: (2, 128, 128), Output shape: (2, 128, 128)\n",
      "   Output mean (should be ~0): 0.000000\n",
      "   Output variance (should be ~1): 0.999990\n",
      "\n",
      "ðŸ” Testing YOUR SelfAttentionLayer...\n",
      "   Input embeddings shape: (2, 128, 128)\n",
      "   Attention mask shape: (2, 128)\n",
      "   Mask sample - seq 1: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] ... [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "âœ… SelfAttentionLayer working. Output shape: (2, 128, 128)\n",
      "   Output range: [-0.7532, 0.7810]\n",
      "   Output mean: 0.0010\n",
      "   Output std: 0.0782\n",
      "   Attention heads: 8\n",
      "   d_head: 16\n",
      "   d_model: 128\n",
      "\n",
      "ðŸ” Testing YOUR DecoderBlock...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_206177/3617421218.py\", line 29, in test_positional_embeddings\n",
      "    pos_layer = InitializePositionalEmbeddings(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_206177/3965528913.py\", line 11, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 291, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Unrecognized keyword arguments passed to InitializePositionalEmbeddings: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Input shape: (2, 128, 128)\n",
      "   Attention mask shape: (2, 128)\n",
      "âœ… DecoderBlock working (training=False). Output shape: (2, 128, 128)\n",
      "âœ… DecoderBlock working (training=True). Output shape: (2, 128, 128)\n",
      "   Input mean: 0.0003, Output mean: -0.0041\n",
      "   Output range: [-4.3376, 4.7553]\n",
      "\n",
      "ðŸ” Testing YOUR complete GPT model...\n",
      "âŒ Full model test failed: Unrecognized keyword arguments passed to GPT: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n",
      "\n",
      "ðŸ” Testing the specific embedding issue from your original code...\n",
      "âŒ Original embedding test still fails: GPT.__init__() takes from 1 to 8 positional arguments but 9 were given\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ¯ TESTING SUMMARY FOR YOUR CUSTOM MODEL:\n",
      "======================================================================\n",
      "Sinusoidal Lookup Table........................... âœ… PASSED\n",
      "Positional Embeddings............................. âŒ FAILED\n",
      "Layer Normalization............................... âœ… PASSED\n",
      "YOUR Self Attention Layer......................... âœ… PASSED\n",
      "YOUR Decoder Block................................ âœ… PASSED\n",
      "YOUR Full Model Forward Pass...................... âŒ FAILED\n",
      "YOUR Original Embedding Issue..................... âŒ FAILED\n",
      "Model Compilation & Training...................... âŒ FAILED\n",
      "\n",
      "ðŸ† Overall: 4/8 tests passed\n",
      "âš ï¸  Some tests failed. Please fix the issues before training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_206177/3617421218.py\", line 186, in test_your_full_model\n",
      "    model = GPT(\n",
      "            ^^^^\n",
      "  File \"/tmp/ipykernel_206177/1791215164.py\", line 64, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/models/model.py\", line 158, in __init__\n",
      "    Layer.__init__(self, *args, **kwargs)\n",
      "  File \"/home/akshat/ml/ml-venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 291, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Unrecognized keyword arguments passed to GPT: {'sinusoidal_lookup_table': <tf.Tensor: shape=(128, 128), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00, ...,\n",
      "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "       [ 8.4147096e-01,  5.4030228e-01,  7.6172042e-01, ...,\n",
      "         1.0000000e+00,  1.1547820e-04,  1.0000000e+00],\n",
      "       [ 9.0929741e-01, -4.1614684e-01,  9.8704624e-01, ...,\n",
      "         9.9999994e-01,  2.3095640e-04,  1.0000000e+00],\n",
      "       ...,\n",
      "       [-6.1604047e-01,  7.8771454e-01,  9.9029869e-01, ...,\n",
      "         9.9986106e-01,  1.4434273e-02,  9.9989581e-01],\n",
      "       [ 3.2999083e-01,  9.4398415e-01,  7.4746519e-01, ...,\n",
      "         9.9985886e-01,  1.4549740e-02,  9.9989414e-01],\n",
      "       [ 9.7263008e-01,  2.3235910e-01, -2.1724481e-02, ...,\n",
      "         9.9985659e-01,  1.4665205e-02,  9.9989247e-01]],\n",
      "      shape=(128, 128), dtype=float32)>}\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_206177/3617421218.py\", line 255, in test_specific_embedding_issue\n",
      "    dum_model = GPT(D_MODEL, VOCAB_SIZE, CONTEXT_LEN, 8, 0.00001, 4, 0.1, sinusoidal_lookup_table)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: GPT.__init__() takes from 1 to 8 positional arguments but 9 were given\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "# Model configuration\n",
    "CONTEXT_LEN = 128\n",
    "D_MODEL = 128\n",
    "VOCAB_SIZE = 94\n",
    "\n",
    "def test_sinusoidal_lookup_table():\n",
    "    \"\"\"Test the sinusoidal lookup table creation\"\"\"\n",
    "    print(\"ðŸ” Testing sinusoidal lookup table creation...\")\n",
    "    try:\n",
    "        sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL, CONTEXT_LEN)\n",
    "        print(f\"âœ… Sinusoidal lookup table created successfully. Shape: {sinusoidal_lookup_table.shape}\")\n",
    "        print(f\"   Table type: {type(sinusoidal_lookup_table)}\")\n",
    "        print(f\"   Table dtype: {sinusoidal_lookup_table.dtype}\")\n",
    "        return sinusoidal_lookup_table\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Sinusoidal lookup table creation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_positional_embeddings(sinusoidal_lookup_table):\n",
    "    \"\"\"Test the positional embeddings layer\"\"\"\n",
    "    print(\"\\nðŸ” Testing InitializePositionalEmbeddings layer...\")\n",
    "    \n",
    "    try:\n",
    "        # Create the layer\n",
    "        pos_layer = InitializePositionalEmbeddings(\n",
    "            d_model=D_MODEL,\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            sinusoidal_lookup_table=sinusoidal_lookup_table,\n",
    "            name=\"test_pos_embeddings\"\n",
    "        )\n",
    "        \n",
    "        # Test input\n",
    "        dummy_input = tf.constant([[1, 2, 3, 4, 5] + [0] * (CONTEXT_LEN - 5)], dtype=tf.int32)\n",
    "        print(f\"   Input shape: {dummy_input.shape}\")\n",
    "        \n",
    "        # Forward pass\n",
    "        pos_emb = pos_layer(dummy_input)\n",
    "        print(f\"âœ… Positional embeddings working. Output shape: {pos_emb.shape}\")\n",
    "        print(f\"   Expected shape: (1, {CONTEXT_LEN}, {D_MODEL})\")\n",
    "        \n",
    "        # Check if embeddings are reasonable\n",
    "        print(f\"   Output range: [{tf.reduce_min(pos_emb):.4f}, {tf.reduce_max(pos_emb):.4f}]\")\n",
    "        print(f\"   Output mean: {tf.reduce_mean(pos_emb):.4f}\")\n",
    "        \n",
    "        return pos_layer, pos_emb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Positional embeddings test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_layer_normalization():\n",
    "    \"\"\"Test LayerNormalization layer\"\"\"\n",
    "    print(\"\\nðŸ” Testing LayerNormalization layer...\")\n",
    "    \n",
    "    try:\n",
    "        ln = LayerNormalization(eps=1e-5, name=\"test_ln\")\n",
    "        test_input = tf.random.normal((2, CONTEXT_LEN, D_MODEL))\n",
    "        \n",
    "        output = ln(test_input)\n",
    "        print(f\"âœ… LayerNormalization working. Input shape: {test_input.shape}, Output shape: {output.shape}\")\n",
    "        \n",
    "        # Check normalization properties\n",
    "        mean = tf.reduce_mean(output, axis=-1)\n",
    "        var = tf.reduce_mean(tf.square(output - tf.expand_dims(mean, -1)), axis=-1)\n",
    "        print(f\"   Output mean (should be ~0): {tf.reduce_mean(mean):.6f}\")\n",
    "        print(f\"   Output variance (should be ~1): {tf.reduce_mean(var):.6f}\")\n",
    "        \n",
    "        return ln, output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LayerNormalization test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_your_self_attention():\n",
    "    \"\"\"Test YOUR custom SelfAttentionLayer\"\"\"\n",
    "    print(\"\\nðŸ” Testing YOUR SelfAttentionLayer...\")\n",
    "    \n",
    "    try:\n",
    "        # Create your attention layer with correct parameter name\n",
    "        attn_layer = SelfAttentionLayer(attention_heads=8, name=\"test_attention\")\n",
    "        \n",
    "        # Prepare test inputs\n",
    "        batch_size = 2\n",
    "        seq_len = CONTEXT_LEN\n",
    "        embeddings = tf.random.normal((batch_size, seq_len, D_MODEL))\n",
    "        \n",
    "        # Create attention mask (1 for real tokens, 0 for padding)\n",
    "        attention_mask = tf.ones((batch_size, seq_len), dtype=tf.float32)\n",
    "        # Make some positions masked (set to 0)\n",
    "        attention_mask = attention_mask.numpy()\n",
    "        attention_mask[0, 50:] = 0  # Mask second half of first sequence\n",
    "        attention_mask[1, 80:] = 0  # Mask last part of second sequence\n",
    "        attention_mask = tf.constant(attention_mask)\n",
    "        \n",
    "        print(f\"   Input embeddings shape: {embeddings.shape}\")\n",
    "        print(f\"   Attention mask shape: {attention_mask.shape}\")\n",
    "        print(f\"   Mask sample - seq 1: {attention_mask[0, :10].numpy()} ... {attention_mask[0, -10:].numpy()}\")\n",
    "        \n",
    "        # Test with your layer's expected input format: (embeddings, mask)\n",
    "        output = attn_layer([embeddings, attention_mask])\n",
    "        print(f\"âœ… SelfAttentionLayer working. Output shape: {output.shape}\")\n",
    "        \n",
    "        # Check output properties\n",
    "        print(f\"   Output range: [{tf.reduce_min(output):.4f}, {tf.reduce_max(output):.4f}]\")\n",
    "        print(f\"   Output mean: {tf.reduce_mean(output):.4f}\")\n",
    "        print(f\"   Output std: {tf.math.reduce_std(output):.4f}\")\n",
    "        \n",
    "        # Verify attention heads are working\n",
    "        print(f\"   Attention heads: {attn_layer.attention_heads}\")\n",
    "        print(f\"   d_head: {attn_layer.d_head}\")\n",
    "        print(f\"   d_model: {attn_layer.d_model}\")\n",
    "        \n",
    "        return attn_layer, output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ SelfAttentionLayer test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_your_decoder_block():\n",
    "    \"\"\"Test YOUR custom DecoderBlock\"\"\"\n",
    "    print(\"\\nðŸ” Testing YOUR DecoderBlock...\")\n",
    "    \n",
    "    try:\n",
    "        # Create your decoder block\n",
    "        decoder = DecoderBlock(\n",
    "            d_model=D_MODEL,\n",
    "            n_heads=8,\n",
    "            dropout_rate=0.1,\n",
    "            epsilon=1e-5,\n",
    "            name=\"test_decoder\"\n",
    "        )\n",
    "        \n",
    "        # Prepare test inputs\n",
    "        batch_size = 2\n",
    "        seq_len = CONTEXT_LEN\n",
    "        test_input = tf.random.normal((batch_size, seq_len, D_MODEL))\n",
    "        attention_mask = tf.ones((batch_size, seq_len), dtype=tf.float32)\n",
    "        \n",
    "        # Make some positions masked\n",
    "        attention_mask = attention_mask.numpy()\n",
    "        attention_mask[0, 60:] = 0\n",
    "        attention_mask[1, 90:] = 0\n",
    "        attention_mask = tf.constant(attention_mask)\n",
    "        \n",
    "        print(f\"   Input shape: {test_input.shape}\")\n",
    "        print(f\"   Attention mask shape: {attention_mask.shape}\")\n",
    "        \n",
    "        # Test training=False\n",
    "        output = decoder(test_input, attention_mask, training=False)\n",
    "        print(f\"âœ… DecoderBlock working (training=False). Output shape: {output.shape}\")\n",
    "        \n",
    "        # Test training=True\n",
    "        output_train = decoder(test_input, attention_mask, training=True)\n",
    "        print(f\"âœ… DecoderBlock working (training=True). Output shape: {output_train.shape}\")\n",
    "        \n",
    "        # Check residual connections work (output should be different from input)\n",
    "        input_mean = tf.reduce_mean(test_input)\n",
    "        output_mean = tf.reduce_mean(output)\n",
    "        print(f\"   Input mean: {input_mean:.4f}, Output mean: {output_mean:.4f}\")\n",
    "        print(f\"   Output range: [{tf.reduce_min(output):.4f}, {tf.reduce_max(output):.4f}]\")\n",
    "        \n",
    "        return decoder, output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DecoderBlock test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_your_full_model(sinusoidal_lookup_table):\n",
    "    \"\"\"Test YOUR complete GPT model\"\"\"\n",
    "    print(\"\\nðŸ” Testing YOUR complete GPT model...\")\n",
    "    \n",
    "    try:\n",
    "        # Create model exactly as you do\n",
    "        model = GPT(\n",
    "            d_model=D_MODEL,\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            context_length=CONTEXT_LEN,\n",
    "            attention_heads=8,\n",
    "            epsilon=1e-5,\n",
    "            decoder_blocks=4,\n",
    "            dropout_rate=0.1,\n",
    "            sinusoidal_lookup_table=sinusoidal_lookup_table,\n",
    "            name=\"test_gpt\"\n",
    "        )\n",
    "        \n",
    "        # Prepare test inputs\n",
    "        token_ids = tf.constant([[1, 2, 3, 4, 5] + [0] * (CONTEXT_LEN - 5)], dtype=tf.int32)\n",
    "        attention_mask = tf.ones((1, CONTEXT_LEN), dtype=tf.float32)\n",
    "        \n",
    "        # Set mask to 0 for padding tokens\n",
    "        attention_mask = attention_mask.numpy()\n",
    "        attention_mask[0, 5:] = 0  # Only first 5 tokens are real\n",
    "        attention_mask = tf.constant(attention_mask)\n",
    "        \n",
    "        print(f\"   Token IDs shape: {token_ids.shape}\")\n",
    "        print(f\"   Token IDs sample: {token_ids[0, :10].numpy()}\")\n",
    "        print(f\"   Attention mask shape: {attention_mask.shape}\")\n",
    "        print(f\"   Mask sample: {attention_mask[0, :10].numpy()}\")\n",
    "        \n",
    "        # Test forward pass\n",
    "        logits = model([token_ids, attention_mask], training=False)\n",
    "        print(f\"âœ… Full model forward pass successful!\")\n",
    "        print(f\"   Output logits shape: {logits.shape}\")\n",
    "        print(f\"   Expected shape: (1, {CONTEXT_LEN}, {VOCAB_SIZE})\")\n",
    "        \n",
    "        # Check output properties\n",
    "        print(f\"   Logits range: [{tf.reduce_min(logits):.4f}, {tf.reduce_max(logits):.4f}]\")\n",
    "        print(f\"   Logits mean: {tf.reduce_mean(logits):.4f}\")\n",
    "        \n",
    "        # Test with different batch size\n",
    "        token_ids_batch = tf.constant([\n",
    "            [1, 2, 3] + [0] * (CONTEXT_LEN - 3),\n",
    "            [4, 5, 6, 7] + [0] * (CONTEXT_LEN - 4)\n",
    "        ], dtype=tf.int32)\n",
    "        attention_mask_batch = tf.ones((2, CONTEXT_LEN), dtype=tf.float32)\n",
    "        attention_mask_batch = attention_mask_batch.numpy()\n",
    "        attention_mask_batch[0, 3:] = 0  # First seq has 3 real tokens\n",
    "        attention_mask_batch[1, 4:] = 0  # Second seq has 4 real tokens\n",
    "        attention_mask_batch = tf.constant(attention_mask_batch)\n",
    "        \n",
    "        logits_batch = model([token_ids_batch, attention_mask_batch], training=False)\n",
    "        print(f\"âœ… Batch processing successful! Output shape: {logits_batch.shape}\")\n",
    "        \n",
    "        # Test training mode\n",
    "        logits_train = model([token_ids, attention_mask], training=True)\n",
    "        print(f\"âœ… Training mode successful! Output shape: {logits_train.shape}\")\n",
    "        \n",
    "        return model, logits\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Full model test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def test_specific_embedding_issue():\n",
    "    \"\"\"Test the specific embedding issue you encountered\"\"\"\n",
    "    print(\"\\nðŸ” Testing the specific embedding issue from your original code...\")\n",
    "    \n",
    "    try:\n",
    "        # Create model exactly as you did\n",
    "        sinusoidal_lookup_table = prepare_sinusoidal_lookup_table(D_MODEL, CONTEXT_LEN)\n",
    "        dum_model = GPT(D_MODEL, VOCAB_SIZE, CONTEXT_LEN, 8, 0.00001, 4, 0.1, sinusoidal_lookup_table)\n",
    "        \n",
    "        # Test exactly as you did\n",
    "        dummy_input = tf.constant([[0] * CONTEXT_LEN], dtype=tf.int32)\n",
    "        \n",
    "        # Get the embeddings layer\n",
    "        pos_layer = dum_model.get_layer('init_embeddings')\n",
    "        \n",
    "        # Run the embeddings layer\n",
    "        pos_emb = pos_layer(dummy_input)\n",
    "        print(f\"âœ… Your original embedding test now works! Shape: {pos_emb.shape}\")\n",
    "        print(f\"   Input was all zeros: {dummy_input[0, :5].numpy()}\")\n",
    "        print(f\"   Output range: [{tf.reduce_min(pos_emb):.4f}, {tf.reduce_max(pos_emb):.4f}]\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Original embedding test still fails: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def test_model_compilation_and_training(model):\n",
    "    \"\"\"Test model compilation and training capability\"\"\"\n",
    "    print(\"\\nðŸ” Testing model compilation and training...\")\n",
    "    \n",
    "    try:\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.AdamW(learning_rate=1e-4),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(\"âœ… Model compilation successful!\")\n",
    "        \n",
    "        # Create dummy training data\n",
    "        batch_size = 4\n",
    "        dummy_x = tf.random.uniform((batch_size, CONTEXT_LEN), maxval=VOCAB_SIZE, dtype=tf.int32)\n",
    "        dummy_mask = tf.ones((batch_size, CONTEXT_LEN), dtype=tf.float32)\n",
    "        # Create some realistic masking\n",
    "        for i in range(batch_size):\n",
    "            seq_len = tf.random.uniform([], minval=10, maxval=CONTEXT_LEN, dtype=tf.int32)\n",
    "            dummy_mask = dummy_mask.numpy()\n",
    "            dummy_mask[i, seq_len:] = 0\n",
    "            dummy_mask = tf.constant(dummy_mask)\n",
    "        \n",
    "        dummy_y = tf.random.uniform((batch_size, CONTEXT_LEN), maxval=VOCAB_SIZE, dtype=tf.int32)\n",
    "        \n",
    "        print(f\"   Training data shapes: X={dummy_x.shape}, mask={dummy_mask.shape}, Y={dummy_y.shape}\")\n",
    "        \n",
    "        # Test prediction\n",
    "        predictions = model.predict([dummy_x, dummy_mask], verbose=0)\n",
    "        print(f\"âœ… Model prediction successful! Predictions shape: {predictions.shape}\")\n",
    "        \n",
    "        # Test training step\n",
    "        loss = model.train_on_batch([dummy_x, dummy_mask], dummy_y)\n",
    "        print(f\"âœ… Training step successful! Loss: {loss}\")\n",
    "        \n",
    "        # Test model summary\n",
    "        print(f\"\\nðŸ“Š Model has {model.count_params():,} parameters\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Model compilation/training test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def run_all_tests_for_your_model():\n",
    "    \"\"\"Run all tests specifically for your model implementation\"\"\"\n",
    "    print(\"ðŸš€ Starting comprehensive testing for YOUR custom model implementation...\\n\")\n",
    "    \n",
    "    # Test 1: Sinusoidal lookup table\n",
    "    sinusoidal_lookup_table = test_sinusoidal_lookup_table()\n",
    "    if sinusoidal_lookup_table is None:\n",
    "        print(\"âŒ Cannot proceed without sinusoidal lookup table\")\n",
    "        return\n",
    "    \n",
    "    # Test 2: Positional embeddings\n",
    "    pos_layer, pos_emb = test_positional_embeddings(sinusoidal_lookup_table)\n",
    "    \n",
    "    # Test 3: Layer normalization\n",
    "    ln_layer, ln_output = test_layer_normalization()\n",
    "    \n",
    "    # Test 4: Your self attention\n",
    "    attn_layer, attn_output = test_your_self_attention()\n",
    "    \n",
    "    # Test 5: Your decoder block\n",
    "    decoder_layer, decoder_output = test_your_decoder_block()\n",
    "    \n",
    "    # Test 6: Your full model\n",
    "    model, logits = test_your_full_model(sinusoidal_lookup_table)\n",
    "    \n",
    "    # Test 7: Your specific embedding issue\n",
    "    embedding_issue_fixed = test_specific_embedding_issue()\n",
    "    \n",
    "    # Test 8: Model compilation and training\n",
    "    compilation_success = False\n",
    "    if model is not None:\n",
    "        compilation_success = test_model_compilation_and_training(model)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸŽ¯ TESTING SUMMARY FOR YOUR CUSTOM MODEL:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    tests = [\n",
    "        (\"Sinusoidal Lookup Table\", sinusoidal_lookup_table is not None),\n",
    "        (\"Positional Embeddings\", pos_emb is not None),\n",
    "        (\"Layer Normalization\", ln_output is not None),\n",
    "        (\"YOUR Self Attention Layer\", attn_output is not None),\n",
    "        (\"YOUR Decoder Block\", decoder_output is not None),\n",
    "        (\"YOUR Full Model Forward Pass\", logits is not None),\n",
    "        (\"YOUR Original Embedding Issue\", embedding_issue_fixed),\n",
    "        (\"Model Compilation & Training\", compilation_success)\n",
    "    ]\n",
    "    \n",
    "    passed = sum(1 for _, result in tests if result)\n",
    "    total = len(tests)\n",
    "    \n",
    "    for test_name, result in tests:\n",
    "        status = \"âœ… PASSED\" if result else \"âŒ FAILED\"\n",
    "        print(f\"{test_name:.<50} {status}\")\n",
    "    \n",
    "    print(f\"\\nðŸ† Overall: {passed}/{total} tests passed\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"ðŸŽ‰ All tests passed! Your model is working perfectly!\")\n",
    "        print(\"ðŸš€ Your model is ready for training and inference!\")\n",
    "    elif passed >= total - 2:\n",
    "        print(\"ðŸŽŠ Almost all tests passed! Your model is mostly working correctly!\")\n",
    "        print(\"ðŸ”§ Check the failed tests above for minor issues.\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Some tests failed. Please fix the issues before training.\")\n",
    "    \n",
    "    return model if logits is not None else None\n",
    "\n",
    "# Run the tests\n",
    "if __name__ == \"__main__\":\n",
    "    final_model = run_all_tests_for_your_model()\n",
    "    \n",
    "    if final_model is not None:\n",
    "        print(f\"\\nðŸŽ Model returned successfully!\")\n",
    "        print(f\"   Total parameters: {final_model.count_params():,}\")\n",
    "        print(f\"   Ready for: training, inference, and saving!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39917dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_from_bot(model, token_to_id_dict, prompt, max_length=100, temperature=0.7, context_len=128):\n",
    "    \"\"\"Generate text response from your GPT model\"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    input_tokens = [token_to_id_dict.get(char, 0) for char in prompt]\n",
    "    \n",
    "    # Handle context length\n",
    "    if len(input_tokens) > context_len:\n",
    "        input_tokens = input_tokens[-context_len:]\n",
    "    \n",
    "    # Pad to context length\n",
    "    input_ids = np.zeros(context_len, dtype=np.int32)\n",
    "    if len(input_tokens) > 0:\n",
    "        input_ids[-len(input_tokens):] = input_tokens\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = np.zeros(context_len, dtype=np.int32)\n",
    "    if len(input_tokens) > 0:\n",
    "        attention_mask[-len(input_tokens):] = 1\n",
    "    \n",
    "    # Prepare for model\n",
    "    input_ids = np.expand_dims(input_ids, axis=0)\n",
    "    attention_mask = np.expand_dims(attention_mask, axis=0)\n",
    "    \n",
    "    # Generate response token by token\n",
    "    generated_tokens = input_tokens.copy()\n",
    "    id_to_token = {v: k for k, v in token_to_id_dict.items()}\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Get model predictions\n",
    "        predictions = model.predict([input_ids, attention_mask], verbose=0)\n",
    "        \n",
    "        # Get last token logits (find the last non-zero position in attention mask)\n",
    "        last_pos = np.sum(attention_mask[0]) - 1\n",
    "        if last_pos < 0:\n",
    "            last_pos = 0\n",
    "        next_token_logits = predictions[0, last_pos, :] / temperature\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        probabilities = tf.nn.softmax(next_token_logits).numpy()\n",
    "        \n",
    "        # Sample next token\n",
    "        next_token = np.random.choice(len(probabilities), p=probabilities)\n",
    "        \n",
    "        # Stop if we hit a stop token or newline\n",
    "        if next_token == 0 or (next_token in token_to_id_dict.values() and id_to_token[next_token] == '\\n'):\n",
    "            break\n",
    "            \n",
    "        generated_tokens.append(next_token)\n",
    "        \n",
    "        # Update input for next iteration\n",
    "        if len(generated_tokens) > context_len:\n",
    "            generated_tokens = generated_tokens[-context_len:]\n",
    "        \n",
    "        # Create new input\n",
    "        new_input_ids = np.zeros((1, context_len), dtype=np.int32)\n",
    "        if len(generated_tokens) > 0:\n",
    "            new_input_ids[0, -len(generated_tokens):] = generated_tokens\n",
    "        \n",
    "        new_attention_mask = np.zeros((1, context_len), dtype=np.int32)\n",
    "        if len(generated_tokens) > 0:\n",
    "            new_attention_mask[0, -len(generated_tokens):] = 1\n",
    "        \n",
    "        input_ids = new_input_ids\n",
    "        attention_mask = new_attention_mask\n",
    "    \n",
    "    # Convert tokens back to text\n",
    "    response_tokens = generated_tokens[len(input_tokens):]  # Only the new tokens\n",
    "    response = ''.join([id_to_token.get(token, '') for token in response_tokens])\n",
    "    \n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b200e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"]8'Vi3A;#sFÃ¶XÃ¶xr3Ã¶][xÃ¶M6!dlwxâ€”$pb:Orxx1JkW0:pÃ¶yyÃ¶;94Å“!Ã¶Ã¶GHQÃ¶G:â€˜::$fwrg3Rg!R!/gxrgg/PÃ¶JIYPlÃ¶6Ã¶J%6RpLp\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response_from_bot(model,token_to_id_dict,prompt = 'yoyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770fbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ada879",
   "metadata": {},
   "source": [
    "## 7. Notes & Next Steps\n",
    "Document any observations, issues, or future plans here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
